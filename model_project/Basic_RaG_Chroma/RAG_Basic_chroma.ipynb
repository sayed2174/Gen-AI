{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1a4ae28f6c19450d882e47f73e05c704": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d79cf11d24084fbdb7bdef40a676b06c",
              "IPY_MODEL_87981dc0d8b54579b8000f83c0189673",
              "IPY_MODEL_cf887194bb2048d09937bf3957dc8f32"
            ],
            "layout": "IPY_MODEL_6648f1bfc4ad44ad882e2b9b1a332833"
          }
        },
        "d79cf11d24084fbdb7bdef40a676b06c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c4484bdc36744b3867e839161444629",
            "placeholder": "​",
            "style": "IPY_MODEL_4e7687c272dc4dc8811dce7b1456a226",
            "value": "modules.json: 100%"
          }
        },
        "87981dc0d8b54579b8000f83c0189673": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8758fbedab7d4726a99b32e5603e3a05",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9feaef9bb67e4914b3cd49260b70f23d",
            "value": 349
          }
        },
        "cf887194bb2048d09937bf3957dc8f32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a30dbbc68d54b5080087c8e3a4e4e8a",
            "placeholder": "​",
            "style": "IPY_MODEL_e85ebcd8de214590a9e7c84e7d1e04f7",
            "value": " 349/349 [00:00&lt;00:00, 11.7kB/s]"
          }
        },
        "6648f1bfc4ad44ad882e2b9b1a332833": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c4484bdc36744b3867e839161444629": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e7687c272dc4dc8811dce7b1456a226": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8758fbedab7d4726a99b32e5603e3a05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9feaef9bb67e4914b3cd49260b70f23d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2a30dbbc68d54b5080087c8e3a4e4e8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e85ebcd8de214590a9e7c84e7d1e04f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f7404363d474e52827ce7895dc602ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_de8000d52e0a43b58792e30c70daa211",
              "IPY_MODEL_df9ae781076a4db1b45086ba5d8a98db",
              "IPY_MODEL_42162e3c0ea54ce39beb913ed79f5847"
            ],
            "layout": "IPY_MODEL_c07b785cf7f8476fb0aaad22a6415fdf"
          }
        },
        "de8000d52e0a43b58792e30c70daa211": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_154451f0989f49a78b6190bb4b6882a8",
            "placeholder": "​",
            "style": "IPY_MODEL_6a379ef45e5a48eba4593a3d4ad77041",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "df9ae781076a4db1b45086ba5d8a98db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9309a642a2a244a593cf1946267563c6",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_612b3bb969024b0cb542e12da550ea3d",
            "value": 116
          }
        },
        "42162e3c0ea54ce39beb913ed79f5847": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d05439739bd45dba2ae1cb95efebc37",
            "placeholder": "​",
            "style": "IPY_MODEL_77aea7fd3a4a4fe7aeb119ec4aa5fe30",
            "value": " 116/116 [00:00&lt;00:00, 2.83kB/s]"
          }
        },
        "c07b785cf7f8476fb0aaad22a6415fdf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "154451f0989f49a78b6190bb4b6882a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a379ef45e5a48eba4593a3d4ad77041": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9309a642a2a244a593cf1946267563c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "612b3bb969024b0cb542e12da550ea3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3d05439739bd45dba2ae1cb95efebc37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77aea7fd3a4a4fe7aeb119ec4aa5fe30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "986bc2a56703421ebbff68afebf05f8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_170b80103869458994cfef551c240feb",
              "IPY_MODEL_5d9fe05845e24d5fa55dc34186f91237",
              "IPY_MODEL_7686eb60dc744deb8ddd448689f42d06"
            ],
            "layout": "IPY_MODEL_4c368b321003407db6190390ca05b378"
          }
        },
        "170b80103869458994cfef551c240feb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11a7d5ddd8934a9bac85777f01b6fff9",
            "placeholder": "​",
            "style": "IPY_MODEL_2f752923874347398e26fdb95debb05f",
            "value": "README.md: "
          }
        },
        "5d9fe05845e24d5fa55dc34186f91237": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46023a651a004868a9225eb187b506c7",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0de7164d51564d3faf35dc1d58502424",
            "value": 1
          }
        },
        "7686eb60dc744deb8ddd448689f42d06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cbf173bae72461bbb7de68aa840c289",
            "placeholder": "​",
            "style": "IPY_MODEL_3043448dd2e14e2799bdadb8eb759960",
            "value": " 10.5k/? [00:00&lt;00:00, 393kB/s]"
          }
        },
        "4c368b321003407db6190390ca05b378": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11a7d5ddd8934a9bac85777f01b6fff9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f752923874347398e26fdb95debb05f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "46023a651a004868a9225eb187b506c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "0de7164d51564d3faf35dc1d58502424": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5cbf173bae72461bbb7de68aa840c289": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3043448dd2e14e2799bdadb8eb759960": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87c355185b45469aaf7887e1eef73b08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f9436dacee8d4cd18b3d79c41fa1c807",
              "IPY_MODEL_d53905bac8804e4492b493edf52bded6",
              "IPY_MODEL_26f31ddbdae542028dbf4ce059ef7a60"
            ],
            "layout": "IPY_MODEL_6904fa7ed1bf423eac26a242320e0fe9"
          }
        },
        "f9436dacee8d4cd18b3d79c41fa1c807": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7017464ddd024884800093e9e98d82fa",
            "placeholder": "​",
            "style": "IPY_MODEL_742da65c40b44993b35800aaf0ce602d",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "d53905bac8804e4492b493edf52bded6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5807ad6c003b4ea89f5f2e80421a76e7",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_77e1d46e624347118023b4d8426a3f2c",
            "value": 53
          }
        },
        "26f31ddbdae542028dbf4ce059ef7a60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99b60c8910674ea793ef48db88dc3a2f",
            "placeholder": "​",
            "style": "IPY_MODEL_262868e9b02b41d2ad0160535d699d73",
            "value": " 53.0/53.0 [00:00&lt;00:00, 2.49kB/s]"
          }
        },
        "6904fa7ed1bf423eac26a242320e0fe9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7017464ddd024884800093e9e98d82fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "742da65c40b44993b35800aaf0ce602d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5807ad6c003b4ea89f5f2e80421a76e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77e1d46e624347118023b4d8426a3f2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "99b60c8910674ea793ef48db88dc3a2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "262868e9b02b41d2ad0160535d699d73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f224abbb1c04013810652d39e50ab64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0f55279ebc474c07b3f55cbdee800715",
              "IPY_MODEL_19d8f0a11e9a48cbbcd2f27b87bb78a4",
              "IPY_MODEL_8918f01c16264a7ea34c88008e952b8b"
            ],
            "layout": "IPY_MODEL_013ce602481f4faea177f0a5caced5ba"
          }
        },
        "0f55279ebc474c07b3f55cbdee800715": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e626ed0506744f718e7ac08b34e72b66",
            "placeholder": "​",
            "style": "IPY_MODEL_a94a428c37454da08587532e2a36fbbb",
            "value": "config.json: 100%"
          }
        },
        "19d8f0a11e9a48cbbcd2f27b87bb78a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f99b96c64e084e4883601f13f7d1b70d",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_43c50f56e80a4520b7b41db71948545b",
            "value": 612
          }
        },
        "8918f01c16264a7ea34c88008e952b8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7e6e78930844cea89428aa4b2ba67a2",
            "placeholder": "​",
            "style": "IPY_MODEL_8ea614f93a304d31861372d1f0c63996",
            "value": " 612/612 [00:00&lt;00:00, 60.8kB/s]"
          }
        },
        "013ce602481f4faea177f0a5caced5ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e626ed0506744f718e7ac08b34e72b66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a94a428c37454da08587532e2a36fbbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f99b96c64e084e4883601f13f7d1b70d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43c50f56e80a4520b7b41db71948545b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f7e6e78930844cea89428aa4b2ba67a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ea614f93a304d31861372d1f0c63996": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "72351f110b1c4d0a84313f094783975c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_80d0d803275f4cd495e5d3f5e752bd1d",
              "IPY_MODEL_cd9244bfa1e94e05b6de87bea90aeab5",
              "IPY_MODEL_c7b9af97fdf34a2082b2c90e9cfca8eb"
            ],
            "layout": "IPY_MODEL_68d345b659964460b1963b4d9e42ca49"
          }
        },
        "80d0d803275f4cd495e5d3f5e752bd1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3eb3737ad1f2499580a53623506cb320",
            "placeholder": "​",
            "style": "IPY_MODEL_6a10ce05d0ae4568aef6776d1449096e",
            "value": "model.safetensors: 100%"
          }
        },
        "cd9244bfa1e94e05b6de87bea90aeab5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebc49181a1a44f69a57b12657cc96579",
            "max": 90868376,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c5bcc73aba2e452a86c823140f9bf1c7",
            "value": 90868376
          }
        },
        "c7b9af97fdf34a2082b2c90e9cfca8eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70ad14fd7bde4eca8f8586e6ffa2f955",
            "placeholder": "​",
            "style": "IPY_MODEL_57b8059bcc0a415c80d3d32671d844de",
            "value": " 90.9M/90.9M [00:01&lt;00:00, 85.5MB/s]"
          }
        },
        "68d345b659964460b1963b4d9e42ca49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3eb3737ad1f2499580a53623506cb320": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a10ce05d0ae4568aef6776d1449096e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ebc49181a1a44f69a57b12657cc96579": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5bcc73aba2e452a86c823140f9bf1c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "70ad14fd7bde4eca8f8586e6ffa2f955": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57b8059bcc0a415c80d3d32671d844de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0925c51de38444f0a12e63cf14ed6fd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c71c3b3044bf48b88079abb640091c7d",
              "IPY_MODEL_a397a772d92d4cfeb6d89bb7020cd258",
              "IPY_MODEL_4299ee4fa06b48dc809aa167c5ade670"
            ],
            "layout": "IPY_MODEL_0a8d4f0cc3684e43aefda5a13db212cf"
          }
        },
        "c71c3b3044bf48b88079abb640091c7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59077d9d349c4e8594c1aef660ef9dc7",
            "placeholder": "​",
            "style": "IPY_MODEL_c41e1e21741d4b8db3825695697f0f6f",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "a397a772d92d4cfeb6d89bb7020cd258": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27374921278046c3b75b0acc331a2407",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_83c14accea134a33849225abe9af8ceb",
            "value": 350
          }
        },
        "4299ee4fa06b48dc809aa167c5ade670": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce9c63498c174f31870fa578d39fcae1",
            "placeholder": "​",
            "style": "IPY_MODEL_a8d1cd079a4441b78a5f48d899ec2280",
            "value": " 350/350 [00:00&lt;00:00, 29.5kB/s]"
          }
        },
        "0a8d4f0cc3684e43aefda5a13db212cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59077d9d349c4e8594c1aef660ef9dc7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c41e1e21741d4b8db3825695697f0f6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27374921278046c3b75b0acc331a2407": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83c14accea134a33849225abe9af8ceb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ce9c63498c174f31870fa578d39fcae1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8d1cd079a4441b78a5f48d899ec2280": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "487564842a074a2eb992a070c0f16e02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f6d4c3c7128f4afcac6aa49146a06cad",
              "IPY_MODEL_5a40d3e9e4574e5b996494d3e7dedf52",
              "IPY_MODEL_1a39df0e8672479198f193c1838f3e51"
            ],
            "layout": "IPY_MODEL_1499a9d070df4d7e96c2cca287629c3a"
          }
        },
        "f6d4c3c7128f4afcac6aa49146a06cad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d65ccd220d14e19a401e5cfa0630939",
            "placeholder": "​",
            "style": "IPY_MODEL_ff3b82fdbb7d48dcab15cde8a3e29832",
            "value": "vocab.txt: "
          }
        },
        "5a40d3e9e4574e5b996494d3e7dedf52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56585b3b6e5948fbbdaa0cb29416caf4",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6c668cd5af8c45d58288f51f465d09f8",
            "value": 1
          }
        },
        "1a39df0e8672479198f193c1838f3e51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d171213fd18c47ccb06f314f80ee061d",
            "placeholder": "​",
            "style": "IPY_MODEL_d0356541624443cfa5b2e2b34ff097ee",
            "value": " 232k/? [00:00&lt;00:00, 4.32MB/s]"
          }
        },
        "1499a9d070df4d7e96c2cca287629c3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d65ccd220d14e19a401e5cfa0630939": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff3b82fdbb7d48dcab15cde8a3e29832": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56585b3b6e5948fbbdaa0cb29416caf4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "6c668cd5af8c45d58288f51f465d09f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d171213fd18c47ccb06f314f80ee061d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0356541624443cfa5b2e2b34ff097ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fbfcf731639d474f86209905939b5aac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6511c4969a794e98b579974144351144",
              "IPY_MODEL_d6f0108fcedf4e0b8e45e8a6dc798be7",
              "IPY_MODEL_c1b99b3957d34a5e8d3130e10b3480a5"
            ],
            "layout": "IPY_MODEL_d8ac1ef2a6604254801b85e210d45488"
          }
        },
        "6511c4969a794e98b579974144351144": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2ad6b1c63b14381bf73062af2905775",
            "placeholder": "​",
            "style": "IPY_MODEL_5a2b3787ea0e4416808b03560bd866c0",
            "value": "tokenizer.json: "
          }
        },
        "d6f0108fcedf4e0b8e45e8a6dc798be7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5dc522205c749959e18412f6ac93516",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ffe5e81e7a05414aa77dd15a7d10d19e",
            "value": 1
          }
        },
        "c1b99b3957d34a5e8d3130e10b3480a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d02b7d73e75043fbbc33214ea4af4e51",
            "placeholder": "​",
            "style": "IPY_MODEL_763550291f8645b6a53a2a650e1b493a",
            "value": " 466k/? [00:00&lt;00:00, 11.5MB/s]"
          }
        },
        "d8ac1ef2a6604254801b85e210d45488": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2ad6b1c63b14381bf73062af2905775": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a2b3787ea0e4416808b03560bd866c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5dc522205c749959e18412f6ac93516": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "ffe5e81e7a05414aa77dd15a7d10d19e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d02b7d73e75043fbbc33214ea4af4e51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "763550291f8645b6a53a2a650e1b493a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "576fd1d199e34074a1290b0f36332a24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_68d0a62b671643618b6a718ce3451f64",
              "IPY_MODEL_5f1fe47181544f3788983551cbb2a190",
              "IPY_MODEL_4d0dd3e980d74860b98cf61f38458b84"
            ],
            "layout": "IPY_MODEL_232b15daa94d49989731c5e2ac35e9e4"
          }
        },
        "68d0a62b671643618b6a718ce3451f64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dcd7bdc046534ff0a97b78027bab1475",
            "placeholder": "​",
            "style": "IPY_MODEL_91cf3dd491a9420cb5f1e24c276b6f1c",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "5f1fe47181544f3788983551cbb2a190": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_098ea265e0cf4f9daf1c224b27410e11",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e70d15740e0a45caabf60f152629f3d2",
            "value": 112
          }
        },
        "4d0dd3e980d74860b98cf61f38458b84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2cc09ddb60ff492aaca47c282e695e6e",
            "placeholder": "​",
            "style": "IPY_MODEL_1b8e6caf82a942789f74c2fc612fc3b4",
            "value": " 112/112 [00:00&lt;00:00, 9.01kB/s]"
          }
        },
        "232b15daa94d49989731c5e2ac35e9e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcd7bdc046534ff0a97b78027bab1475": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91cf3dd491a9420cb5f1e24c276b6f1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "098ea265e0cf4f9daf1c224b27410e11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e70d15740e0a45caabf60f152629f3d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2cc09ddb60ff492aaca47c282e695e6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b8e6caf82a942789f74c2fc612fc3b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "22d08bb26b284c8ab40c6dd57341244c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9729de70dee84f12b68a3b5e1b239641",
              "IPY_MODEL_409cb5d5799740cbb5745f6f74aeb9c9",
              "IPY_MODEL_2d619012733d470bac42f1b104493c27"
            ],
            "layout": "IPY_MODEL_56cd5ed0c3954d0c9217483e9741551c"
          }
        },
        "9729de70dee84f12b68a3b5e1b239641": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e0a2142a3074e3e9fbb907c92a08d98",
            "placeholder": "​",
            "style": "IPY_MODEL_e1339b3db34f42248128e711125b24db",
            "value": "config.json: 100%"
          }
        },
        "409cb5d5799740cbb5745f6f74aeb9c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c98dfdaada1d402b917bbeec711533e4",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_80d37c70fe6a4497918e4f2f38eeed67",
            "value": 190
          }
        },
        "2d619012733d470bac42f1b104493c27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce1fe69e6d0944a98b23db158909646a",
            "placeholder": "​",
            "style": "IPY_MODEL_c05794924c5941e2b25eb2b11a40de3d",
            "value": " 190/190 [00:00&lt;00:00, 9.69kB/s]"
          }
        },
        "56cd5ed0c3954d0c9217483e9741551c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e0a2142a3074e3e9fbb907c92a08d98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1339b3db34f42248128e711125b24db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c98dfdaada1d402b917bbeec711533e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80d37c70fe6a4497918e4f2f38eeed67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ce1fe69e6d0944a98b23db158909646a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c05794924c5941e2b25eb2b11a40de3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xd3bOGqIEdlN",
        "outputId": "43d56b97-114d-4fb7-ee07-299712619c02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "Downloading pip-25.3-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-25.3\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.2)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.1.3)\n",
            "Collecting chromadb\n",
            "  Downloading chromadb-1.3.7-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.2 kB)\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-6.4.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.13.1-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (7.6 kB)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Collecting mistralai\n",
            "  Downloading mistralai-1.9.11-py3-none-any.whl.metadata (39 kB)\n",
            "Collecting langchain-mistralai\n",
            "  Downloading langchain_mistralai-1.1.1-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting langchain_classic\n",
            "  Downloading langchain_classic-1.0.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.9.0+cpu)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.36.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.20.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.1.2 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.1.3)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.2->langchain) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.2->langchain) (0.4.56)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.2->langchain) (9.1.2)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.2->langchain) (0.12.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.1.2->langchain) (3.0.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.5)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.2.15)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.2->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.2->langchain) (0.25.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (4.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Collecting build>=1.0.3 (from chromadb)\n",
            "  Downloading build-1.3.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting pybase64>=1.4.1 (from chromadb)\n",
            "  Downloading pybase64-1.4.3-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.38.0)\n",
            "Collecting posthog<6.0.0,>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.39.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.76.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.20.0)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-34.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.25.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.2 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.9.0.post0)\n",
            "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.5.0)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.44)\n",
            "Collecting requests (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (3.13.2)\n",
            "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.12.0)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.3)\n",
            "Collecting langchain-text-splitters<2.0.0,>=1.0.0 (from langchain_classic)\n",
            "  Downloading langchain_text_splitters-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.22.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting langchain-core<2.0.0,>=1.1.2 (from langchain)\n",
            "  Downloading langchain_core-1.2.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.2.1)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain_community) (3.3.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.12/dist-packages (from seaborn) (2.2.2)\n",
            "Collecting eval-type-backport>=0.2.0 (from mistralai)\n",
            "  Downloading eval_type_backport-0.3.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting invoke<3.0.0,>=2.2.0 (from mistralai)\n",
            "  Downloading invoke-2.2.1-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.30.0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.43.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
            "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (6.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.12/dist-packages (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.9.23)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.72.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.39.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.39.1-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.39.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.39.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.39.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.39.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.60b1 (from opentelemetry-sdk>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.60b1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (3.5 kB)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb) (3.3.1)\n",
            "Downloading chromadb-1.3.7-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.7/21.7 MB\u001b[0m \u001b[31m110.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
            "Downloading pypdf-6.4.2-py3-none-any.whl (328 kB)\n",
            "Downloading faiss_cpu-1.13.1-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m129.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m92.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_classic-1.0.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading langchain_text_splitters-1.1.0-py3-none-any.whl (34 kB)\n",
            "Downloading langchain_core-1.2.0-py3-none-any.whl (475 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mistralai-1.9.11-py3-none-any.whl (442 kB)\n",
            "Downloading invoke-2.2.1-py3-none-any.whl (160 kB)\n",
            "Downloading langchain_mistralai-1.1.1-py3-none-any.whl (19 kB)\n",
            "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl (278 kB)\n",
            "Downloading build-1.3.0-py3-none-any.whl (23 kB)\n",
            "Downloading eval_type_backport-0.3.1-py3-none-any.whl (6.1 kB)\n",
            "Downloading kubernetes-34.1.0-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
            "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m114.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.39.1-py3-none-any.whl (19 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.39.1-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.39.1-py3-none-any.whl (72 kB)\n",
            "Downloading opentelemetry_sdk-1.39.1-py3-none-any.whl (132 kB)\n",
            "Downloading opentelemetry_api-1.39.1-py3-none-any.whl (66 kB)\n",
            "Downloading opentelemetry_semantic_conventions-0.60b1-py3-none-any.whl (219 kB)\n",
            "Downloading pybase64-1.4.3-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
            "Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (517 kB)\n",
            "Downloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m94.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (456 kB)\n",
            "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "Downloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Building wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=6d3978e06e79e059bb96eb8c357f992a516805f4575ad7ea0c1efbb3ce01290b\n",
            "  Stored in directory: /root/.cache/pip/wheels/d5/3d/69/8d68d249cd3de2584f226e27fd431d6344f7d70fd856ebd01b\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, durationpy, uvloop, urllib3, pyproject_hooks, pypdf, pybase64, opentelemetry-proto, mypy-extensions, mmh3, marshmallow, invoke, humanfriendly, httptools, faiss-cpu, eval-type-backport, bcrypt, backoff, watchfiles, typing-inspect, requests, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, build, posthog, opentelemetry-semantic-conventions, onnxruntime, mistralai, dataclasses-json, opentelemetry-sdk, kubernetes, opentelemetry-exporter-otlp-proto-grpc, langchain-core, langchain-text-splitters, langchain-mistralai, chromadb, langchain_classic, langchain_community\n",
            "\u001b[2K  Attempting uninstall: urllib3\n",
            "\u001b[2K    Found existing installation: urllib3 2.5.0\n",
            "\u001b[2K    Uninstalling urllib3-2.5.0:\n",
            "\u001b[2K      Successfully uninstalled urllib3-2.5.0\n",
            "\u001b[2K  Attempting uninstall: opentelemetry-proto\n",
            "\u001b[2K    Found existing installation: opentelemetry-proto 1.37.0\n",
            "\u001b[2K    Uninstalling opentelemetry-proto-1.37.0:\n",
            "\u001b[2K      Successfully uninstalled opentelemetry-proto-1.37.0\n",
            "\u001b[2K  Attempting uninstall: requests\n",
            "\u001b[2K    Found existing installation: requests 2.32.4\n",
            "\u001b[2K    Uninstalling requests-2.32.4:\n",
            "\u001b[2K      Successfully uninstalled requests-2.32.4\n",
            "\u001b[2K  Attempting uninstall: opentelemetry-exporter-otlp-proto-common\n",
            "\u001b[2K    Found existing installation: opentelemetry-exporter-otlp-proto-common 1.37.0\n",
            "\u001b[2K    Uninstalling opentelemetry-exporter-otlp-proto-common-1.37.0:\n",
            "\u001b[2K      Successfully uninstalled opentelemetry-exporter-otlp-proto-common-1.37.0\n",
            "\u001b[2K  Attempting uninstall: opentelemetry-api\n",
            "\u001b[2K    Found existing installation: opentelemetry-api 1.37.0\n",
            "\u001b[2K    Uninstalling opentelemetry-api-1.37.0:\n",
            "\u001b[2K      Successfully uninstalled opentelemetry-api-1.37.0\n",
            "\u001b[2K  Attempting uninstall: opentelemetry-semantic-conventions\n",
            "\u001b[2K    Found existing installation: opentelemetry-semantic-conventions 0.58b0\n",
            "\u001b[2K    Uninstalling opentelemetry-semantic-conventions-0.58b0:\n",
            "\u001b[2K      Successfully uninstalled opentelemetry-semantic-conventions-0.58b0\n",
            "\u001b[2K  Attempting uninstall: opentelemetry-sdk\n",
            "\u001b[2K    Found existing installation: opentelemetry-sdk 1.37.0\n",
            "\u001b[2K    Uninstalling opentelemetry-sdk-1.37.0:\n",
            "\u001b[2K      Successfully uninstalled opentelemetry-sdk-1.37.0\n",
            "\u001b[2K  Attempting uninstall: langchain-core\n",
            "\u001b[2K    Found existing installation: langchain-core 1.1.3\n",
            "\u001b[2K    Uninstalling langchain-core-1.1.3:\n",
            "\u001b[2K      Successfully uninstalled langchain-core-1.1.3\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39/39\u001b[0m [langchain_community]\n",
            "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-gcp-logging 1.11.0a0 requires opentelemetry-sdk<1.39.0,>=1.35.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\n",
            "google-adk 1.20.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.39.1 which is incompatible.\n",
            "google-adk 1.20.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed backoff-2.2.1 bcrypt-5.0.0 build-1.3.0 chromadb-1.3.7 coloredlogs-15.0.1 dataclasses-json-0.6.7 durationpy-0.10 eval-type-backport-0.3.1 faiss-cpu-1.13.1 httptools-0.7.1 humanfriendly-10.0 invoke-2.2.1 kubernetes-34.1.0 langchain-core-1.2.0 langchain-mistralai-1.1.1 langchain-text-splitters-1.1.0 langchain_classic-1.0.0 langchain_community-0.4.1 marshmallow-3.26.1 mistralai-1.9.11 mmh3-5.2.0 mypy-extensions-1.1.0 onnxruntime-1.23.2 opentelemetry-api-1.39.1 opentelemetry-exporter-otlp-proto-common-1.39.1 opentelemetry-exporter-otlp-proto-grpc-1.39.1 opentelemetry-proto-1.39.1 opentelemetry-sdk-1.39.1 opentelemetry-semantic-conventions-0.60b1 posthog-5.4.0 pybase64-1.4.3 pypdf-6.4.2 pypika-0.48.9 pyproject_hooks-1.2.0 requests-2.32.5 typing-inspect-0.9.0 urllib3-2.3.0 uvloop-0.22.1 watchfiles-1.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install sentence-transformers langchain chromadb pypdf faiss-cpu  langchain_community scikit-learn matplotlib seaborn numpy mistralai langchain-mistralai langchain_classic"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import PyPDFLoader, PyPDFDirectoryLoader\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS,Chroma\n",
        "from langchain_classic.schema import Document\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "\n",
        "\n",
        "loader = PyPDFDirectoryLoader(\"/content/drive/MyDrive/pdf/\",glob=\"*.pdf\")\n",
        "docs = loader.load()\n",
        "\n",
        "\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
        "chunks = splitter.split_documents(docs)\n",
        "print(f\"Loaded {len(docs)} docs, split into {len(chunks)} chunks\")\n",
        "# inspect one\n",
        "print(chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLxbq8mWEnEq",
        "outputId": "9dc7166d-216e-4ef6-b129-dc9a3cb22dc6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Loaded 133 docs, split into 212 chunks\n",
            "[Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-09T20:37:37+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-09T20:37:37+05:30', 'source': '/content/drive/MyDrive/pdf/Day-8-chunking.pdf', 'total_pages': 20, 'page': 0, 'page_label': '1'}, page_content='preencoded.png\\nDay 8\\nIngestion & Chunking'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-09T20:37:37+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-09T20:37:37+05:30', 'source': '/content/drive/MyDrive/pdf/Day-8-chunking.pdf', 'total_pages': 20, 'page': 1, 'page_label': '2'}, page_content='preencoded.png\\nThe Art of Chunking: \\nOptimizing RAG \\nArchitecture\\nUnderstanding how to break down information is crucial for \\nefficient Retrieval Augmented Generation (RAG) systems. This \\npresentation explores the vital role of \"chunking\" in enhancing LLM \\nperformance and overall RAG architecture.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-09T20:37:37+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-09T20:37:37+05:30', 'source': '/content/drive/MyDrive/pdf/Day-8-chunking.pdf', 'total_pages': 20, 'page': 2, 'page_label': '3'}, page_content='preencoded.png\\nWhy is Chunking Essential for \\nLLMs?\\nLLMs\\' Processing Limits\\nLarge Language Models cannot \\nprocess entire documents at \\nonce. They require content to be \\nbroken into manageable, smaller \\npieces.\\nMeaningful Segmentation\\nDocuments must be split into \\n\"meaningful chunks\" that retain \\ncoherence and context, not just \\narbitrary divisions.\\nEnhanced Retrieval\\nEffective chunking directly leads to better information retrieval, which is \\nthe cornerstone of a superior RAG system.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-09T20:37:37+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-09T20:37:37+05:30', 'source': '/content/drive/MyDrive/pdf/Day-8-chunking.pdf', 'total_pages': 20, 'page': 3, 'page_label': '4'}, page_content='preencoded.png\\nNavigating the Context Window Limit\\nEvery Large Language Model operates within a defined \"context \\nwindow\" – a fixed number of tokens it can process \\nsimultaneously.\\n• Models can only \"remember\" and reason with information \\nwithin this window.\\n• To provide more context to the LLM, large documents must \\nbe efficiently chunked and relevant pieces retrieved.\\n• Proper chunking ensures that the most pertinent \\ninformation fits within the context window, preventing'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-09T20:37:37+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-09T20:37:37+05:30', 'source': '/content/drive/MyDrive/pdf/Day-8-chunking.pdf', 'total_pages': 20, 'page': 3, 'page_label': '4'}, page_content='information fits within the context window, preventing \\ncritical details from being overlooked.\\nWhen a query requires information beyond this limit, chunking \\nand retrieval become indispensable.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-09T20:37:37+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-09T20:37:37+05:30', 'source': '/content/drive/MyDrive/pdf/Day-8-chunking.pdf', 'total_pages': 20, 'page': 4, 'page_label': '5'}, page_content='preencoded.png'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-09T20:37:37+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-09T20:37:37+05:30', 'source': '/content/drive/MyDrive/pdf/Day-8-chunking.pdf', 'total_pages': 20, 'page': 5, 'page_label': '6'}, page_content='preencoded.png\\nDefining a \"Chunk\"\\nA Small Text \\nSegment\\nA chunk is not just any arbitrary \\nsplit. It\\'s a carefully defined \\nsection of text.\\nContaining One \\nClear Idea\\nThe fundamental principle: \\neach chunk should \\nencapsulate a single, coherent \\nthought or concept.\\nBeyond Random \\nSplitting\\nAvoid merely cutting text at \\nfixed intervals; this often \\ndisrupts meaning and reduces \\nthe utility of the chunk.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-09T20:37:37+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-09T20:37:37+05:30', 'source': '/content/drive/MyDrive/pdf/Day-8-chunking.pdf', 'total_pages': 20, 'page': 6, 'page_label': '7'}, page_content='preencoded.png\\nKey Chunking Strategies\\n01\\nFixed Size Chunking\\nSimple and straightforward, \\noften used as a baseline.\\n02\\nOverlap Chunking\\nIntroduces redundancy to \\npreserve context across \\nboundaries.\\n03\\nRecursive Text Splitter\\nHierarchical splitting that respects document structure.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-09T20:37:37+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-09T20:37:37+05:30', 'source': '/content/drive/MyDrive/pdf/Day-8-chunking.pdf', 'total_pages': 20, 'page': 7, 'page_label': '8'}, page_content='preencoded.png'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-09T20:37:37+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-09T20:37:37+05:30', 'source': '/content/drive/MyDrive/pdf/Day-8-chunking.pdf', 'total_pages': 20, 'page': 8, 'page_label': '9'}, page_content='preencoded.png'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-09T20:37:37+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-09T20:37:37+05:30', 'source': '/content/drive/MyDrive/pdf/Day-8-chunking.pdf', 'total_pages': 20, 'page': 9, 'page_label': '10'}, page_content='preencoded.png'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-09T20:37:37+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-09T20:37:37+05:30', 'source': '/content/drive/MyDrive/pdf/Day-8-chunking.pdf', 'total_pages': 20, 'page': 10, 'page_label': '11'}, page_content='preencoded.png'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-09T20:37:37+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-09T20:37:37+05:30', 'source': '/content/drive/MyDrive/pdf/Day-8-chunking.pdf', 'total_pages': 20, 'page': 11, 'page_label': '12'}, page_content='preencoded.png'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-09T20:37:37+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-09T20:37:37+05:30', 'source': '/content/drive/MyDrive/pdf/Day-8-chunking.pdf', 'total_pages': 20, 'page': 12, 'page_label': '13'}, page_content='preencoded.png'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-09T20:37:37+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-09T20:37:37+05:30', 'source': '/content/drive/MyDrive/pdf/Day-8-chunking.pdf', 'total_pages': 20, 'page': 13, 'page_label': '14'}, page_content='preencoded.png'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-09T20:37:37+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-09T20:37:37+05:30', 'source': '/content/drive/MyDrive/pdf/Day-8-chunking.pdf', 'total_pages': 20, 'page': 14, 'page_label': '15'}, page_content=\"preencoded.png\\nFixed Size Chunking: Pros \\nand Cons\\nPros:\\n• Ease of Implementation: It's \\nthe simplest chunking \\nmethod to set up and \\nexecute.\\n• Predictable Output: \\nGenerates chunks of a \\nconsistent length, which \\ncan be useful for certain \\nmodels.\\nCons:\\n• Loss of Meaning: Can \\nfrequently cut sentences or \\nideas mid-flow, leading to \\nincoherent chunks.\\n• Contextual Gaps: Important \\nconnections between cut \\ntext segments can be lost, \\nhampering retrieval \\naccuracy.\"), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-09T20:37:37+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-09T20:37:37+05:30', 'source': '/content/drive/MyDrive/pdf/Day-8-chunking.pdf', 'total_pages': 20, 'page': 15, 'page_label': '16'}, page_content='preencoded.png\\nThe Advantage of Overlapping Chunks\\nOverlapping chunks address a critical flaw in fixed-size \\nmethods by maintaining contextual continuity.\\n• Preserves Sentence Integrity: By allowing a small portion \\nof text to repeat in subsequent chunks, it ensures that \\nsentences and short ideas are not cut off abruptly.\\n• Reduces Contextual Gaps: The overlap acts as a bridge, \\nlinking related information and improving the chances of \\nretrieving a complete thought.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-09T20:37:37+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-09T20:37:37+05:30', 'source': '/content/drive/MyDrive/pdf/Day-8-chunking.pdf', 'total_pages': 20, 'page': 15, 'page_label': '16'}, page_content='linking related information and improving the chances of \\nretrieving a complete thought.\\n• Minor Redundancy for Major Gain: While it introduces a \\nsmall amount of redundant information, the benefit of \\nimproved coherence far outweighs this drawback.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-09T20:37:37+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-09T20:37:37+05:30', 'source': '/content/drive/MyDrive/pdf/Day-8-chunking.pdf', 'total_pages': 20, 'page': 16, 'page_label': '17'}, page_content='preencoded.png\\nRecursive Text Splitter: Structure-\\nAware Chunking\\nPrioritizes Document Structure\\nThis advanced method first attempts to split text based on hierarchical structures like \\nheadings.\\nBreaks Down to Paragraphs\\nIf the text is still too large, it then splits into individual paragraphs.\\nFinal Split by Sentences\\nAs a last resort, it breaks down paragraphs into sentences, ensuring the \\nsmallest meaningful units.\\nMost Accurate for RAG'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-09T20:37:37+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-09T20:37:37+05:30', 'source': '/content/drive/MyDrive/pdf/Day-8-chunking.pdf', 'total_pages': 20, 'page': 16, 'page_label': '17'}, page_content='smallest meaningful units.\\nMost Accurate for RAG\\nBy respecting the inherent organization of the document, it provides the most \\ncontextually relevant chunks for RAG systems.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-09T20:37:37+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-09T20:37:37+05:30', 'source': '/content/drive/MyDrive/pdf/Day-8-chunking.pdf', 'total_pages': 20, 'page': 17, 'page_label': '18'}, page_content=\"preencoded.png\\nOptimal Chunk Configuration for Q&A RAG\\nFor most Question-Answering (Q&A) based RAG applications, a carefully tuned chunk size and overlap can significantly improve \\nperformance.\\n300\\nChunk Size (Tokens)\\nThis size generally allows for sufficient context without overwhelming the LLM's context window. It captures enough detail fo r \\nmost queries.\\n50\\nOverlap (Tokens)\"), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-09T20:37:37+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-09T20:37:37+05:30', 'source': '/content/drive/MyDrive/pdf/Day-8-chunking.pdf', 'total_pages': 20, 'page': 17, 'page_label': '18'}, page_content='most queries.\\n50\\nOverlap (Tokens)\\nA 50-token overlap effectively bridges potential gaps, ensuring that key information at chunk boundaries remains connected \\nand retrievable.\\nThis configuration balances detail, context preservation, and processing efficiency, making it ideal for robust Q&A interactions.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-09T20:37:37+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-09T20:37:37+05:30', 'source': '/content/drive/MyDrive/pdf/Day-8-chunking.pdf', 'total_pages': 20, 'page': 18, 'page_label': '19'}, page_content='preencoded.png\\nGood vs. Bad Chunks: A Visual Comparison\\nGood Chunk\\nA \"good\" chunk provides clear context, focusing on a single, \\ncomplete topic. It answers a potential question without \\nambiguity and retains all necessary surrounding \\ninformation.\\n• Clear context: All relevant information for one idea.\\n• Single topic: Focused and coherent content.\\n• Well-bounded: Starts and ends logically.\\nBad Chunk\\nA \"bad\" chunk might be cut mid-sentence, contain'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-09T20:37:37+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-09T20:37:37+05:30', 'source': '/content/drive/MyDrive/pdf/Day-8-chunking.pdf', 'total_pages': 20, 'page': 18, 'page_label': '19'}, page_content='Bad Chunk\\nA \"bad\" chunk might be cut mid-sentence, contain \\nfragmented ideas, or blend unrelated lines. This leads to \\nconfusion and hinders effective retrieval, making it difficult \\nfor the LLM to understand or answer queries accurately.\\n• Mid-sentence cut: Incomplete thoughts.\\n• Unrelated lines: Jumbled, incoherent information.\\n• Ambiguous context: Hard for LLM to interpret.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-09T20:37:37+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-09T20:37:37+05:30', 'source': '/content/drive/MyDrive/pdf/Day-8-chunking.pdf', 'total_pages': 20, 'page': 19, 'page_label': '20'}, page_content='preencoded.png\\nHands on tasks !'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:59+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:33:59+05:30', 'source': '/content/drive/MyDrive/pdf/Day-6.pdf', 'total_pages': 13, 'page': 0, 'page_label': '1'}, page_content='preencoded.png\\nDay 6\\nPrompt Evaluation & Quality Measurement\\nEnsuring accuracy, reliability & trust in LLM outputs'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:59+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:33:59+05:30', 'source': '/content/drive/MyDrive/pdf/Day-6.pdf', 'total_pages': 13, 'page': 1, 'page_label': '2'}, page_content='preencoded.png\\nThe Art and Science of LLM \\nPrompt Evaluation\\nIn the rapidly evolving landscape of Large Language Models (LLMs), \\neffective prompt evaluation is paramount. This presentation \\nexplores various methods to ensure LLM outputs are high-quality, \\nreliable, and aligned with user expectations.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:59+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:33:59+05:30', 'source': '/content/drive/MyDrive/pdf/Day-6.pdf', 'total_pages': 13, 'page': 2, 'page_label': '3'}, page_content='preencoded.png\\nWhy Prompt Evaluation Matters\\nIncorrect Facts\\nLLMs can generate factually inaccurate information, \\nleading to misinformation.\\nMissing Information\\nOutputs may lack crucial details, resulting in incomplete \\nor unhelpful responses.\\nWrong Formats\\nLLMs might deviate from specified output formats, \\ncausing integration issues.\\nHallucinations\\nThe model can produce confident but entirely fabricated \\ncontent, a significant risk.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:59+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:33:59+05:30', 'source': '/content/drive/MyDrive/pdf/Day-6.pdf', 'total_pages': 13, 'page': 2, 'page_label': '3'}, page_content='The model can produce confident but entirely fabricated \\ncontent, a significant risk.\\nWithout robust evaluation metrics, deploying LLMs can lead to unreliable systems. We need to measure quality before \\ndeployment.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:59+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:33:59+05:30', 'source': '/content/drive/MyDrive/pdf/Day-6.pdf', 'total_pages': 13, 'page': 3, 'page_label': '4'}, page_content='preencoded.png\\nEvaluation Categories\\nHuman Evaluation\\nLeveraging human judgment for nuanced quality \\nassessment.\\nAutomated Metrics\\nQuantifiable scores for specific linguistic tasks.\\nBehavioral Checks\\nRule-based tests to enforce structural and content \\nconstraints.\\nLLM-as-a-Judge\\nUsing advanced LLMs to evaluate simpler model outputs.\\nThe most effective evaluation strategies combine multiple methods for comprehensive quality assurance.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:59+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:33:59+05:30', 'source': '/content/drive/MyDrive/pdf/Day-6.pdf', 'total_pages': 13, 'page': 4, 'page_label': '5'}, page_content='preencoded.png\\nHuman Evaluation\\nHuman evaluation involves domain experts assessing LLM outputs based on a predefined set of criteria. This \\nmethod is invaluable for capturing the subjective and nuanced aspects of language quality.\\n• Factual Accuracy: Verifying the correctness of information.\\n• Completeness: Ensuring all required information is present.\\n• Grammar & Fluency: Assessing linguistic quality and readability.\\n• Tone and Safety: Judging appropriate tone and absence of harmful content.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:59+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:33:59+05:30', 'source': '/content/drive/MyDrive/pdf/Day-6.pdf', 'total_pages': 13, 'page': 4, 'page_label': '5'}, page_content='• Tone and Safety: Judging appropriate tone and absence of harmful content.\\nWhile human evaluation offers unparalleled quality and incorporates specialized domain knowledge, it is both \\nresource-intensive and time-consuming.\\n1\\nPros: High Quality\\nProvides deep insights and accurate assessments.\\n2\\nPros: Domain Expertise\\nLeverages specialized knowledge for nuanced feedback.\\n3\\nCons: Expensive\\nRequires significant financial investment.\\n4\\nCons: Slow\\nCan delay development cycles due to manual effort.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:59+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:33:59+05:30', 'source': '/content/drive/MyDrive/pdf/Day-6.pdf', 'total_pages': 13, 'page': 5, 'page_label': '6'}, page_content='preencoded.png\\nAutomated Evaluation\\nAutomated metrics provide objective and quantifiable assessments of LLM \\nperformance, making them suitable for large-scale and iterative evaluations. They \\nare particularly useful for specific NLP tasks where clear reference answers exist.\\nCommonly used in:\\n• Summarization: Measuring how well a model condenses text.\\n• Translation: Assessing the accuracy of language conversion.\\n• Classification: Evaluating the correctness of categorical assignments.\\nPros: Fast'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:59+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:33:59+05:30', 'source': '/content/drive/MyDrive/pdf/Day-6.pdf', 'total_pages': 13, 'page': 5, 'page_label': '6'}, page_content='• Classification: Evaluating the correctness of categorical assignments.\\nPros: Fast\\nQuick execution for rapid feedback.\\nPros: Scalable\\nEfficiently evaluates large datasets.\\nCons: Limited Meaning Capture\\nStruggles with semantic nuances and \\ncontext.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:59+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:33:59+05:30', 'source': '/content/drive/MyDrive/pdf/Day-6.pdf', 'total_pages': 13, 'page': 6, 'page_label': '7'}, page_content='preencoded.png\\nBLEU Score: Bilingual Evaluation Understudy\\nThe BLEU score is a widely used automated metric primarily for evaluating \\nmachine translation. It measures the similarity between a machine-\\ngenerated translation (candidate) and one or more human-generated \\nreference translations.\\nHow it works:\\n• N-gram Overlap: Compares sequences of words (n-grams) between \\nthe candidate and reference texts.\\n• Score Range: A score from 0 to 1 (often expressed as a percentage)'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:59+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:33:59+05:30', 'source': '/content/drive/MyDrive/pdf/Day-6.pdf', 'total_pages': 13, 'page': 6, 'page_label': '7'}, page_content='• Score Range: A score from 0 to 1 (often expressed as a percentage) \\nindicates higher similarity.\\nExample:Reference: “Cats are great pets.”Model: “Cats make good \\npets.”Shared n-grams contribute to a higher BLEU score.\\nLimit: BLEU scores can penalize outputs that use synonyms or alternative \\nphrasings, as they prioritize exact wording matches, potentially \\noverlooking semantic equivalence.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:59+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:33:59+05:30', 'source': '/content/drive/MyDrive/pdf/Day-6.pdf', 'total_pages': 13, 'page': 7, 'page_label': '8'}, page_content='preencoded.png\\nROUGE Score: Recall-Oriented Understudy for Gisting \\nEvaluation\\nROUGE is a set of metrics specifically designed to evaluate automatic \\nsummarization and machine translation by comparing an automatically \\nproduced summary or translation with a set of reference summaries or \\ntranslations.\\nTypes of ROUGE:\\n• ROUGE-1: Measures the overlap of unigrams (individual words).\\n• ROUGE-2: Measures the overlap of bigrams (sequences of two words).'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:59+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:33:59+05:30', 'source': '/content/drive/MyDrive/pdf/Day-6.pdf', 'total_pages': 13, 'page': 7, 'page_label': '8'}, page_content='• ROUGE-2: Measures the overlap of bigrams (sequences of two words).\\n• ROUGE-L: Focuses on the longest common subsequence, capturing \\nsentence-level structural similarity without requiring consecutive matches.\\nStrength: ROUGE metrics excel at measuring recall, indicating how much \\nimportant information from the reference is preserved in the generated text.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:59+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:33:59+05:30', 'source': '/content/drive/MyDrive/pdf/Day-6.pdf', 'total_pages': 13, 'page': 8, 'page_label': '9'}, page_content=\"preencoded.png\\nClassification Metrics\\nFor tasks that categorize inputs, specific metrics are used to assess the model's accuracy and reliability.\\n85%\\nAccuracy\\nThe proportion of total correct predictions (Correct predictions / \\nTotal predictions).\\n92%\\nPrecision\\nThe proportion of true positive predictions among all positive \\npredictions.\\n88%\\nRecall\\nThe proportion of true positive predictions among all actual \\npositive instances.\\n90%\\nF1-Score\"), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:59+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:33:59+05:30', 'source': '/content/drive/MyDrive/pdf/Day-6.pdf', 'total_pages': 13, 'page': 8, 'page_label': '9'}, page_content='The proportion of true positive predictions among all actual \\npositive instances.\\n90%\\nF1-Score\\nThe harmonic mean of Precision and Recall, useful for imbalanced \\ndatasets.\\nExample Use Cases:\\n• Sentiment Classification: Determining if text expresses positive, negative, or neutral sentiment.\\n• Email Spam Detection: Identifying whether an email is spam or legitimate.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:59+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:33:59+05:30', 'source': '/content/drive/MyDrive/pdf/Day-6.pdf', 'total_pages': 13, 'page': 9, 'page_label': '10'}, page_content='preencoded.png\\nBehavioral Evaluation (Rule-based Checks)\\nBehavioral evaluation, often implemented through rule-based checks, ensures that LLM outputs adhere to specific structural, formatting, or content constraints defined in the \\nprompt.\\n• Format Validation: Ensuring outputs conform to specified structures, e.g., valid \\nJSON, XML.\\n• Content Inclusion: Verifying the presence of required elements like citations or \\nreasoning steps.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:59+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:33:59+05:30', 'source': '/content/drive/MyDrive/pdf/Day-6.pdf', 'total_pages': 13, 'page': 9, 'page_label': '10'}, page_content='reasoning steps.\\n• Structural Adherence: Checking for ordered lists, specific paragraph structures, or \\nother formatting rules.\\n• Hallucination Prevention: Implementing rules to detect and flag fabricated \\ninformation.\\nAutomated tests based on these rules contribute to stable and predictable model performance. For example, a rule might dictate: \"Output must contain a field: \"answer\": \\n\"<value>\".\"'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:59+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:33:59+05:30', 'source': '/content/drive/MyDrive/pdf/Day-6.pdf', 'total_pages': 13, 'page': 10, 'page_label': '11'}, page_content='preencoded.png\\nLLM-as-a-Judge\\nThis innovative evaluation method leverages a more powerful or specially tuned LLM to assess the outputs of \\nanother, often less capable, LLM. The \"judge\" LLM provides human-like feedback and scoring, automating a \\nprocess traditionally requiring human intervention.\\n• Rank Responses: Ordering multiple LLM outputs by quality or relevance.\\n• Score Reasoning & Correctness: Evaluating the logical coherence and factual accuracy of answers.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:59+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:33:59+05:30', 'source': '/content/drive/MyDrive/pdf/Day-6.pdf', 'total_pages': 13, 'page': 10, 'page_label': '11'}, page_content='• Score Reasoning & Correctness: Evaluating the logical coherence and factual accuracy of answers.\\n• Detect Hallucinations: Identifying instances where the LLM generates false information.\\nPrompt Example: \"Rate this answer 1-10 based on factual accuracy.\"\\nUsed in:\\n• Leaderboards: Benchmarking and comparing LLM performance.\\n• Auto-Feedback Systems: Providing instant, scalable feedback for model improvement.\\nCost & Token Efficiency Evaluation'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:59+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:33:59+05:30', 'source': '/content/drive/MyDrive/pdf/Day-6.pdf', 'total_pages': 13, 'page': 10, 'page_label': '11'}, page_content='Cost & Token Efficiency Evaluation\\nBeyond quality, the practical considerations of cost and performance are critical for deploying LLMs efficiently.\\nTokens Input/Output\\nMonitoring token usage directly impacts operational costs.\\nExecution Latency\\nMinimizing response time is crucial for a positive user experience.\\nThe ultimate goal is to achieve high-quality responses with optimal efficiency and reduced computational expense.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:59+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:33:59+05:30', 'source': '/content/drive/MyDrive/pdf/Day-6.pdf', 'total_pages': 13, 'page': 11, 'page_label': '12'}, page_content='preencoded.png\\nHow a good prompt will change everything !\\nA good prompt ensures:\\n Correctness\\n  Completeness\\n  Structured & formatted output\\n  Reasoning included\\n  Low hallucination\\n  Efficient \\ntoken usage\\n  Consistent performance'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:59+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:33:59+05:30', 'source': '/content/drive/MyDrive/pdf/Day-6.pdf', 'total_pages': 13, 'page': 12, 'page_label': '13'}, page_content='preencoded.png\\nHow a good prompt will \\nchange everything !\\nA good prompt ensures:\\n Correctness\\n Completeness\\n Structured & formatted output\\n Reasoning included\\n Low hallucination\\n Efficient token usage\\n Consistent performance'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 2', 'source': '/content/drive/MyDrive/pdf/Day 2.pdf', 'total_pages': 18, 'page': 0, 'page_label': '1'}, page_content='Foundations of Large \\nLanguage Models (LLMs)'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 2', 'source': '/content/drive/MyDrive/pdf/Day 2.pdf', 'total_pages': 18, 'page': 1, 'page_label': '2'}, page_content='What Are Large Language \\nModels (LLMs)?\\nDeﬁnition\\nLLMs are advanced AI programs \\nthat understand and generate \\nhuman-like text, learning from \\nvast amounts of data.\\nExamples\\nLeading LLMs include GPT\\ue0884o, \\nGemini, Claude, and Mistral, \\neach with unique capabilities.\\nImportance Today\\nThey are revolutionizing how we \\ninteract with technology, \\nautomating tasks, and powering \\nnew applications across \\nindustries.'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 2', 'source': '/content/drive/MyDrive/pdf/Day 2.pdf', 'total_pages': 18, 'page': 2, 'page_label': '3'}, page_content=\"Today's Learning Journey: Exploring LLM Fundamentals\\nWhat LLMs Are\\nGaining a clear understanding of their core concept and purpose.\\nHow They Work\\nUnpacking the underlying mechanisms that enable their capabilities.\\nTokens, Embeddings, Attention\\nDelving into key components that define their operational logic.\\nML Basics Behind LLMs\\nConnecting LLMs to foundational Machine Learning principles.\"), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 2', 'source': '/content/drive/MyDrive/pdf/Day 2.pdf', 'total_pages': 18, 'page': 3, 'page_label': '4'}, page_content=\"Machine Learning Basics: Predicting from Patterns\\nAt its core, Machine Learning is about making predictions based on past patterns found in data.\\n• ML models learn relationships between input data \\ue081X) and output \\ue081Y\\ue082.\\n• The process involves collecting data, analyzing patterns, choosing algorithms, training a model, and finally, making predictions.\\n• Think of it as your brain's ability to predict outcomes – ML models do the same, just with vast datasets.\\nThe ML Workﬂow\\nCollect Data\"), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 2', 'source': '/content/drive/MyDrive/pdf/Day 2.pdf', 'total_pages': 18, 'page': 3, 'page_label': '4'}, page_content='The ML Workﬂow\\nCollect Data\\nAnalyze Patterns\\nChoose Algorithms\\nTrain Model\\nMake Predictions'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 2', 'source': '/content/drive/MyDrive/pdf/Day 2.pdf', 'total_pages': 18, 'page': 4, 'page_label': '5'}, page_content='Language Models: Machine \\nLearning for Text\\nLanguage Models are specialized ML models trained on enormous text \\ndatasets, known as corpora, to understand and generate human \\nlanguage.\\nCore Function:\\nUnlike general ML that predicts \\nany Y from X, Language Models \\nexcel at predicting the next \\ntoken in a sequence, not an \\nentire sentence at once.\\nVersatile Applications:\\n• Answering complex questions \\n\\ue081Q&A\\ue082\\n• Enhancing search capabilities\\n• Summarizing lengthy \\ndocuments'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 2', 'source': '/content/drive/MyDrive/pdf/Day 2.pdf', 'total_pages': 18, 'page': 4, 'page_label': '5'}, page_content='\\ue081Q&A\\ue082\\n• Enhancing search capabilities\\n• Summarizing lengthy \\ndocuments\\n• Accurate speech transcription'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 2', 'source': '/content/drive/MyDrive/pdf/Day 2.pdf', 'total_pages': 18, 'page': 5, 'page_label': '6'}, page_content='Early Language Models: Probabilistic n-grams\\nThe earliest language models relied on simple statistical probabilities. They counted how often words appeared together.\\nCounting Patterns\\nThese models predicted the next \\nword based on the frequency of \\nword sequences in their training \\ndata.\\nn-grams\\nAn \"n-gram\" is a contiguous \\nsequence of \\'n\\' items from a given \\nsample of text or speech.\\nLimited Context\\nWhile simple and effective for their \\ntime, n-gram models struggled with'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 2', 'source': '/content/drive/MyDrive/pdf/Day 2.pdf', 'total_pages': 18, 'page': 5, 'page_label': '6'}, page_content='Limited Context\\nWhile simple and effective for their \\ntime, n-gram models struggled with \\nlong-range dependencies in \\nlanguage.\\nN-gram Example\\nContext Predicted Next Word (based on frequency)\\n\"I love to eat...\" \"pizza\" (high frequency after \"to eat\")\\n\"The cat sat on the...\" \"mat\" (more common than \"moon\")'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 2', 'source': '/content/drive/MyDrive/pdf/Day 2.pdf', 'total_pages': 18, 'page': 6, 'page_label': '7'}, page_content='A New Era: Neural Networks for Language\\nThe advent of neural networks marked a significant shift, moving beyond simple word counts to capture deeper \\nsemantic relationships.\\nDeep Learning Advantage\\nNeural networks can learn intricate patterns \\nand hierarchical structures within language.\\nEmbeddings: Meaning as Numbers\\nText is converted into numerical vectors \\n(embeddings), allowing the model to \\nunderstand semantic similarity.\\nSemantic & Context Capture\\nThey can grasp the meaning of words in'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 2', 'source': '/content/drive/MyDrive/pdf/Day 2.pdf', 'total_pages': 18, 'page': 6, 'page_label': '7'}, page_content='understand semantic similarity.\\nSemantic & Context Capture\\nThey can grasp the meaning of words in \\ncontext and handle longer linguistic \\ndependencies.\\nText to Meaning'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 2', 'source': '/content/drive/MyDrive/pdf/Day 2.pdf', 'total_pages': 18, 'page': 7, 'page_label': '8'}, page_content='The Evolution of Language Models: A Timeline\\nFrom basic statistical methods to powerful transformer architectures, language models have undergone rapid advancements.\\n1Word2Vec (2013)\\nIntroduced efficient word embeddings, capturing semantic \\nrelationships.\\n2 Recurrent Neural Networks \\n(RNNs)Handled sequential data, but struggled with very long \\nsequences.\\n3Long Short-Term Memory \\n(LSTMs)An improvement on RNNs, better at retaining information over \\nlonger sequences.\\n4 Transformers (2017)'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 2', 'source': '/content/drive/MyDrive/pdf/Day 2.pdf', 'total_pages': 18, 'page': 7, 'page_label': '8'}, page_content='longer sequences.\\n4 Transformers (2017)\\nRevolutionized NLP with parallel processing and self-attention, \\nbecoming the foundation for modern LLMs.\\n5Modern LLMs (GPT, Gemini, \\nClaude)Vast, highly capable models built on transformer architecture, \\ndriving current AI breakthroughs.'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 2', 'source': '/content/drive/MyDrive/pdf/Day 2.pdf', 'total_pages': 18, 'page': 8, 'page_label': '9'}, page_content='How Transformers Work: The \\nPower of Attention\\nTransformers are the backbone of modern LLMs, designed to process text \\nefficiently and understand complex relationships.\\nParallel Processing\\nUnlike earlier models, \\ntransformers can process entire \\ntext sequences simultaneously, \\ngreatly speeding up training.\\nSelf-Attention Mechanism\\nThis allows the model to weigh \\nthe importance of different words \\nin a sentence relative to each \\nother, even if they are far apart.\\nLong-Range Dependencies'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 2', 'source': '/content/drive/MyDrive/pdf/Day 2.pdf', 'total_pages': 18, 'page': 8, 'page_label': '9'}, page_content='in a sentence relative to each \\nother, even if they are far apart.\\nLong-Range Dependencies\\nEffectively captures relationships between words that are not adjacent, \\ncrucial for understanding complex language.'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 2', 'source': '/content/drive/MyDrive/pdf/Day 2.pdf', 'total_pages': 18, 'page': 9, 'page_label': '10'}, page_content='Tokens: The Building Blocks of \\nLLMsLLMs don\\'t process words directly; they break text into smaller units called tokens.\\nWhat Are Tokens?\\n• Tokens can be whole words, parts of words, or punctuation marks.\\n• The way text is tokenized impacts how an LLM processes information.\\nExamples:\\n\"Apple\" often translates to a single token.\\n\"Internationalization\" might be broken into multiple tokens like \"Inter\", \"national\", \\n\"ization\".'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 2', 'source': '/content/drive/MyDrive/pdf/Day 2.pdf', 'total_pages': 18, 'page': 9, 'page_label': '10'}, page_content='\"Internationalization\" might be broken into multiple tokens like \"Inter\", \"national\", \\n\"ization\".\\nUnderstanding tokens is vital as they directly influence the cost, speed, and context window limitations of LLM interactions.'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 2', 'source': '/content/drive/MyDrive/pdf/Day 2.pdf', 'total_pages': 18, 'page': 10, 'page_label': '11'}, page_content=\"Day 1: What Are We Covering?\\n01 \\nIntroduction to LLMs\\nUnderstanding the core concepts and their impact.\\n0 \\n 2 \\nHow LLMs Work\\nA high-level overview of their architecture and text generation.\\n0 \\n 3 \\nCapabilities & \\nLimitationsExploring why LLMs are so powerful and what they can't do.\\n0 \\n 4 \\nReal-World Applications & \\nHands-OnPractical uses and an interactive activity to get started.\"), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 2', 'source': '/content/drive/MyDrive/pdf/Day 2.pdf', 'total_pages': 18, 'page': 11, 'page_label': '12'}, page_content='Embeddings: Converting Text \\nto Vectors\\nAt their core, Large Language Models convert human language into a \\nnumerical format they can understand and process. This transformation is \\ndone through \"embeddings.\"\\nText to Vectors\\nTransforming words and phrases into numerical arrays.\\nCapture Meaning\\nMathematically representing semantic relationships and context.\\nSimilar Concepts\\nConcepts with related meanings are grouped closer in vector space.'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 2', 'source': '/content/drive/MyDrive/pdf/Day 2.pdf', 'total_pages': 18, 'page': 11, 'page_label': '12'}, page_content='Similar Concepts\\nConcepts with related meanings are grouped closer in vector space.\\nImagine an equation: \"King\" – \"Man\" + \"Woman\" ≈ \"Queen.\" Embeddings \\nallow LLMs to understand these nuanced relationships.'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 2', 'source': '/content/drive/MyDrive/pdf/Day 2.pdf', 'total_pages': 18, 'page': 12, 'page_label': '13'}, page_content=\"LLM Architecture: A \\nHigh-Level Flow\\nUnderstanding the fundamental steps an LLM takes to process your \\ninput and generate a response.\\nTransformer Layers\\nEmbeddings\\nTokenizer\\nText Input\\nThis simplified diagram illustrates the journey of your query through the \\nLLM's internal mechanisms, from raw text to a coherent output.\"), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 2', 'source': '/content/drive/MyDrive/pdf/Day 2.pdf', 'total_pages': 18, 'page': 13, 'page_label': '14'}, page_content='How LLMs Generate Text: Next-Token Prediction\\nLLMs don\\'t \"think\" like humans; they excel at a sophisticated \"word-guessing game\" based on patterns learned from vast amounts of data.\\n1 You Provide a Prompt\\nStarting the conversation with your input text.\\n2 Model Predicts Next Token\\nBased on context, it anticipates the most probable next word or \\nsub-word.\\n3 Prediction Becomes Input\\nThe newly predicted token is added to the sequence, extending \\nthe context.\\n4 Repeats Until Complete'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 2', 'source': '/content/drive/MyDrive/pdf/Day 2.pdf', 'total_pages': 18, 'page': 13, 'page_label': '14'}, page_content='the context.\\n4 Repeats Until Complete\\nThis iterative process continues until a full sentence or desired \\noutput is generated.\\nThis \"word-guessing game,\" performed billions of times per second, creates the illusion of intelligence.'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 2', 'source': '/content/drive/MyDrive/pdf/Day 2.pdf', 'total_pages': 18, 'page': 14, 'page_label': '15'}, page_content='Why LLMs Are So Good\\nThe impressive capabilities of LLMs stem from a combination of massive data and advanced architectural \\ndesign.\\nTrained on Huge Datasets: Exposure to petabytes of text and code from the internet.\\nFollow Normal Patterns: Learns the statistical regularities and nuances of human language.\\nRarely Unnatural: Generates remarkably coherent and contextually appropriate responses.'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 2', 'source': '/content/drive/MyDrive/pdf/Day 2.pdf', 'total_pages': 18, 'page': 14, 'page_label': '15'}, page_content='Rarely Unnatural: Generates remarkably coherent and contextually appropriate responses.\\n\"Garbage in, garbage out\" still applies. The quality of the input greatly influences the quality of the output.'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 2', 'source': '/content/drive/MyDrive/pdf/Day 2.pdf', 'total_pages': 18, 'page': 15, 'page_label': '16'}, page_content='Do LLMs Truly Understand?\\nThis is a profound philosophical and technical debate. While LLMs exhibit \\nimpressive linguistic feats, their \"understanding\" differs from human cognition.\\nPattern Prediction\\nThey learn and predict based on \\nstatistical patterns in data.\\nSimulated \\nUnderstanding\\nThey can mimic comprehension \\nwithout actual consciousness or \\nbelief.\\nNo Consciousness\\nLLMs lack genuine subjective experience, feelings, or self-awareness.'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 2', 'source': '/content/drive/MyDrive/pdf/Day 2.pdf', 'total_pages': 18, 'page': 16, 'page_label': '17'}, page_content='Real-World Applications of LLMs\\nLLMs are rapidly transforming various industries and everyday tasks, making them more efficient and accessible.\\nChatbots & Assistants\\nCustomer service, virtual helpers, interactive tools.\\nCoding Assistants\\nGenerating code, debugging, explaining complex logic.\\nSummarization\\nCondensing long articles, reports, or meetings.\\nPDF Extraction\\nExtracting specific information from unstructured documents.\\nAgents & Workﬂows\\nAutomating multi-step tasks and processes.'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 2', 'source': '/content/drive/MyDrive/pdf/Day 2.pdf', 'total_pages': 18, 'page': 16, 'page_label': '17'}, page_content='Agents & Workﬂows\\nAutomating multi-step tasks and processes.\\nPersonalized Learning\\nTailoring educational content and tutoring.'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 2', 'source': '/content/drive/MyDrive/pdf/Day 2.pdf', 'total_pages': 18, 'page': 17, 'page_label': '18'}, page_content='Hands-On Activity'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 3', 'source': '/content/drive/MyDrive/pdf/Day 3.pdf', 'total_pages': 14, 'page': 0, 'page_label': '1'}, page_content='Day 2\\nPrompt Engineering'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 3', 'source': '/content/drive/MyDrive/pdf/Day 3.pdf', 'total_pages': 14, 'page': 1, 'page_label': '2'}, page_content='● Focus on essential prompt engineering \\ntechniques\\n● Understand the function of the context \\nwindow size\\n● Develop effective prompts for better model \\nresponses\\n● Explore advanced prompting strategies \\nduring Day 2'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 3', 'source': '/content/drive/MyDrive/pdf/Day 3.pdf', 'total_pages': 14, 'page': 2, 'page_label': '3'}, page_content='What is Prompt Engineering?\\n● Crafting and reﬁning inputs for large \\nlanguage models\\n● Involves structuring prompts to guide \\nmodel behavior\\n● Focuses on achieving desired, high-quality \\nmodel outputs\\n● Essential skill for maximizing the utility of \\nLLMs'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 3', 'source': '/content/drive/MyDrive/pdf/Day 3.pdf', 'total_pages': 14, 'page': 3, 'page_label': '4'}, page_content='What is Prompt Engineering?\\n● Crafting and reﬁning inputs for large \\nlanguage models\\n● Involves structuring prompts to guide \\nmodel behavior\\n● Focuses on achieving desired, high-quality \\nmodel outputs\\n● Essential skill for maximizing the utility of \\nLLMs'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 3', 'source': '/content/drive/MyDrive/pdf/Day 3.pdf', 'total_pages': 14, 'page': 4, 'page_label': '5'}, page_content=\"Zero-Shot Prompting Explained\\n● Zero-shot prompting provides \\nan instruction only\\n● The LLM uses its training to \\nanswer the request\\n● No speciﬁc examples are given \\nwithin the prompt\\n● It relies solely on the model's \\nexisting knowledge\"), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 3', 'source': '/content/drive/MyDrive/pdf/Day 3.pdf', 'total_pages': 14, 'page': 5, 'page_label': '6'}, page_content='Zero-Shot Prompting Explained'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 3', 'source': '/content/drive/MyDrive/pdf/Day 3.pdf', 'total_pages': 14, 'page': 6, 'page_label': '7'}, page_content=\"Few-Shot Prompting \\nExplained\\n● Providing examples guides the \\nmodel's response\\n● Few-shot prompting includes \\nseveral input-output pairs\\n● Improves accuracy and helps \\nmodel learn speciﬁc tasks\\n● Examples are shown directly \\nwithin the prompt's context\"), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 3', 'source': '/content/drive/MyDrive/pdf/Day 3.pdf', 'total_pages': 14, 'page': 7, 'page_label': '8'}, page_content='Few-Shot Prompting Explained'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 3', 'source': '/content/drive/MyDrive/pdf/Day 3.pdf', 'total_pages': 14, 'page': 9, 'page_label': '10'}, page_content='Building a Prompt Framework\\nT o perform Few-shot prompting effectively, you need a structure. \\nJust throwing text at the model can confuse it. Use the Standard \\nPrompt Structure:\\n1. Role (Optional): Who is the AI?\\n2. Instruction: What is the task?\\n3. Examples (The \"Shots\"): The pattern to follow.\\n4. Context/Constraint: Any guardrails?\\n5. Input Data: The actual thing to process.\\n6. Output Indicator: A cue for the AI to start.'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 3', 'source': '/content/drive/MyDrive/pdf/Day 3.pdf', 'total_pages': 14, 'page': 10, 'page_label': '11'}, page_content='Building a Prompt Framework\\nT o perform Few-shot prompting effectively, you need a structure. \\nJust throwing text at the model can confuse it. Use the Standard \\nPrompt Structure:\\n1. Role (Optional): Who is the AI?\\n2. Instruction: What is the task?\\n3. Examples (The \"Shots\"): The pattern to follow.\\n4. Context/Constraint: Any guardrails?\\n5. Input Data: The actual thing to process.\\n6. Output Indicator: A cue for the AI to start.'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 3', 'source': '/content/drive/MyDrive/pdf/Day 3.pdf', 'total_pages': 14, 'page': 11, 'page_label': '12'}, page_content=\"Context Window \\nDeep Dive\\n● The context window is the \\nmodel's short-term memory\\n● It deﬁnes the amount of text \\nthe model can process\\n● Window size limits the input \\nand output length\\n● Exceeding the window causes \\nthe model to forget \\ninformation\"), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 3', 'source': '/content/drive/MyDrive/pdf/Day 3.pdf', 'total_pages': 14, 'page': 12, 'page_label': '13'}, page_content='What happens if the context window is \\nexceeded ?'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 3', 'source': '/content/drive/MyDrive/pdf/Day 3.pdf', 'total_pages': 14, 'page': 13, 'page_label': '14'}, page_content='Hands on …..'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:28+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:37:04+05:30', 'source': '/content/drive/MyDrive/pdf/Day-5.pdf', 'total_pages': 14, 'page': 0, 'page_label': '1'}, page_content='preencoded.png\\nDay 4 \\nPrompt Design Patterns (ReAct, Self-Reflect)'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:28+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:37:04+05:30', 'source': '/content/drive/MyDrive/pdf/Day-5.pdf', 'total_pages': 14, 'page': 1, 'page_label': '2'}, page_content='preencoded.png\\nWhy Prompt Patterns Matter\\nLarge Language Models (LLMs) interpret instructions with extreme literalness. This means that poorly constructed prompts \\ninevitably lead to suboptimal or inaccurate results. Conversely, well-designed prompts are the cornerstone of effective LLM \\ninteraction.\\nEnhanced Accuracy\\nReduces \"hallucinations\" and improves factual \\ncorrectness.\\nConsistent Outputs\\nEnsures predictable structure and formatting every \\ntime.\\nAutomation-Ready'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:28+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:37:04+05:30', 'source': '/content/drive/MyDrive/pdf/Day-5.pdf', 'total_pages': 14, 'page': 1, 'page_label': '2'}, page_content=\"Consistent Outputs\\nEnsures predictable structure and formatting every \\ntime.\\nAutomation-Ready\\nGenerates outputs that can be seamlessly integrated \\ninto automated workflows.\\nSuperior Reasoning\\nFacilitates better logical thinking and effective tool \\nutilization.\\nThe prompt we design directly influences the model's behavior and utility.\\n“Prompting is programming the LLM with language.”\"), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:28+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:37:04+05:30', 'source': '/content/drive/MyDrive/pdf/Day-5.pdf', 'total_pages': 14, 'page': 2, 'page_label': '3'}, page_content='preencoded.png\\nPersona / Role Prompting\\nPersona or Role Prompting involves instructing the LLM to adopt a \\nspecific identity and behavioral style. This technique is invaluable \\nfor eliciting responses with an expert tone, targeting a particular \\naudience, or ensuring domain-specific accuracy.\\nTemplate\\nAct as a . Your audience is . Use'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:28+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:37:04+05:30', 'source': '/content/drive/MyDrive/pdf/Day-5.pdf', 'total_pages': 14, 'page': 3, 'page_label': '4'}, page_content='preencoded.png\\nStructured Output Prompting\\nFor seamless integration into production systems, LLM responses often need to be machine-readable. Structured Output Prompting ensures the model \\ndelivers information in predefined formats like JSON, Tables, XML, or Markdown Lists.\\nTemplate\\nReturn ONLY valid JSON: {\"skill\": \"\", \"rating\": \"\", \"years_of_experience\": \"\"}\\nExample\\nInput text: “Kiran has 3 years experience in Python and intermediate SQL skills.”\\nOutput:'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:28+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:37:04+05:30', 'source': '/content/drive/MyDrive/pdf/Day-5.pdf', 'total_pages': 14, 'page': 3, 'page_label': '4'}, page_content='Example\\nInput text: “Kiran has 3 years experience in Python and intermediate SQL skills.”\\nOutput:\\n{\"skill\": \"Python\", \"rating\": \"Intermediate\", \"years_of_experience\": 3}\\n Best Practice:\\n• Clearly state the required format.\\n• Specify validation requirements.\\n• Use ALL CAPS for non-negotiable rules (e.g., ONLY, NO explanation).'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:28+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:37:04+05:30', 'source': '/content/drive/MyDrive/pdf/Day-5.pdf', 'total_pages': 14, 'page': 4, 'page_label': '5'}, page_content='preencoded.png\\nReAct Prompting (Reason + Act)\\nReAct (Reason + Act) Prompting is particularly effective for tasks requiring tool utilization, mathematical calculations, sea rch operations, or multi-step reasoning. It \\nguides the LLM through a structured problem-solving process.\\nFormat\\nThought:Action:Observation:Final Answer:\\nExample\\nQuestion: What is 234 * 77?\\nAction: calculator(\"234 * 77\")Observation: 18018Thought: Calculation doneFinal Answer: 18,018'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:28+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:37:04+05:30', 'source': '/content/drive/MyDrive/pdf/Day-5.pdf', 'total_pages': 14, 'page': 4, 'page_label': '5'}, page_content='Action: calculator(\"234 * 77\")Observation: 18018Thought: Calculation doneFinal Answer: 18,018\\n Used in: LangChain Agents, search-connected bots, and Retrieval Augmented Generation (RAG) tools to avoid superficial guesses and enhance \\nreliability.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:28+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:37:04+05:30', 'source': '/content/drive/MyDrive/pdf/Day-5.pdf', 'total_pages': 14, 'page': 5, 'page_label': '6'}, page_content='preencoded.png\\nSelf-Critique / Self-Refine\\nSelf-Critique and Self-Refine prompting empowers the LLM to act as its own editor, significantly improving output quality and \\nreducing factual inaccuracies or \"hallucinations.\" This involves a two-phase prompting approach:\\n01\\nPhase 1: Generate\\nThe model first creates the initial response or content based \\non the given instructions.\\n02\\nPhase 2: Critique & Improve\\nThe model then critically reviews its own generated output,'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:28+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:37:04+05:30', 'source': '/content/drive/MyDrive/pdf/Day-5.pdf', 'total_pages': 14, 'page': 5, 'page_label': '6'}, page_content='02\\nPhase 2: Critique & Improve\\nThe model then critically reviews its own generated output, \\nidentifying areas for enhancement and making revisions.\\nExample\\nWrite a 40-word summary of AI. Then review clarity & improve structure. Return improved version only.\\n Tip: Instruct the model to only return the improved version, avoiding the inclusion of the critique text itself, for a \\ncleaner and more concise output.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:28+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:37:04+05:30', 'source': '/content/drive/MyDrive/pdf/Day-5.pdf', 'total_pages': 14, 'page': 6, 'page_label': '7'}, page_content='preencoded.png\\nEvidence-Based Prompting (Grounded)\\nEvidence-Based Prompting is crucial in applications like Retrieval Augmented Generation (RAG), where the model is strictly forbidden from \\ninferring or generating information not present in the provided context. It ensures that every claim is directly supported by the given data.\\nTemplate\\nUse ONLY the context below. If answer not found, say “I don’t know.” Provide supporting sentence.\\nExample\\nContext: “Gold is a good conductor of electricity.”'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:28+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:37:04+05:30', 'source': '/content/drive/MyDrive/pdf/Day-5.pdf', 'total_pages': 14, 'page': 6, 'page_label': '7'}, page_content='Example\\nContext: “Gold is a good conductor of electricity.”\\nQuestion: Is gold a better conductor than copper?\\nAnswer: I don’t know. (No information found in the provided context)\\n Improves Reliability\\nEnsures responses are factually accurate and sourced.\\n Prevents Hallucination\\nEliminates the generation of fabricated or unverified information.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:28+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:37:04+05:30', 'source': '/content/drive/MyDrive/pdf/Day-5.pdf', 'total_pages': 14, 'page': 7, 'page_label': '8'}, page_content=\"preencoded.png\\nDecomposition Prompting\\nDecomposition Prompting is a powerful technique for tackling complex problems by breaking them down into manageable, \\nsequential steps. This approach significantly improves the LLM's reasoning accuracy, especially for lengthy and intricate tasks.\\nTemplate\\nBreak the task into clear steps. Solve each step. Then combine into a final result.\\nExample\\nExplain how a transformer model works:\\n• Step 1: Input → tokens\\n• Step 2: Attention mechanism…\"), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:28+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:37:04+05:30', 'source': '/content/drive/MyDrive/pdf/Day-5.pdf', 'total_pages': 14, 'page': 7, 'page_label': '8'}, page_content='Explain how a transformer model works:\\n• Step 1: Input → tokens\\n• Step 2: Attention mechanism…\\nFinal Answer: Summary of above steps.\\n Great for: Coding tasks, detailed analysis, and complex mathematical problems that require a methodical approach.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:28+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:37:04+05:30', 'source': '/content/drive/MyDrive/pdf/Day-5.pdf', 'total_pages': 14, 'page': 8, 'page_label': '9'}, page_content='preencoded.png\\nCompare & Evaluate Prompting\\nThis technique involves instructing the model to generate multiple potential outputs and then critically compare and \\nevaluate them to select the best option. This leads to a significant boost in the accuracy and quality of the final answer, \\nparticularly in subjective or creative tasks.\\nExample\\nGenerate 3 taglines for a fitness brand. Then select the best one based on clarity & emotion. Return only the best.\\nTagline 1:\\n\"Sweat. Achieve. Repeat.\"'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:28+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:37:04+05:30', 'source': '/content/drive/MyDrive/pdf/Day-5.pdf', 'total_pages': 14, 'page': 8, 'page_label': '9'}, page_content='Tagline 1:\\n\"Sweat. Achieve. Repeat.\"\\nTagline 2:\\n\"Unleash Your Inner Athlete.\"\\nTagline 3 (Selected):\\n\"Transform Your Body, Elevate \\nYour Mind.\"\\n Useful for: Creative endeavors, ambiguous problems, and situations where multiple valid solutions exist.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:28+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:37:04+05:30', 'source': '/content/drive/MyDrive/pdf/Day-5.pdf', 'total_pages': 14, 'page': 9, 'page_label': '10'}, page_content='preencoded.png\\nPlanning + Persona + Format Prompt\\nCombining multiple prompt patterns is the key to achieving the best real-world performance from LLMs, especially for sophisticated applications like \\nAgents and RAG systems. This \"pattern stacking\" allows for highly nuanced and effective instructions.\\nExample for writing a report:\\nAct as a cybersecurity expert. Plan first: list the key sections for a ransomware report. Ask for approval. After approval, write a detailed report in table \\nformat.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:28+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:37:04+05:30', 'source': '/content/drive/MyDrive/pdf/Day-5.pdf', 'total_pages': 14, 'page': 9, 'page_label': '10'}, page_content='format.\\n1 Planning\\n2 Persona\\n3 Structured Format\\n4 Review/Approval\\n Pattern Stacking: This synergistic approach is optimal for developing sophisticated AI agents and advanced RAG applications, yielding \\nmore comprehensive and accurate results.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:28+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:37:04+05:30', 'source': '/content/drive/MyDrive/pdf/Day-5.pdf', 'total_pages': 14, 'page': 10, 'page_label': '11'}, page_content='preencoded.png\\nGood vs Bad Prompt Summary\\n“Explain blockchain.” “Explain blockchain in 5 bullets for a 12-year-old with a \\nreal-life example.”\\nNo specific format JSON, bullets, table, XML\\nNo defined role Role defined = domain accuracy\\nGuessing allowed Ground answer strictly in provided context\\n Good prompts are characterized by:\\nClear Role Definition\\n Structured Format Requirements\\nExplicit Constraints\\n Verification Mechanisms'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:28+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:37:04+05:30', 'source': '/content/drive/MyDrive/pdf/Day-5.pdf', 'total_pages': 14, 'page': 11, 'page_label': '12'}, page_content='preencoded.png\\nChoosing the best approach to write prompts\\nZero-Shot: Simple tasks; no examples needed.Wrong use → \\nvague/inaccurate results.\\nFew-Shot: Specific formats or styles; examples guide output.Wrong \\nuse → formatting drift.\\nChain-of-Thought (CoT): Multi-step reasoning.Wrong use → \\nshallow or wrong logic.\\nReAct: Tasks needing tools/search + reasoning.Wrong use → \\nmissing or incorrect tool actions.\\nCritique / Self-Refinement: High-quality, polished outputs.Wrong'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:28+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:37:04+05:30', 'source': '/content/drive/MyDrive/pdf/Day-5.pdf', 'total_pages': 14, 'page': 11, 'page_label': '12'}, page_content='Critique / Self-Refinement: High-quality, polished outputs.Wrong \\nuse → unreviewed errors, lower quality.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:28+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:37:04+05:30', 'source': '/content/drive/MyDrive/pdf/Day-5.pdf', 'total_pages': 14, 'page': 12, 'page_label': '13'}, page_content='preencoded.png\\nWhat happens if you choose the wrong method\\n• Lower accuracy\\n• Missing steps or faulty reasoning\\n• Poor formatting or inconsistency\\n• Tool calls not triggered when needed\\n• Overall weaker performance'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:28+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:37:04+05:30', 'source': '/content/drive/MyDrive/pdf/Day-5.pdf', 'total_pages': 14, 'page': 13, 'page_label': '14'}, page_content='preencoded.png\\nSummary\\nPattern What It Improves Real Benefit\\nPersona / Role Prompting \\n Tone + Expertise Domain-accurate and audience-\\nspecific responses\\nStructured Output \\n Format + Consistency Directly usable in apps (JSON, \\ntables)\\nReAct Prompting \\n Step-by-step reasoning + tool use Better correctness for math, \\nsearch, agents\\nSelf-Refine / Critique \\n Clarity + Coherence Higher quality with fewer \\nhallucinations\\nEvidence-Based Prompting \\n Source grounding Trustworthy responses (critical for'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:28+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:37:04+05:30', 'source': '/content/drive/MyDrive/pdf/Day-5.pdf', 'total_pages': 14, 'page': 13, 'page_label': '14'}, page_content='hallucinations\\nEvidence-Based Prompting \\n Source grounding Trustworthy responses (critical for \\nRAG)'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:32:52+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:36:15+05:30', 'source': '/content/drive/MyDrive/pdf/Day-4.pdf', 'total_pages': 13, 'page': 0, 'page_label': '1'}, page_content='preencoded.png\\nDay - 3 \\nChain of thoughts and Self-Consistency'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:32:52+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:36:15+05:30', 'source': '/content/drive/MyDrive/pdf/Day-4.pdf', 'total_pages': 13, 'page': 1, 'page_label': '2'}, page_content='preencoded.png\\nWhy LLMs Need Reasoning\\nLarge Language Models (LLMs) excel at pattern recognition, but they don\\'t \"think\" in \\nthe human sense. Their core function is to predict the next token based on vast \\namounts of data.\\nWhen tasks demand logical deduction or multiple sequential steps, simple prediction \\nfalls short. This is where the concept of reasoning becomes critical for LLMs.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:32:52+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:36:15+05:30', 'source': '/content/drive/MyDrive/pdf/Day-4.pdf', 'total_pages': 13, 'page': 2, 'page_label': '3'}, page_content='preencoded.png\\nThe Gap: Prediction vs. Reasoning\\nPattern Completion\\nLLMs operate on sophisticated pattern \\nmatching, completing sequences rather \\nthan understanding underlying logic.\\nNeed for Structured \\nThought\\nComplex, multi-step tasks require a \\nstructured, methodical approach that \\nprediction alone cannot provide.\\nBridging the Gap\\nWithout guided reasoning, LLMs can \\nstruggle with coherence, consistency, \\nand factual accuracy.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:32:52+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:36:15+05:30', 'source': '/content/drive/MyDrive/pdf/Day-4.pdf', 'total_pages': 13, 'page': 2, 'page_label': '3'}, page_content='Without guided reasoning, LLMs can \\nstruggle with coherence, consistency, \\nand factual accuracy.\\nThis fundamental difference leads to common LLM pitfalls that reasoning techniques aim to address.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:32:52+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:36:15+05:30', 'source': '/content/drive/MyDrive/pdf/Day-4.pdf', 'total_pages': 13, 'page': 3, 'page_label': '4'}, page_content=\"preencoded.png\\nThe Challenges of Unguided LLMs\\nLogical Jumps\\nModels may skip necessary intermediate \\nsteps, leading to incomplete or flawed \\nconclusions.\\nHallucinations\\nWithout a clear reasoning path, LLMs can \\nconfidently generate factually incorrect \\ninformation.\\nSkipped Steps\\nCrucial parts of a problem-solving \\nsequence might be omitted, undermining \\nthe final answer's validity.\\nThese issues highlight the critical need for explicit reasoning mechanisms to guide LLM behavior.\"), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:32:52+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:36:15+05:30', 'source': '/content/drive/MyDrive/pdf/Day-4.pdf', 'total_pages': 13, 'page': 4, 'page_label': '5'}, page_content=\"preencoded.png\\nIntroducing Chain-of-\\nThought (CoT)\\nCoT is a prompting technique \\nthat makes the model “show its \\nwork.”\\nChain-of-Thought (CoT) transforms how LLMs approach complex problems by \\ninstructing them to vocalize their reasoning process. This makes the invisible steps \\nvisible, leading to more robust and verifiable outputs.\\nIt's akin to a student showing all their calculations in a math problem—the final \\nanswer is important, but the process reveals understanding.\"), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:32:52+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:36:15+05:30', 'source': '/content/drive/MyDrive/pdf/Day-4.pdf', 'total_pages': 13, 'page': 5, 'page_label': '6'}, page_content=\"preencoded.png\\nHow CoT Works: Key Principles\\nForces Step-by-Step\\nCoT explicitly guides the LLM to break down problems into \\nsequential, manageable steps.\\nExposes Logic\\nThe intermediate reasoning becomes transparent, allowing users \\nto understand the model's path to a solution.\\nMimics Human Problem Solving\\nInspired by how humans tackle complex tasks, CoT encourages a \\nmore deliberate and structured approach.\\nEnhances Specific Tasks\"), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:32:52+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:36:15+05:30', 'source': '/content/drive/MyDrive/pdf/Day-4.pdf', 'total_pages': 13, 'page': 5, 'page_label': '6'}, page_content='more deliberate and structured approach.\\nEnhances Specific Tasks\\nIt is particularly effective for reasoning, mathematics, planning, and \\nmulti-step decision-making.\\nCoT shifts the LLM from simply \"guessing an answer\" to \"walking through the solution\" systematically.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:32:52+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:36:15+05:30', 'source': '/content/drive/MyDrive/pdf/Day-4.pdf', 'total_pages': 13, 'page': 6, 'page_label': '7'}, page_content='preencoded.png\\nWhen to Leverage Chain-\\nof-Thought\\nBest Use Cases:\\n• Math & arithmetic problems\\n• Logical deduction & puzzles\\n• Multi-step decision making\\n• Multi-hop questions (requiring multiple \\ninformation retrievals)\\n• Complex planning tasks\\n• Classification with detailed \\nexplanation\\nAvoid CoT for:\\n• Simple Q&A (e.g., \"What is the capital \\nof France?\")\\n• Short creative tasks (e.g., \"Write a \\nhaiku\")\\n• Direct fact retrieval'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:32:52+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:36:15+05:30', 'source': '/content/drive/MyDrive/pdf/Day-4.pdf', 'total_pages': 13, 'page': 6, 'page_label': '7'}, page_content='of France?\")\\n• Short creative tasks (e.g., \"Write a \\nhaiku\")\\n• Direct fact retrieval\\nA good rule of thumb: If a question requires more than a single step or direct recall, CoT can \\nsignificantly improve the LLM\\'s performance.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:32:52+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:36:15+05:30', 'source': '/content/drive/MyDrive/pdf/Day-4.pdf', 'total_pages': 13, 'page': 7, 'page_label': '8'}, page_content='preencoded.png\\nWhy CoT Enhances Performance\\nBreaks Down Problems\\nCoT deconstructs complex challenges into a series of manageable, logical steps.\\nReduces Hallucinations\\nBy articulating each step, the model is less likely to invent facts or make \\nunsupported claims.\\nFosters Self-Correction\\nThe visible reasoning path allows the LLM to evaluate its own logic and potentially \\ncorrect errors.\\nMimics Human Cognition\\nThis structured approach mirrors effective human problem-solving, leading to'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:32:52+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:36:15+05:30', 'source': '/content/drive/MyDrive/pdf/Day-4.pdf', 'total_pages': 13, 'page': 7, 'page_label': '8'}, page_content='This structured approach mirrors effective human problem-solving, leading to \\nmore reliable outcomes.\\nUltimately, CoT prompts encourage \"slow thinking,\" resulting in more accurate, consistent, and explainable answers from LLMs.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:32:52+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:36:15+05:30', 'source': '/content/drive/MyDrive/pdf/Day-4.pdf', 'total_pages': 13, 'page': 8, 'page_label': '9'}, page_content='preencoded.png\\nMastering CoT Prompt Patterns\\nGeneral Reasoning\\n\"Let’s think step by step.\"\\n\"Explain your reasoning before answering.\"\\nMathematical Tasks\\n\"Solve it step-by-step and show the calculations.\"\\nLogical Deduction\\n\"Think through each condition one-by-one.\"\\nPlanning & Execution\\n\"List the steps needed to reach the final solution.\"\\nEmploying these specific phrases can significantly guide the LLM toward generating clear, step-by-step reasoning sequences.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:32:52+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:36:15+05:30', 'source': '/content/drive/MyDrive/pdf/Day-4.pdf', 'total_pages': 13, 'page': 9, 'page_label': '10'}, page_content='preencoded.png\\nIntroducing Self-Consistency\\nSelf-consistency: Ask the model to \\nsolve the same problem multiple \\ntimes → pick the most common \\nanswer.\\nWhile CoT makes the reasoning path visible, self-consistency takes it a step further by \\nleveraging the LLM\\'s capacity to explore multiple reasoning avenues.\\nBy sampling several \"thoughts\" from the model and identifying the most frequent outcome, we \\ncan drastically improve the reliability of the final answer. It\\'s essentially implementing a'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:32:52+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:36:15+05:30', 'source': '/content/drive/MyDrive/pdf/Day-4.pdf', 'total_pages': 13, 'page': 9, 'page_label': '10'}, page_content='can drastically improve the reliability of the final answer. It\\'s essentially implementing a \\n\"majority vote\" among the LLM\\'s own internal reasoning processes.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:32:52+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:36:15+05:30', 'source': '/content/drive/MyDrive/pdf/Day-4.pdf', 'total_pages': 13, 'page': 10, 'page_label': '11'}, page_content=\"preencoded.png\\nWhy Self-Consistency Boosts \\nAccuracy\\nDiverse Paths\\nLLMs can generate various reasoning sequences, some correct, others flawed.\\nCorrectness Amplification\\nThe correct answers tend to appear more frequently across multiple samples.\\nNoise Reduction\\nMajority voting effectively filters out erroneous or outlier reasoning paths.\\nEnhanced Stability\\nThis technique makes the LLM's reasoning more robust, especially for challenging questions.\"), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:32:52+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:36:15+05:30', 'source': '/content/drive/MyDrive/pdf/Day-4.pdf', 'total_pages': 13, 'page': 10, 'page_label': '11'}, page_content=\"This technique makes the LLM's reasoning more robust, especially for challenging questions.\\nBy generating and comparing multiple reasoning trajectories, self-consistency reduces hallucinations \\nand leads to a more stable and accurate final answer.\"), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:32:52+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:36:15+05:30', 'source': '/content/drive/MyDrive/pdf/Day-4.pdf', 'total_pages': 13, 'page': 11, 'page_label': '12'}, page_content='preencoded.png\\nHands on tasks\\nTask 1 — CoT vs No-CoT\\n• Solve any math word problem\\n• Compare accuracy with and without CoT\\nTask 2 — Write a CoT Prompt\\n• Convert a normal prompt → CoT-enhanced reasoning prompt\\nTask 3 — Self-Consistency Experiment\\n• Ask the same question 5 times using CoT\\n• Count the answers\\n• Report the majority result'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:32:52+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:36:15+05:30', 'source': '/content/drive/MyDrive/pdf/Day-4.pdf', 'total_pages': 13, 'page': 12, 'page_label': '13'}, page_content='preencoded.png\\nSummary\\n• CoT → Improves LLM reasoning by forcing step-by-step logic\\n• Self-consistency → Improves stability by sampling multiple reasoning paths\\n• Best for math, logic, multi-step reasoning, planning\\n• Avoid CoT for simple answer tasks\\n• These techniques reduce hallucination and improve accuracy\\nCoT + Self-consistency → Stronger, more reliable LLM reasoning.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': '/content/drive/MyDrive/pdf/Day-7-RAG.pdf', 'total_pages': 17, 'page': 0, 'page_label': '1'}, page_content='preencoded.png\\nDay 7 \\nRetrieval-Augmented Generation (RAG)'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': '/content/drive/MyDrive/pdf/Day-7-RAG.pdf', 'total_pages': 17, 'page': 1, 'page_label': '2'}, page_content='preencoded.png\\nWhy LLMs Go Wrong: \\nUnderstanding Hallucinations\\nLarge Language Models (LLMs) operate by predicting the next token based \\non vast patterns learned during their training. However, they lack direct \\naccess to the latest information or private knowledge bases . This \\nfundamental limitation often leads them to confidently guess when faced \\nwith queries outside their training data, resulting in what we call \\nhallucinations .'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': '/content/drive/MyDrive/pdf/Day-7-RAG.pdf', 'total_pages': 17, 'page': 1, 'page_label': '2'}, page_content='with queries outside their training data, resulting in what we call \\nhallucinations .\\nExample: If you ask an LLM, \"Who won IPL 2025?\", it might invent a \\nwinner and match details, despite the event not having occurred yet.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': '/content/drive/MyDrive/pdf/Day-7-RAG.pdf', 'total_pages': 17, 'page': 2, 'page_label': '3'}, page_content=\"preencoded.png\\nWhat Exactly is an LLM Hallucination?\\nSounds Confident\\nThe LLM delivers information with conviction, as if it were factual.\\nFactually Incorrect\\nThe generated content is false, misleading, or unsupported by real-world data.\\nCommon Causes:\\n• Missing Knowledge: The LLM's training data doesn't cover the specific information requested.\\n• Ambiguous Prompts: Vague or unclear user queries can lead the model to make assumptions.\"), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': '/content/drive/MyDrive/pdf/Day-7-RAG.pdf', 'total_pages': 17, 'page': 2, 'page_label': '3'}, page_content='• Ambiguous Prompts: Vague or unclear user queries can lead the model to make assumptions.\\n• Over-Generalization: The model applies patterns too broadly, leading to incorrect inferences.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': '/content/drive/MyDrive/pdf/Day-7-RAG.pdf', 'total_pages': 17, 'page': 3, 'page_label': '4'}, page_content=\"preencoded.png\\nWhat Exactly is an LLM Hallucination?\\nSounds Confident\\nThe LLM delivers information with conviction, as if it were factual.\\nFactually Incorrect\\nThe generated content is false, misleading, or unsupported by real-world data.\\nCommon Causes:\\n• Missing Knowledge: The LLM's training data doesn't cover the specific information requested.\\n• Ambiguous Prompts: Vague or unclear user queries can lead the model to make assumptions.\"), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': '/content/drive/MyDrive/pdf/Day-7-RAG.pdf', 'total_pages': 17, 'page': 3, 'page_label': '4'}, page_content='• Ambiguous Prompts: Vague or unclear user queries can lead the model to make assumptions.\\n• Over-Generalization: The model applies patterns too broadly, leading to incorrect inferences.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': '/content/drive/MyDrive/pdf/Day-7-RAG.pdf', 'total_pages': 17, 'page': 4, 'page_label': '5'}, page_content=\"preencoded.png\\nWhat Exactly is an LLM Hallucination?\\nSounds Confident\\nThe LLM delivers information with conviction, as if it were factual.\\nFactually Incorrect\\nThe generated content is false, misleading, or unsupported by real-world data.\\nCommon Causes:\\n• Missing Knowledge: The LLM's training data doesn't cover the specific information requested.\\n• Ambiguous Prompts: Vague or unclear user queries can lead the model to make assumptions.\"), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': '/content/drive/MyDrive/pdf/Day-7-RAG.pdf', 'total_pages': 17, 'page': 4, 'page_label': '5'}, page_content='• Ambiguous Prompts: Vague or unclear user queries can lead the model to make assumptions.\\n• Over-Generalization: The model applies patterns too broadly, leading to incorrect inferences.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': '/content/drive/MyDrive/pdf/Day-7-RAG.pdf', 'total_pages': 17, 'page': 5, 'page_label': '6'}, page_content=\"preencoded.png\\nWhat Exactly is an LLM Hallucination?\\nSounds Confident\\nThe LLM delivers information with conviction, as if it were factual.\\nFactually Incorrect\\nThe generated content is false, misleading, or unsupported by real-world data.\\nCommon Causes:\\n• Missing Knowledge: The LLM's training data doesn't cover the specific information requested.\\n• Ambiguous Prompts: Vague or unclear user queries can lead the model to make assumptions.\"), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': '/content/drive/MyDrive/pdf/Day-7-RAG.pdf', 'total_pages': 17, 'page': 5, 'page_label': '6'}, page_content='• Ambiguous Prompts: Vague or unclear user queries can lead the model to make assumptions.\\n• Over-Generalization: The model applies patterns too broadly, leading to incorrect inferences.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': '/content/drive/MyDrive/pdf/Day-7-RAG.pdf', 'total_pages': 17, 'page': 6, 'page_label': '7'}, page_content=\"preencoded.png\\nWhat Exactly is an LLM Hallucination?\\nSounds Confident\\nThe LLM delivers information with conviction, as if it were factual.\\nFactually Incorrect\\nThe generated content is false, misleading, or unsupported by real-world data.\\nCommon Causes:\\n• Missing Knowledge: The LLM's training data doesn't cover the specific information requested.\\n• Ambiguous Prompts: Vague or unclear user queries can lead the model to make assumptions.\"), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': '/content/drive/MyDrive/pdf/Day-7-RAG.pdf', 'total_pages': 17, 'page': 6, 'page_label': '7'}, page_content='• Ambiguous Prompts: Vague or unclear user queries can lead the model to make assumptions.\\n• Over-Generalization: The model applies patterns too broadly, leading to incorrect inferences.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': '/content/drive/MyDrive/pdf/Day-7-RAG.pdf', 'total_pages': 17, 'page': 7, 'page_label': '8'}, page_content='preencoded.png\\nRAG Architecture: A High-Level Overview\\nRetrieval Augmented Generation combines the strengths of information retrieval with the generative power of LLMs. Here’s how the \\npipeline works:\\n01\\nUser Query\\nThe user submits a question or prompt to the RAG system.\\n02\\nRetrieval from Knowledge Base\\nThe system searches a vast knowledge base (documents, databases) \\nto find relevant context.\\n03\\nContext + Query to LLM\\nThe retrieved context is combined with the original query and sent to'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': '/content/drive/MyDrive/pdf/Day-7-RAG.pdf', 'total_pages': 17, 'page': 7, 'page_label': '8'}, page_content='03\\nContext + Query to LLM\\nThe retrieved context is combined with the original query and sent to \\nthe LLM.\\n04\\nResponse with Citations\\nThe LLM generates a response, referencing the sources from which \\nthe information was retrieved.\\n Retrieval + Generation — This synergistic approach offers the best of both worlds: factual accuracy and fluent, coherent text generation.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': '/content/drive/MyDrive/pdf/Day-7-RAG.pdf', 'total_pages': 17, 'page': 8, 'page_label': '9'}, page_content=\"preencoded.png\\nWhat Exactly is an LLM Hallucination?\\nSounds Confident\\nThe LLM delivers information with conviction, as if it were factual.\\nFactually Incorrect\\nThe generated content is false, misleading, or unsupported by real-world data.\\nCommon Causes:\\n• Missing Knowledge: The LLM's training data doesn't cover the specific information requested.\\n• Ambiguous Prompts: Vague or unclear user queries can lead the model to make assumptions.\"), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': '/content/drive/MyDrive/pdf/Day-7-RAG.pdf', 'total_pages': 17, 'page': 8, 'page_label': '9'}, page_content='• Ambiguous Prompts: Vague or unclear user queries can lead the model to make assumptions.\\n• Over-Generalization: The model applies patterns too broadly, leading to incorrect inferences.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': '/content/drive/MyDrive/pdf/Day-7-RAG.pdf', 'total_pages': 17, 'page': 9, 'page_label': '10'}, page_content='preencoded.png'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': '/content/drive/MyDrive/pdf/Day-7-RAG.pdf', 'total_pages': 17, 'page': 10, 'page_label': '11'}, page_content='preencoded.png\\nWhy We Need Retrieval Augmented Generation (RAG)\\nThe core challenge with traditional LLMs is that their internal parameters are frozen once training is complete. They cannot inherently access \\nnew information in real-time.\\nThe RAG Solution:\\n• Integrates real, up-to-date documents into the generation process.\\n• Provides domain-specific knowledge crucial for specialized applications.\\n• Enables source citations, allowing users to verify information.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': '/content/drive/MyDrive/pdf/Day-7-RAG.pdf', 'total_pages': 17, 'page': 10, 'page_label': '11'}, page_content='• Enables source citations, allowing users to verify information.\\nThe result: The LLM becomes more truthful and grounded in verifiable data, drastically reducing hallucinations.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': '/content/drive/MyDrive/pdf/Day-7-RAG.pdf', 'total_pages': 17, 'page': 11, 'page_label': '12'}, page_content='preencoded.png\\nRAG vs. Fine-Tuning: Choosing the Right Approach\\nWhen enhancing LLM performance, RAG and fine-tuning are two primary strategies. Understanding their differences is key to selecting the \\noptimal solution.\\nFeature RAG Fine-Tuning\\nSpeed Fast deployment & updates Slow (requires retraining)\\nData Size Few documents needed Thousands of examples required\\nCost Low computational cost High computational cost\\nDynamic Updates Very easy to refresh data Requires re-training the model'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': '/content/drive/MyDrive/pdf/Day-7-RAG.pdf', 'total_pages': 17, 'page': 11, 'page_label': '12'}, page_content='Dynamic Updates Very easy to refresh data Requires re-training the model\\nBest Use Private or latest factual data Adapting to new behaviors or styles\\nConclusion: Always consider RAG as your initial strategy before opting for the more resource-intensive fine-tuning process.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': '/content/drive/MyDrive/pdf/Day-7-RAG.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13'}, page_content=\"preencoded.png\\nRAG in the Real World: Practical Applications\\nRAG's ability to provide accurate, up-to-date, and verifiable information makes it indispensable across various industries.\\nEnterprise Chatbots\\nEnhances customer service in \\nbanking and healthcare with \\nprecise information.\\nLegal & Policy Assistants\\nProvides rapid access to legal \\nprecedents and policy \\ndocuments for quick analysis.\\nCode Documentation \\nBots\\nHelps developers navigate \\ncomplex codebases and generate\"), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': '/content/drive/MyDrive/pdf/Day-7-RAG.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13'}, page_content='Code Documentation \\nBots\\nHelps developers navigate \\ncomplex codebases and generate \\naccurate documentation.\\nResearch Assistants\\nExpedites literature reviews and \\ndata synthesis across scientific \\ndomains.\\nKey Takeaway: If an LLM leverages company-specific or proprietary data for its responses, it is almost certainly employing a RAG \\narchitecture.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': '/content/drive/MyDrive/pdf/Day-7-RAG.pdf', 'total_pages': 17, 'page': 13, 'page_label': '14'}, page_content=\"preencoded.png\\nDiverse Retrieval Sources for RAG Systems\\nThe power of RAG lies in its flexibility to integrate knowledge from almost any digital source, transforming raw data into searchable intelligence.\\nPDFs\\nWebsites\\nSQL Databases\\nAPIs\\nSharePoint / Drive\\nEssentially, any form of text-based information can be processed and indexed to become part of the LLM's dynamic knowledge base, enabling robust and relevant responses.\"), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': '/content/drive/MyDrive/pdf/Day-7-RAG.pdf', 'total_pages': 17, 'page': 14, 'page_label': '15'}, page_content=\"preencoded.png\\nWhat Makes a Good RAG System?\\nAn effective RAG system is built on several critical components that ensure accuracy, relevance, and reliability in LLM-generated responses.\\nCorrect & Relevant Retrieval\\nEnsuring the system pulls the most accurate and pertinent information.\\nStructured Chunking\\nBreaking down documents into optimally sized segments for efficient retrieval.\\nTop-k Contextual Grounding\\nSelecting the most relevant 'k' chunks to provide sufficient context to the LLM.\"), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': '/content/drive/MyDrive/pdf/Day-7-RAG.pdf', 'total_pages': 17, 'page': 14, 'page_label': '15'}, page_content=\"Selecting the most relevant 'k' chunks to provide sufficient context to the LLM.\\nCitations + Verifiable Sources\\nProviding clear references to allow users to cross-reference and build trust.\\nHallucination Fallback Strategies\\nImplementing mechanisms to detect and mitigate potential hallucinations.\"), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': '/content/drive/MyDrive/pdf/Day-7-RAG.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16'}, page_content='preencoded.png\\nFixing Hallucinations with \\nRetrieval\\nLet\\'s illustrate the direct impact of retrieval on mitigating LLM hallucinations using a \\nsimple example:\\nLLM-only \\nWhen asked a question beyond its \\ntraining data (e.g., \"What were the latest \\nQ3 earnings for Company X?\"), an LLM \\nwithout retrieval might:\\n• Invent financial figures.\\n• State outdated information.\\n• Generate a plausible but completely \\nfalse report.\\nResult: Hallucinates and provides \\nincorrect information.\\nRetrieval-enabled'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': '/content/drive/MyDrive/pdf/Day-7-RAG.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16'}, page_content='false report.\\nResult: Hallucinates and provides \\nincorrect information.\\nRetrieval-enabled \\nWith retrieval, the same question triggers \\na search across real-time financial reports \\nor company databases. The LLM then:\\n• Accesses the latest Q3 report.\\n• Extracts accurate earnings data.\\n• Cites the source of the information.\\nResult: Provides a correct and verifiable \\nresponse.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': '/content/drive/MyDrive/pdf/Day-7-RAG.pdf', 'total_pages': 17, 'page': 16, 'page_label': '17'}, page_content='preencoded.png\\nWhen RAG Systems Fall Short\\nWhile powerful, RAG systems are not foolproof. Their effectiveness hinges on the quality of their components \\nand implementation.\\nPoor Chunking\\nDocuments are split too broadly or too narrowly, hindering retrieval accuracy.\\nWrong Search Algorithm\\nIneffective algorithms fail to match queries with relevant document sections.\\nMissing Documents\\nCritical information is not included in the knowledge base, leading to gaps.\\nLow-Quality Embeddings'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': '/content/drive/MyDrive/pdf/Day-7-RAG.pdf', 'total_pages': 17, 'page': 16, 'page_label': '17'}, page_content='Critical information is not included in the knowledge base, leading to gaps.\\nLow-Quality Embeddings\\nPoor semantic representation of text leads to inaccurate retrieval matches.\\nUnderstanding these common pitfalls is the first step. We will explore strategies to improve and optimize these \\naspects in our upcoming sessions.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-11T09:05:55+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-11T09:05:55+05:30', 'source': '/content/drive/MyDrive/pdf/Day-10.pdf', 'total_pages': 11, 'page': 0, 'page_label': '1'}, page_content='preencoded.png\\nDay 10\\nVector Databases'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-11T09:05:55+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-11T09:05:55+05:30', 'source': '/content/drive/MyDrive/pdf/Day-10.pdf', 'total_pages': 11, 'page': 1, 'page_label': '2'}, page_content='preencoded.png\\nVector Databases: The Engine of \\nSemantic Search\\nVector databases are specialized tools designed for efficient storage and retrieval of high -\\ndimensional vectors. They are crucial for modern AI applications, particularly in enabling \\nrapid similarity searches that power semantic understanding.\\nPurpose\\nEnable fast similarity searches, \\nmatching queries to relevant data \\npoints.\\nStorage\\nStore embeddings, document chunks, \\nand associated metadata efficiently.\\nPopular Options'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-11T09:05:55+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-11T09:05:55+05:30', 'source': '/content/drive/MyDrive/pdf/Day-10.pdf', 'total_pages': 11, 'page': 1, 'page_label': '2'}, page_content='Storage\\nStore embeddings, document chunks, \\nand associated metadata efficiently.\\nPopular Options\\nIncludes open-source solutions like ChromaDB and FAISS.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-11T09:05:55+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-11T09:05:55+05:30', 'source': '/content/drive/MyDrive/pdf/Day-10.pdf', 'total_pages': 11, 'page': 2, 'page_label': '3'}, page_content='preencoded.png\\nWhy Vector Databases are Essential\\nAt the core of advanced information retrieval, vector databases revolutionize how we interact \\nwith data by enabling semantic search. This process transforms conventional text into a \\nmachine-readable format that captures its meaning.\\nText to Embeddings\\nText is converted into numerical representations called embeddings, which are \\nhigh-dimensional vectors.\\nVector Storage\\nVector databases are optimized to store these embeddings efficiently.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-11T09:05:55+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-11T09:05:55+05:30', 'source': '/content/drive/MyDrive/pdf/Day-10.pdf', 'total_pages': 11, 'page': 2, 'page_label': '3'}, page_content='Vector Storage\\nVector databases are optimized to store these embeddings efficiently.\\nSemantic Search\\nThis storage enables rapid semantic search, allowing retrieval of contextually \\nsimilar information.\\nRAG Enhancement\\nCrucially improves retrieval capabilities for Retrieval Augmented Generation \\n(RAG) systems.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-11T09:05:55+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-11T09:05:55+05:30', 'source': '/content/drive/MyDrive/pdf/Day-10.pdf', 'total_pages': 11, 'page': 3, 'page_label': '4'}, page_content='preencoded.png\\nVector Databases in Retrieval Augmented \\nGeneration (RAG)\\nIn RAG systems, vector databases play a pivotal role in bridging the gap between vast data sources and the \\nprecise contextual needs of Language Models (LLMs).\\n1\\nStores Document Chunks & Embeddings\\nBreaks down long documents into smaller, manageable chunks and stores their vector embeddings.\\n2\\nEnriches with Metadata\\nAttaches crucial metadata like page numbers, source URLs, and author information to each chunk.\\n3'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-11T09:05:55+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-11T09:05:55+05:30', 'source': '/content/drive/MyDrive/pdf/Day-10.pdf', 'total_pages': 11, 'page': 3, 'page_label': '4'}, page_content=\"Attaches crucial metadata like page numbers, source URLs, and author information to each chunk.\\n3\\nEnables Top-K Retrieval\\nAllows for the efficient retrieval of the 'Top-K' most relevant document chunks based on a query.\\n4\\nGrounds LLM Responses\\nConnects retrieved context to the LLM, ensuring responses are accurate and grounded in real data.\"), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-11T09:05:55+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-11T09:05:55+05:30', 'source': '/content/drive/MyDrive/pdf/Day-10.pdf', 'total_pages': 11, 'page': 4, 'page_label': '5'}, page_content=\"preencoded.png\\nLeading Vector Store Solutions\\nThe landscape of vector databases offers diverse options, each suited for different scales and use cases. We'll focus \\non FAISS and Chroma, key players in local development.\\nFAISS Local library Fast indexing & search, ideal for research\\nChromaDB Local + scalable Developer-friendly, persistent storage, easy to use\\nPinecone Cloud managed Large-scale production, fully managed service\"), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-11T09:05:55+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-11T09:05:55+05:30', 'source': '/content/drive/MyDrive/pdf/Day-10.pdf', 'total_pages': 11, 'page': 4, 'page_label': '5'}, page_content=\"Pinecone Cloud managed Large-scale production, fully managed service\\nWeaviate Hybrid search Combines graph & vector search for complex queries\\nToday's focus: FAISS and Chroma for their local and developer-centric advantages.\"), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-11T09:05:55+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-11T09:05:55+05:30', 'source': '/content/drive/MyDrive/pdf/Day-10.pdf', 'total_pages': 11, 'page': 5, 'page_label': '6'}, page_content='preencoded.png\\nFAISS: Facebook AI Similarity \\nSearch\\nDeveloped by Facebook AI Research, FAISS is an open-source library that \\nprovides highly optimized algorithms for efficient similarity search and \\nclustering of dense vectors. It is a cornerstone for many research and \\nprototyping efforts.\\nKey Features:\\n• Optimized for similarity search of \\nlarge datasets.\\n• Leverages GPU support for \\nsignificant speed improvements.\\n• Ideal for rapid prototyping and \\nacademic research.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-11T09:05:55+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-11T09:05:55+05:30', 'source': '/content/drive/MyDrive/pdf/Day-10.pdf', 'total_pages': 11, 'page': 5, 'page_label': '6'}, page_content='significant speed improvements.\\n• Ideal for rapid prototyping and \\nacademic research.\\n• Operates entirely offline, \\nensuring data privacy and local \\ncontrol.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-11T09:05:55+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-11T09:05:55+05:30', 'source': '/content/drive/MyDrive/pdf/Day-10.pdf', 'total_pages': 11, 'page': 6, 'page_label': '7'}, page_content='preencoded.png\\nChroma DB: The AI-Native Open-Source \\nVector Database\\nChroma DB positions itself as a robust, AI-native open-source embedding database designed specifically for \\nbuilding RAG applications. It prioritizes ease of use and local persistence.\\nPurpose-Built for RAG\\nEngineered from the ground up \\nto support Retrieval Augmented \\nGeneration workflows.\\nSimple Python API\\nOffers an intuitive Python API for \\nseamless integration and \\ndevelopment.\\nPersistent Storage\\nEnsures embeddings and'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-11T09:05:55+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-11T09:05:55+05:30', 'source': '/content/drive/MyDrive/pdf/Day-10.pdf', 'total_pages': 11, 'page': 6, 'page_label': '7'}, page_content='seamless integration and \\ndevelopment.\\nPersistent Storage\\nEnsures embeddings and \\nmetadata are saved and \\naccessible across sessions.\\nLocal Operation\\nFunctions entirely locally, eliminating the need for \\nAPI keys or external services.\\nVersatile Storage\\nCapable of storing text chunks, unique IDs, and rich \\nmetadata for each embedding.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-11T09:05:55+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-11T09:05:55+05:30', 'source': '/content/drive/MyDrive/pdf/Day-10.pdf', 'total_pages': 11, 'page': 7, 'page_label': '8'}, page_content=\"preencoded.png\\nOptimizing Retrieval: The Top-K \\nMethod\\nRetrieval methods in vector databases focus on efficiently identifying the most pertinent \\ninformation. The search(query_vector, k) function is central, aiming to retrieve the 'k' most \\nsimilar document chunks.\\nKey Considerations:\\n• Higher 'k': Provides more context to the \\nLLM, potentially leading to richer \\nanswers. However, it can increase \\nprocessing time and introduce noise.\\n• Lower 'k': Offers faster retrieval, but\"), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-11T09:05:55+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-11T09:05:55+05:30', 'source': '/content/drive/MyDrive/pdf/Day-10.pdf', 'total_pages': 11, 'page': 7, 'page_label': '8'}, page_content=\"processing time and introduce noise.\\n• Lower 'k': Offers faster retrieval, but \\ncarries the risk of missing crucial \\ndetails if the most relevant chunks are \\nnot within the top results.\\nThe Trade-Off:\\nChoosing the optimal 'k' involves \\nbalancing the desire for comprehensive \\ncontext with the need for efficient, timely \\nresponses.\"), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-11T09:05:55+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-11T09:05:55+05:30', 'source': '/content/drive/MyDrive/pdf/Day-10.pdf', 'total_pages': 11, 'page': 8, 'page_label': '9'}, page_content='preencoded.png\\nThe Vector Database Workflow: From Text to Insight\\nThe journey of transforming raw text into actionable insights via a vector database follows a systematic, multi-step process. Each stage is crucial \\nfor effective semantic retrieval.\\n01\\nLoad Text\\nIngest raw text data from various sources (documents, web pages, \\netc.).\\n02\\nCreate Chunks\\nBreak down large texts into smaller, semantically meaningful \\nsegments.\\n03\\nGenerate Embeddings'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-11T09:05:55+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-11T09:05:55+05:30', 'source': '/content/drive/MyDrive/pdf/Day-10.pdf', 'total_pages': 11, 'page': 8, 'page_label': '9'}, page_content='Break down large texts into smaller, semantically meaningful \\nsegments.\\n03\\nGenerate Embeddings\\nConvert each text chunk into a high-dimensional vector representation \\nusing an embedding model.\\n04\\nStore in Vector DB\\nPersist these embeddings along with their original text chunks and any \\nassociated metadata.\\n05\\nQuery with Similarity Search\\nPerform a semantic search to find the most relevant chunks based on a \\nquery vector.\\n06\\nUse Results for Applications'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-11T09:05:55+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-11T09:05:55+05:30', 'source': '/content/drive/MyDrive/pdf/Day-10.pdf', 'total_pages': 11, 'page': 8, 'page_label': '9'}, page_content='query vector.\\n06\\nUse Results for Applications\\nIntegrate the retrieved information into downstream applications, such \\nas RAG systems for LLMs.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-11T09:05:55+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-11T09:05:55+05:30', 'source': '/content/drive/MyDrive/pdf/Day-10.pdf', 'total_pages': 11, 'page': 9, 'page_label': '10'}, page_content='preencoded.png\\nChallenges in Vector Search\\nWhile powerful, vector search systems are not without their limitations. Understanding these challenges is key to building mo re \\nrobust and reliable RAG applications.\\nIrrelevant Chunk Retrieval\\nDespite semantic similarity, vector \\nsearch can sometimes return \\nchunks that are contextually \\nirrelevant to the query.\\nScaling Performance\\nAs the dataset and the index grow, \\nretrieval times can increase, \\nimpacting system responsiveness.\\nRedundancy & Overlap'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-11T09:05:55+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-11T09:05:55+05:30', 'source': '/content/drive/MyDrive/pdf/Day-10.pdf', 'total_pages': 11, 'page': 9, 'page_label': '10'}, page_content='retrieval times can increase, \\nimpacting system responsiveness.\\nRedundancy & Overlap\\nTo ensure comprehensive context, \\nmaintaining some level of \\nredundancy or overlapping chunks \\nin the database is often necessary, \\nwhich can increase storage needs.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-11T09:05:55+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-11T09:05:55+05:30', 'source': '/content/drive/MyDrive/pdf/Day-10.pdf', 'total_pages': 11, 'page': 10, 'page_label': '11'}, page_content='preencoded.png\\nKey Takeaways: The Power of \\nVector Databases\\nVector databases are transformative technologies, enabling AI systems to \\nunderstand and retrieve information based on meaning, rather than just keywords. \\nThey are fundamental to the next generation of intelligent applications.\\nSemantic Retrieval\\nCore to finding data based on meaning, not just keywords.\\nFAISS: Fast & Research-Friendly\\nExcellent for rapid prototyping and high-speed similarity searches.\\nChroma: Feature-Rich & Persistent'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-11T09:05:55+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-11T09:05:55+05:30', 'source': '/content/drive/MyDrive/pdf/Day-10.pdf', 'total_pages': 11, 'page': 10, 'page_label': '11'}, page_content='Chroma: Feature-Rich & Persistent\\nDesigned for RAG, offering easy integration and data persistence.\\nRAG System Core Component\\nIndispensable for building robust Retrieval Augmented Generation systems.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-11T09:06:22+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-11T09:06:22+05:30', 'source': '/content/drive/MyDrive/pdf/Day-9.pdf', 'total_pages': 13, 'page': 0, 'page_label': '1'}, page_content='preencoded.png\\nDay 9 \\nEmbeddings: Representing Meaning in Vector \\nSpace(Foundations for Semantic Search & RAG)'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-11T09:06:22+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-11T09:06:22+05:30', 'source': '/content/drive/MyDrive/pdf/Day-9.pdf', 'total_pages': 13, 'page': 1, 'page_label': '2'}, page_content=\"preencoded.png\\nThe Power of Embeddings: \\nUnlocking Semantic \\nUnderstanding\\nWelcome to a journey into the fascinating world of embeddings, a \\ncore technology driving the latest advancements in AI and natural \\nlanguage processing. In this presentation, we'll explore how these \\nnumerical representations enable machines to understand and \\nprocess human language with unprecedented accuracy, \\ntransforming applications from semantic search to advanced AI \\nsystems.\"), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-11T09:06:22+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-11T09:06:22+05:30', 'source': '/content/drive/MyDrive/pdf/Day-9.pdf', 'total_pages': 13, 'page': 2, 'page_label': '3'}, page_content=\"preencoded.png\\nWhy Text Needs Vector Representation\\nMachines Don't Speak Human\\nRaw text, with its nuances and \\ncomplexities, is incomprehensible to \\nmachines. They operate in the realm of \\nnumbers and logic.\\nNumerical Translation\\nTo unlock meaning, text must be \\nconverted into a numerical format. This \\ntransformation is fundamental for any \\nanalytical task.\\nEnabling Advanced Search\\nNumerical representations power \\nsophisticated functions like semantic \\nsearch, allowing for meaning-based\"), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-11T09:06:22+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-11T09:06:22+05:30', 'source': '/content/drive/MyDrive/pdf/Day-9.pdf', 'total_pages': 13, 'page': 2, 'page_label': '3'}, page_content='sophisticated functions like semantic \\nsearch, allowing for meaning-based \\nretrieval rather than just keyword \\nmatching.\\nClustering and Insights\\nBy representing text as vectors, we can group similar concepts, \\ndiscover hidden relationships, and extract valuable insights from \\nvast datasets.\\nFueling LLMs\\nEmbeddings are critical for Retrieval-Augmented Generation \\n(RAG) systems, providing Large Language Models (LLMs) with \\nrelevant context to generate more accurate and informed \\nresponses.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-11T09:06:22+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-11T09:06:22+05:30', 'source': '/content/drive/MyDrive/pdf/Day-9.pdf', 'total_pages': 13, 'page': 3, 'page_label': '4'}, page_content='preencoded.png\\nWhat Are Embeddings?\\nEmbeddings are high-dimensional dense vector representations of \\ntext, words, or even entire documents. Think of them as numerical \\nfingerprints that capture the semantic meaning and contextual \\nrelationships of the input.\\nIn this semantic space, text snippets with similar meanings are \\nmapped to vectors that are numerically \"closer\" to each other. \\nConversely, text with vastly different meanings will have vectors \\nthat are \"far apart.\"'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-11T09:06:22+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-11T09:06:22+05:30', 'source': '/content/drive/MyDrive/pdf/Day-9.pdf', 'total_pages': 13, 'page': 3, 'page_label': '4'}, page_content='Conversely, text with vastly different meanings will have vectors \\nthat are \"far apart.\"\\nExample: The embedding for \"King\" would be numerically close \\nto \"Queen\" but significantly distant from \"Table\", reflecting their \\nconceptual relationship.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-11T09:06:22+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-11T09:06:22+05:30', 'source': '/content/drive/MyDrive/pdf/Day-9.pdf', 'total_pages': 13, 'page': 4, 'page_label': '5'}, page_content='preencoded.png\\nEmbedding Dimensions: The Depth of Meaning\\nWhen a sentence or word is embedded, it transforms into a \\nvector of numbers. This vector\\'s length, or \"dimension,\" \\ndetermines how much context and nuance the embedding can \\ncapture.\\nExample of a vector representation: [0.23, -1.12, 0.87, 1.54, \\n..., 0.76]. Each number in the vector represents a feature or \\nattribute of the original text\\'s meaning.\\nHigher dimensions (e.g., 768 or 1536) allow for richer, more'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-11T09:06:22+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-11T09:06:22+05:30', 'source': '/content/drive/MyDrive/pdf/Day-9.pdf', 'total_pages': 13, 'page': 4, 'page_label': '5'}, page_content='Higher dimensions (e.g., 768 or 1536) allow for richer, more \\ndetailed contextual representation, enabling the model to \\ndistinguish between subtle semantic differences. However, this \\ncomes with a trade-off:\\n• Accuracy: Higher dimensions generally lead to better \\nsemantic capture.\\n• Speed: Processing and comparing higher-dimensional \\nvectors can be slower.\\n• Storage: Larger vectors require more memory and disk space.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-11T09:06:22+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-11T09:06:22+05:30', 'source': '/content/drive/MyDrive/pdf/Day-9.pdf', 'total_pages': 13, 'page': 5, 'page_label': '6'}, page_content='preencoded.png\\nIntuition Behind Semantic Space\\nImagine a multi-dimensional space where words and phrases are not just random points, but are meticulously arranged \\nbased on their relationships and meanings. This is the semantic space that embeddings create.\\nKing - Man + Woman ≈ Queen\\nThis famous analogy demonstrates how \\nsemantic relationships are preserved in the \\nvector space, allowing for vector arithmetic \\nto reveal new meanings.\\nGeographic Proximity'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-11T09:06:22+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-11T09:06:22+05:30', 'source': '/content/drive/MyDrive/pdf/Day-9.pdf', 'total_pages': 13, 'page': 5, 'page_label': '6'}, page_content='vector space, allowing for vector arithmetic \\nto reveal new meanings.\\nGeographic Proximity\\nCountries with similar geopolitical contexts \\nor cultural ties tend to be closer in this \\nspace.\\nClustering Topics\\nAll documents related to \"sports\" will \\nnaturally cluster together, distinct from \\n\"education\" or \"finance.\"\\nContextual Awareness\\nThe same word can have different \\nembeddings depending on its surrounding \\ncontext within a sentence.\\nEmergent Relationships\\nThe semantic space can reveal'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-11T09:06:22+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-11T09:06:22+05:30', 'source': '/content/drive/MyDrive/pdf/Day-9.pdf', 'total_pages': 13, 'page': 5, 'page_label': '6'}, page_content='context within a sentence.\\nEmergent Relationships\\nThe semantic space can reveal \\nunexpected connections between \\nconcepts, leading to new insights and \\ndiscovery.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-11T09:06:22+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-11T09:06:22+05:30', 'source': '/content/drive/MyDrive/pdf/Day-9.pdf', 'total_pages': 13, 'page': 6, 'page_label': '7'}, page_content=\"preencoded.png\\nCosine Similarity: The Measure of Relatedness\\nWhen comparing two embeddings, we don't use Euclidean distance (straight-line distance) because it doesn't perform well in high-dimensional spaces. \\nInstead, we use Cosine Similarity, which measures the angle between two vectors.\\n• Angle, Not Distance: Cosine similarity focuses on the orientation of \\nvectors, indicating how similar their directions are, rather than their \\nmagnitude.\\n• Scale:\"), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-11T09:06:22+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-11T09:06:22+05:30', 'source': '/content/drive/MyDrive/pdf/Day-9.pdf', 'total_pages': 13, 'page': 6, 'page_label': '7'}, page_content=\"vectors, indicating how similar their directions are, rather than their \\nmagnitude.\\n• Scale:\\n• +1: Indicates vectors pointing in exactly the same direction, \\nmeaning strong semantic similarity .\\n• 0: Indicates vectors at a 90-degree angle, suggesting no linear \\nrelationship or semantic relation.\\n• -1: Indicates vectors pointing in opposite directions, meaning \\nopposite semantic meaning .\\n• Why it's preferred: In high-dimensional spaces, words with similar\"), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-11T09:06:22+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-11T09:06:22+05:30', 'source': '/content/drive/MyDrive/pdf/Day-9.pdf', 'total_pages': 13, 'page': 6, 'page_label': '7'}, page_content=\"opposite semantic meaning .\\n• Why it's preferred: In high-dimensional spaces, words with similar \\nmeanings might be far apart in Euclidean distance but still have a \\nsmall angle between them. Cosine similarity effectively captures this \\nsemantic closeness.\"), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-11T09:06:22+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-11T09:06:22+05:30', 'source': '/content/drive/MyDrive/pdf/Day-9.pdf', 'total_pages': 13, 'page': 7, 'page_label': '8'}, page_content='preencoded.png'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-11T09:06:22+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-11T09:06:22+05:30', 'source': '/content/drive/MyDrive/pdf/Day-9.pdf', 'total_pages': 13, 'page': 8, 'page_label': '9'}, page_content='preencoded.png\\nEmbeddings for Long Text: The Chunking Strategy\\nWhile embeddings excel at capturing meaning, processing extremely long documents (like entire books or research papers) can be \\ncomputationally intensive and dilute contextual nuances. The solution involves a strategic approach called chunking.\\n01\\nDivide and Conquer\\nLong documents are first broken down into smaller, manageable \\nsegments or \"chunks.\" These chunks can be paragraphs, \\nsentences, or fixed-size blocks of text.\\n02'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-11T09:06:22+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-11T09:06:22+05:30', 'source': '/content/drive/MyDrive/pdf/Day-9.pdf', 'total_pages': 13, 'page': 8, 'page_label': '9'}, page_content='segments or \"chunks.\" These chunks can be paragraphs, \\nsentences, or fixed-size blocks of text.\\n02\\nIndependent Embedding\\nEach of these individual chunks is then independently converted \\ninto its own embedding vector. This ensures that the local context \\nof each segment is accurately captured.\\n03\\nEnhanced Search\\nBy embedding chunks, we can perform highly granular searches. \\nWhen a query comes in, we search for the most relevant chunks,'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-11T09:06:22+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-11T09:06:22+05:30', 'source': '/content/drive/MyDrive/pdf/Day-9.pdf', 'total_pages': 13, 'page': 8, 'page_label': '9'}, page_content='When a query comes in, we search for the most relevant chunks, \\nnot just the entire document, leading to more precise results.\\n04\\nScalability\\nThis method is crucial for building scalable retrieval systems \\nacross vast knowledge bases, allowing for efficient processing and \\nindexing of large text corpora.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-11T09:06:22+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-11T09:06:22+05:30', 'source': '/content/drive/MyDrive/pdf/Day-9.pdf', 'total_pages': 13, 'page': 9, 'page_label': '10'}, page_content='preencoded.png\\nEmbeddings + Vector Databases: The Retrieval Engine\\nOnce text is converted into embeddings, we need an efficient way to store, index, and query these high-dimensional vectors. This is where \\nVector Databases come into play, forming the backbone of modern semantic search.\\nIndexing Embeddings\\nVector databases are optimized to store and index embedding \\nvectors, enabling lightning-fast similarity lookups among \\nmillions or billions of vectors.\\nFast Similarity Search'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-11T09:06:22+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-11T09:06:22+05:30', 'source': '/content/drive/MyDrive/pdf/Day-9.pdf', 'total_pages': 13, 'page': 9, 'page_label': '10'}, page_content='millions or billions of vectors.\\nFast Similarity Search\\nWhen a user submits a query (also converted into an \\nembedding), the vector database quickly finds the most \\nsemantically similar text chunks or documents.\\nTop-K Retrieval\\nThey enable \"top-k\" retrieval, returning the \\'k\\' most relevant \\nresults, making them ideal for recommendation systems, \\nquestion-answering, and contextual grounding.\\nPopular Open-Source Options\\nFrameworks like FAISS (Facebook AI Similarity Search) and'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-11T09:06:22+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-11T09:06:22+05:30', 'source': '/content/drive/MyDrive/pdf/Day-9.pdf', 'total_pages': 13, 'page': 9, 'page_label': '10'}, page_content='Popular Open-Source Options\\nFrameworks like FAISS (Facebook AI Similarity Search) and \\nChroma DB are widely used for building robust vector search \\ncapabilities.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-11T09:06:22+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-11T09:06:22+05:30', 'source': '/content/drive/MyDrive/pdf/Day-9.pdf', 'total_pages': 13, 'page': 10, 'page_label': '11'}, page_content=\"preencoded.png\\nEmbeddings: The Core of Retrieval-Augmented Generation (RAG)\\nEmbeddings are the central nervous system of Retrieval-Augmented Generation (RAG) systems, significantly enhancing the capabilities of Large Language Models (LLMs).\\n1 1. Chunking\\nBreaking down vast knowledge bases into digestible text segments.\\n2 2. Embedding\\nConverting each chunk into a numerical vector representation.\\n3 3. Similarity Search\\nFinding the most relevant embedded chunks to a user's query.\"), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-11T09:06:22+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-11T09:06:22+05:30', 'source': '/content/drive/MyDrive/pdf/Day-9.pdf', 'total_pages': 13, 'page': 10, 'page_label': '11'}, page_content=\"3 3. Similarity Search\\nFinding the most relevant embedded chunks to a user's query.\\n4 4. Context Injection\\nFeeding these relevant chunks as context to the LLM.\\n5 5. LLM Answer\\nEnabling the LLM to generate accurate, informed, and grounded responses.\\nBy grounding LLM responses in external, up-to-date knowledge bases, embeddings help reduce hallucination and produce more reliable outputs, critical for enterprise AI \\napplications.\"), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-11T09:06:22+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-11T09:06:22+05:30', 'source': '/content/drive/MyDrive/pdf/Day-9.pdf', 'total_pages': 13, 'page': 11, 'page_label': '12'}, page_content='preencoded.png\\nChoosing the Right Embedding Model\\nSelecting the optimal embedding model is crucial for the performance and efficiency of your semantic search or RAG system. Consider these key \\nfactors:\\nQuality\\nEvaluate how well the model captures semantic meaning for your \\nspecific domain and use case. Higher quality often means better \\nretrieval accuracy.\\nSpeed\\nConsider the inference speed for embedding new data and querying. \\nFaster models are essential for real-time applications.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-11T09:06:22+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-11T09:06:22+05:30', 'source': '/content/drive/MyDrive/pdf/Day-9.pdf', 'total_pages': 13, 'page': 11, 'page_label': '12'}, page_content=\"Faster models are essential for real-time applications.\\nDimension Size\\nHigher dimensions capture more context but increase computational \\nand storage costs. Find a balance that suits your needs.\\nLicense & Cost\\nCheck the model's licensing terms and any associated costs, \\nespecially for commercial use or deployment at scale.\\nPopular and Free Option: For many applications, sentence-transformers/all-MiniLM-L6-v2 offers a great balance of performance and\"), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-11T09:06:22+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-11T09:06:22+05:30', 'source': '/content/drive/MyDrive/pdf/Day-9.pdf', 'total_pages': 13, 'page': 11, 'page_label': '12'}, page_content='efficiency, making it a highly recommended starting point.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-11T09:06:22+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-11T09:06:22+05:30', 'source': '/content/drive/MyDrive/pdf/Day-9.pdf', 'total_pages': 13, 'page': 12, 'page_label': '13'}, page_content='preencoded.png\\nSummary\\n• Embeddings convert text → meaningful vectors\\n• Semantic similarity enables intelligent retrieval\\n• Foundation of RAG systems and modern search\\n• Better embeddings → better accuracy, fewer hallucinations')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Creating embeddings... this may take a moment.\")\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545,
          "referenced_widgets": [
            "1a4ae28f6c19450d882e47f73e05c704",
            "d79cf11d24084fbdb7bdef40a676b06c",
            "87981dc0d8b54579b8000f83c0189673",
            "cf887194bb2048d09937bf3957dc8f32",
            "6648f1bfc4ad44ad882e2b9b1a332833",
            "0c4484bdc36744b3867e839161444629",
            "4e7687c272dc4dc8811dce7b1456a226",
            "8758fbedab7d4726a99b32e5603e3a05",
            "9feaef9bb67e4914b3cd49260b70f23d",
            "2a30dbbc68d54b5080087c8e3a4e4e8a",
            "e85ebcd8de214590a9e7c84e7d1e04f7",
            "8f7404363d474e52827ce7895dc602ce",
            "de8000d52e0a43b58792e30c70daa211",
            "df9ae781076a4db1b45086ba5d8a98db",
            "42162e3c0ea54ce39beb913ed79f5847",
            "c07b785cf7f8476fb0aaad22a6415fdf",
            "154451f0989f49a78b6190bb4b6882a8",
            "6a379ef45e5a48eba4593a3d4ad77041",
            "9309a642a2a244a593cf1946267563c6",
            "612b3bb969024b0cb542e12da550ea3d",
            "3d05439739bd45dba2ae1cb95efebc37",
            "77aea7fd3a4a4fe7aeb119ec4aa5fe30",
            "986bc2a56703421ebbff68afebf05f8a",
            "170b80103869458994cfef551c240feb",
            "5d9fe05845e24d5fa55dc34186f91237",
            "7686eb60dc744deb8ddd448689f42d06",
            "4c368b321003407db6190390ca05b378",
            "11a7d5ddd8934a9bac85777f01b6fff9",
            "2f752923874347398e26fdb95debb05f",
            "46023a651a004868a9225eb187b506c7",
            "0de7164d51564d3faf35dc1d58502424",
            "5cbf173bae72461bbb7de68aa840c289",
            "3043448dd2e14e2799bdadb8eb759960",
            "87c355185b45469aaf7887e1eef73b08",
            "f9436dacee8d4cd18b3d79c41fa1c807",
            "d53905bac8804e4492b493edf52bded6",
            "26f31ddbdae542028dbf4ce059ef7a60",
            "6904fa7ed1bf423eac26a242320e0fe9",
            "7017464ddd024884800093e9e98d82fa",
            "742da65c40b44993b35800aaf0ce602d",
            "5807ad6c003b4ea89f5f2e80421a76e7",
            "77e1d46e624347118023b4d8426a3f2c",
            "99b60c8910674ea793ef48db88dc3a2f",
            "262868e9b02b41d2ad0160535d699d73",
            "6f224abbb1c04013810652d39e50ab64",
            "0f55279ebc474c07b3f55cbdee800715",
            "19d8f0a11e9a48cbbcd2f27b87bb78a4",
            "8918f01c16264a7ea34c88008e952b8b",
            "013ce602481f4faea177f0a5caced5ba",
            "e626ed0506744f718e7ac08b34e72b66",
            "a94a428c37454da08587532e2a36fbbb",
            "f99b96c64e084e4883601f13f7d1b70d",
            "43c50f56e80a4520b7b41db71948545b",
            "f7e6e78930844cea89428aa4b2ba67a2",
            "8ea614f93a304d31861372d1f0c63996",
            "72351f110b1c4d0a84313f094783975c",
            "80d0d803275f4cd495e5d3f5e752bd1d",
            "cd9244bfa1e94e05b6de87bea90aeab5",
            "c7b9af97fdf34a2082b2c90e9cfca8eb",
            "68d345b659964460b1963b4d9e42ca49",
            "3eb3737ad1f2499580a53623506cb320",
            "6a10ce05d0ae4568aef6776d1449096e",
            "ebc49181a1a44f69a57b12657cc96579",
            "c5bcc73aba2e452a86c823140f9bf1c7",
            "70ad14fd7bde4eca8f8586e6ffa2f955",
            "57b8059bcc0a415c80d3d32671d844de",
            "0925c51de38444f0a12e63cf14ed6fd5",
            "c71c3b3044bf48b88079abb640091c7d",
            "a397a772d92d4cfeb6d89bb7020cd258",
            "4299ee4fa06b48dc809aa167c5ade670",
            "0a8d4f0cc3684e43aefda5a13db212cf",
            "59077d9d349c4e8594c1aef660ef9dc7",
            "c41e1e21741d4b8db3825695697f0f6f",
            "27374921278046c3b75b0acc331a2407",
            "83c14accea134a33849225abe9af8ceb",
            "ce9c63498c174f31870fa578d39fcae1",
            "a8d1cd079a4441b78a5f48d899ec2280",
            "487564842a074a2eb992a070c0f16e02",
            "f6d4c3c7128f4afcac6aa49146a06cad",
            "5a40d3e9e4574e5b996494d3e7dedf52",
            "1a39df0e8672479198f193c1838f3e51",
            "1499a9d070df4d7e96c2cca287629c3a",
            "0d65ccd220d14e19a401e5cfa0630939",
            "ff3b82fdbb7d48dcab15cde8a3e29832",
            "56585b3b6e5948fbbdaa0cb29416caf4",
            "6c668cd5af8c45d58288f51f465d09f8",
            "d171213fd18c47ccb06f314f80ee061d",
            "d0356541624443cfa5b2e2b34ff097ee",
            "fbfcf731639d474f86209905939b5aac",
            "6511c4969a794e98b579974144351144",
            "d6f0108fcedf4e0b8e45e8a6dc798be7",
            "c1b99b3957d34a5e8d3130e10b3480a5",
            "d8ac1ef2a6604254801b85e210d45488",
            "a2ad6b1c63b14381bf73062af2905775",
            "5a2b3787ea0e4416808b03560bd866c0",
            "c5dc522205c749959e18412f6ac93516",
            "ffe5e81e7a05414aa77dd15a7d10d19e",
            "d02b7d73e75043fbbc33214ea4af4e51",
            "763550291f8645b6a53a2a650e1b493a",
            "576fd1d199e34074a1290b0f36332a24",
            "68d0a62b671643618b6a718ce3451f64",
            "5f1fe47181544f3788983551cbb2a190",
            "4d0dd3e980d74860b98cf61f38458b84",
            "232b15daa94d49989731c5e2ac35e9e4",
            "dcd7bdc046534ff0a97b78027bab1475",
            "91cf3dd491a9420cb5f1e24c276b6f1c",
            "098ea265e0cf4f9daf1c224b27410e11",
            "e70d15740e0a45caabf60f152629f3d2",
            "2cc09ddb60ff492aaca47c282e695e6e",
            "1b8e6caf82a942789f74c2fc612fc3b4",
            "22d08bb26b284c8ab40c6dd57341244c",
            "9729de70dee84f12b68a3b5e1b239641",
            "409cb5d5799740cbb5745f6f74aeb9c9",
            "2d619012733d470bac42f1b104493c27",
            "56cd5ed0c3954d0c9217483e9741551c",
            "9e0a2142a3074e3e9fbb907c92a08d98",
            "e1339b3db34f42248128e711125b24db",
            "c98dfdaada1d402b917bbeec711533e4",
            "80d37c70fe6a4497918e4f2f38eeed67",
            "ce1fe69e6d0944a98b23db158909646a",
            "c05794924c5941e2b25eb2b11a40de3d"
          ]
        },
        "id": "8AF6nWYTE7p-",
        "outputId": "3d0b4a1f-a274-490f-e587-09897bc771c4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating embeddings... this may take a moment.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-216116326.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1a4ae28f6c19450d882e47f73e05c704"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8f7404363d474e52827ce7895dc602ce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "986bc2a56703421ebbff68afebf05f8a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "87c355185b45469aaf7887e1eef73b08"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6f224abbb1c04013810652d39e50ab64"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "72351f110b1c4d0a84313f094783975c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0925c51de38444f0a12e63cf14ed6fd5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "487564842a074a2eb992a070c0f16e02"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fbfcf731639d474f86209905939b5aac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "576fd1d199e34074a1290b0f36332a24"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "22d08bb26b284c8ab40c6dd57341244c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "if not os.getenv(\"MISTRAL_API_KEY\"):\n",
        "    os.environ[\"MISTRAL_API_KEY\"] = getpass(\"Enter your Mistral API Key: \")"
      ],
      "metadata": {
        "id": "-_IGOcMiTHMR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a6e102c-eabf-41b8-9c41-7590b7d9613d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Mistral API Key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "if not os.path.exists(\"db_chroma\"):\n",
        "  os.mkdir(\"db_chroma\")\n",
        "vectorstore = Chroma.from_documents(documents=chunks, embedding=embeddings, persist_directory=\"db_chroma\")\n",
        "print(vectorstore)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1up748pKJVd",
        "outputId": "ab99ef50-be75-4c89-eed4-6909499dff2f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<langchain_community.vectorstores.chroma.Chroma object at 0x7b9894897350>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  retriving the top 5 context that are related\n"
      ],
      "metadata": {
        "id": "RYRGfs_9NoYs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retrival=vectorstore.as_retriever(search_kwargs={\"k\": 1})"
      ],
      "metadata": {
        "id": "_OaxjZtcMqEB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_mistralai import ChatMistralAI\n",
        "\n",
        "llm = ChatMistralAI(model=\"mistral-tiny\")"
      ],
      "metadata": {
        "id": "k66uMYbdNmcJ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import chain\n",
        "from langchain_core import prompts\n",
        "from langchain_classic.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_classic.chains import create_retrieval_chain\n",
        "\n",
        "# creating the prompt template\n",
        "prompt = prompts.ChatPromptTemplate.from_template(\"\"\"\n",
        "    Answer the question based only on the following context:\n",
        "    <context>\n",
        "    {context}\n",
        "    </context>\n",
        "\n",
        "    Question: {input}\n",
        "    \"\"\")\n",
        "\n",
        "# pass prompt to llm\n",
        "chain_doc = create_stuff_documents_chain(llm, prompt)\n",
        "\n",
        "#inject context on prompt and llm chained object\n",
        "_rag_chain = create_retrieval_chain(retrival, chain_doc)\n",
        "\n"
      ],
      "metadata": {
        "id": "MFs0yDJOO003"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions = [\n",
        "    # Prompt Engineering (1–20)\n",
        "    \"What is prompt engineering and why is it important for LLMs?\",\n",
        "    \"What is the difference between instruction prompting and completion prompting?\",\n",
        "    \"What are zero-shot, one-shot, and few-shot prompts?\",\n",
        "    \"How does prompt structure affect model output quality?\",\n",
        "    \"What is role prompting and how does it work?\",\n",
        "    \"What is chain-of-thought prompting?\",\n",
        "    \"Why can chain-of-thought improve reasoning tasks?\",\n",
        "    \"What is self-consistency prompting?\",\n",
        "    \"What are prompt templates?\",\n",
        "    \"What is prompt leakage?\",\n",
        "    \"How do system prompts differ from user prompts?\",\n",
        "    \"What is prompt injection?\",\n",
        "    \"How can prompt injection be mitigated?\",\n",
        "    \"What is instruction hierarchy in prompts?\",\n",
        "    \"What are delimiters used for in prompts?\",\n",
        "    \"What is context window and why does it matter?\",\n",
        "    \"What happens when prompts exceed context length?\",\n",
        "    \"How do temperature and top-p affect prompt outputs?\",\n",
        "    \"What are common prompt engineering anti-patterns?\",\n",
        "    \"How do you evaluate prompt effectiveness?\",\n",
        "\n",
        "    # Embeddings (21–40)\n",
        "    \"What are embeddings in LLM systems?\",\n",
        "    \"How are embeddings different from tokens?\",\n",
        "    \"What does cosine similarity measure?\",\n",
        "    \"What is the difference between cosine similarity and Euclidean distance?\",\n",
        "    \"Why are embeddings high-dimensional?\",\n",
        "    \"What does semantic similarity mean?\",\n",
        "    \"How are embeddings generated?\",\n",
        "    \"Why are embeddings model-specific?\",\n",
        "    \"What happens if you mix embeddings from different models?\",\n",
        "    \"What is embedding normalization?\",\n",
        "    \"Why do we normalize vectors?\",\n",
        "    \"What is vector dimensionality?\",\n",
        "    \"How does chunk size affect embeddings?\",\n",
        "    \"What is embedding drift?\",\n",
        "    \"How do embeddings help semantic search?\",\n",
        "    \"What is embedding recall vs precision?\",\n",
        "    \"Why are embeddings better than keyword search?\",\n",
        "    \"How do embeddings handle synonyms?\",\n",
        "    \"What are multilingual embeddings?\",\n",
        "    \"What are the limitations of embeddings?\",\n",
        "\n",
        "    # Chunking (41–55)\n",
        "    \"What is chunking in RAG systems?\",\n",
        "    \"Why is chunking necessary?\",\n",
        "    \"What is fixed-size chunking?\",\n",
        "    \"What is semantic chunking?\",\n",
        "    \"What is sliding window chunking?\",\n",
        "    \"What is overlap (lap size) in chunking?\",\n",
        "    \"Why is overlap important?\",\n",
        "    \"What happens if overlap is zero?\",\n",
        "    \"What are optimal chunk sizes for text documents?\",\n",
        "    \"What are optimal chunk sizes for code?\",\n",
        "    \"How does chunking affect retrieval accuracy?\",\n",
        "    \"What is token-aware chunking?\",\n",
        "    \"How do headings affect chunking?\",\n",
        "    \"What is hierarchical chunking?\",\n",
        "    \"What are common chunking mistakes?\",\n",
        "\n",
        "    # RAG (56–75)\n",
        "    \"What is RAG and why is it used?\",\n",
        "    \"What problems does RAG solve?\",\n",
        "    \"What are the main components of a RAG pipeline?\",\n",
        "    \"How does retrieval differ from generation?\",\n",
        "    \"What is retrieval recall?\",\n",
        "    \"What is retrieval precision?\",\n",
        "    \"What happens if retrieval returns irrelevant chunks?\",\n",
        "    \"What is top-k retrieval?\",\n",
        "    \"What is hybrid search?\",\n",
        "    \"What is the difference between dense search and sparse search?\",\n",
        "    \"What is BM25?\",\n",
        "    \"Why combine keyword search with vector search?\",\n",
        "    \"What is context stuffing?\",\n",
        "    \"How many chunks should be passed to the LLM?\",\n",
        "    \"What is re-ranking in RAG?\",\n",
        "    \"What is cross-encoder re-ranking?\",\n",
        "    \"What is latency trade-off in RAG?\",\n",
        "    \"What is hallucination in RAG?\",\n",
        "    \"How does RAG reduce hallucination?\",\n",
        "    \"When should you not use RAG?\",\n",
        "\n",
        "    # Vector Databases (76–90)\n",
        "    \"What is a vector database?\",\n",
        "    \"How is a vector database different from SQL databases?\",\n",
        "    \"What is an Approximate Nearest Neighbor (ANN) search?\",\n",
        "    \"What is HNSW indexing?\",\n",
        "    \"What is FAISS?\",\n",
        "    \"What is Milvus?\",\n",
        "    \"What is Pinecone?\",\n",
        "    \"What is Qdrant?\",\n",
        "    \"What is indexing versus searching?\",\n",
        "    \"What is metadata filtering?\",\n",
        "    \"How does vector compression work?\",\n",
        "    \"What is the latency versus accuracy trade-off?\",\n",
        "    \"How does sharding work in vector databases?\",\n",
        "    \"What happens when a vector database grows very large?\",\n",
        "    \"How do you update or delete vectors?\",\n",
        "\n",
        "    # Production & Evaluation (91–100)\n",
        "    \"How do you evaluate a RAG system?\",\n",
        "    \"What is end-to-end RAG evaluation?\",\n",
        "    \"What are RAG evaluation metrics?\",\n",
        "    \"How do you test retrieval quality?\",\n",
        "    \"How do you prevent data leakage in RAG?\",\n",
        "    \"What is grounding in LLM responses?\",\n",
        "    \"How do you log and monitor RAG systems?\",\n",
        "    \"What are common RAG failure modes?\",\n",
        "    \"How do you optimize RAG cost?\",\n",
        "    \"How would you design a scalable RAG system?\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "-sLdeCM2CIVh"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_set={\n",
        "    \"questions\":[],\n",
        "    \"answers\":[]\n",
        "          }\n",
        "for question in questions:\n",
        "  data_set[\"questions\"].append(question)\n",
        "  answer = _rag_chain.invoke({\"input\":question})\n",
        "  data_set[\"answers\"].append(answer[\"answer\"])\n",
        "\n",
        "\n",
        "# response=_rag_chain.invoke({\"input\":user_query})\n",
        "# print(response)\n",
        "# print(response[\"answer\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "B1wm0aIvPQv7",
        "outputId": "289aff86-175e-42a6-d095-0ed8d1907bdb"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "HTTPStatusError",
          "evalue": "Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"object\":\"error\",\"message\":\"Rate limit exceeded\",\"type\":\"rate_limited\",\"param\":null,\"code\":\"1300\"}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPStatusError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-904521737.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mquestion\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mquestions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mdata_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"questions\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_rag_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"input\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0mdata_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"answers\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"answer\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5546\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5547\u001b[0m     ) -> Output:\n\u001b[0;32m-> 5548\u001b[0;31m         return self.bound.invoke(\n\u001b[0m\u001b[1;32m   5549\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5550\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_configs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3141\u001b[0m                         \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3142\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3143\u001b[0;31m                         \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3144\u001b[0m         \u001b[0;31m# finish the root run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3145\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/passthrough.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m     ) -> dict[str, Any]:\n\u001b[0;32m--> 507\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_with_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     async def _ainvoke(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_call_with_config\u001b[0;34m(self, func, input_, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[1;32m   2056\u001b[0m                 output = cast(\n\u001b[1;32m   2057\u001b[0m                     \u001b[0;34m\"Output\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2058\u001b[0;31m                     context.run(\n\u001b[0m\u001b[1;32m   2059\u001b[0m                         \u001b[0mcall_func_with_variable_args\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2060\u001b[0m                         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/config.py\u001b[0m in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0maccepts_run_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/passthrough.py\u001b[0m in \u001b[0;36m_invoke\u001b[0;34m(self, value, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m         return {\n\u001b[1;32m    492\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             **self.mapper.invoke(\n\u001b[0m\u001b[1;32m    494\u001b[0m                 \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m                 \u001b[0mpatch_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3866\u001b[0m                 ]\n\u001b[1;32m   3867\u001b[0m                 output = {\n\u001b[0;32m-> 3868\u001b[0;31m                     \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3869\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuture\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfutures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3870\u001b[0m                 }\n",
            "\u001b[0;32m/usr/lib/python3.12/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    454\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/concurrent/futures/thread.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_invoke_step\u001b[0;34m(step, input_, config, key)\u001b[0m\n\u001b[1;32m   3849\u001b[0m             )\n\u001b[1;32m   3850\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mset_config_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_config\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3851\u001b[0;31m                 return context.run(\n\u001b[0m\u001b[1;32m   3852\u001b[0m                     \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3853\u001b[0m                     \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5546\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5547\u001b[0m     ) -> Output:\n\u001b[0;32m-> 5548\u001b[0;31m         return self.bound.invoke(\n\u001b[0m\u001b[1;32m   5549\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5550\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_configs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3141\u001b[0m                         \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3142\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3143\u001b[0;31m                         \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3144\u001b[0m         \u001b[0;31m# finish the root run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3145\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    396\u001b[0m             cast(\n\u001b[1;32m    397\u001b[0m                 \u001b[0;34m\"ChatGeneration\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m                 self.generate_prompt(\n\u001b[0m\u001b[1;32m    399\u001b[0m                     \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m                     \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1115\u001b[0m     ) -> LLMResult:\n\u001b[1;32m   1116\u001b[0m         \u001b[0mprompt_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m                 results.append(\n\u001b[0;32m--> 927\u001b[0;31m                     self._generate_with_cache(\n\u001b[0m\u001b[1;32m    928\u001b[0m                         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m                         \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36m_generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1219\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_from_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1221\u001b[0;31m             result = self._generate(\n\u001b[0m\u001b[1;32m   1222\u001b[0m                 \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_mistralai/chat_models.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, stream, **kwargs)\u001b[0m\n\u001b[1;32m    664\u001b[0m         \u001b[0mmessage_dicts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_message_dicts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 666\u001b[0;31m         response = self.completion_with_retry(\n\u001b[0m\u001b[1;32m    667\u001b[0m             \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessage_dicts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_mistralai/chat_models.py\u001b[0m in \u001b[0;36mcompletion_with_retry\u001b[0;34m(self, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_completion_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_combine_llm_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllm_outputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mwrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0mwrapped_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistics\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mretry_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mWrappedFn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0mretry_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRetryCallState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_object\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mdo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36miter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_post_retry_check_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry_state\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"RetryCallState\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_explicit_retry\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretry_run_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_action_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutcome\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: B902\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m                     \u001b[0mretry_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_mistralai/chat_models.py\u001b[0m in \u001b[0;36m_completion_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    578\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0miter_sse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m             \u001b[0m_raise_on_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_mistralai/chat_models.py\u001b[0m in \u001b[0;36m_raise_on_error\u001b[0;34m(response)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;34mf\"while fetching {response.url}: {error_message}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         )\n\u001b[0;32m--> 186\u001b[0;31m         raise httpx.HTTPStatusError(\n\u001b[0m\u001b[1;32m    187\u001b[0m             \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPStatusError\u001b[0m: Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"object\":\"error\",\"message\":\"Rate limit exceeded\",\"type\":\"rate_limited\",\"param\":null,\"code\":\"1300\"}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(data_set[\"questions\"]))\n",
        "print(len(data_set[\"answers\"]))\n",
        "data_set[\"questions\"]=data_set[\"questions\"][:60]\n",
        "print(len(data_set[\"questions\"]))\n",
        "print(len(data_set[\"answers\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3j1l7p0wEK3c",
        "outputId": "6e4629b8-b912-42c7-c304-280636e1db7d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "61\n",
            "60\n",
            "60\n",
            "60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df=pd.DataFrame(data_set)\n",
        "df.to_csv(\"data.csv\")"
      ],
      "metadata": {
        "id": "f5LQnwVdRyGV",
        "collapsed": true
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e7TpBZxQDllA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}