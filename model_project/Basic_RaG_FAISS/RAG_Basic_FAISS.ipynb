{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJ110Q8xnhD1",
        "outputId": "63ab01df-b69c-49e9-b5a8-9d39aad76585",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (25.3)\n",
            "Collecting langchain_huggingface\n",
            "  Downloading langchain_huggingface-1.2.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.2)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.1.3)\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.12/dist-packages (1.3.7)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.12/dist-packages (6.4.2)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.13.1)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.12/dist-packages (0.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: mistralai in /usr/local/lib/python3.12/dist-packages (1.9.11)\n",
            "Requirement already satisfied: langchain-mistralai in /usr/local/lib/python3.12/dist-packages (1.1.1)\n",
            "Requirement already satisfied: langchain_classic in /usr/local/lib/python3.12/dist-packages (1.0.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.33.4 in /usr/local/lib/python3.12/dist-packages (from langchain_huggingface) (0.36.0)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain_huggingface) (1.2.0)\n",
            "Requirement already satisfied: tokenizers<1.0.0,>=0.19.1 in /usr/local/lib/python3.12/dist-packages (from langchain_huggingface) (0.22.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (2.32.5)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (1.2.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (0.4.56)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (2.12.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (9.1.2)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (0.12.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (0.25.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (4.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.0->langchain_huggingface) (0.4.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.3)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.9.0+cpu)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.4)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.5)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.2.15)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.0)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.3.0)\n",
            "Requirement already satisfied: pybase64>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.4.3)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.38.0)\n",
            "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.4.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.23.2)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.39.1)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.39.1)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.39.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.76.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.0.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.20.0)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (34.1.0)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.2.0)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.25.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.2 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (2.3.0)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.44)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (3.13.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.12.0)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.3)\n",
            "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain_classic) (1.1.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.22.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.2.1)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain_community) (3.3.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.12/dist-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: eval-type-backport>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from mistralai) (0.3.1)\n",
            "Requirement already satisfied: invoke<3.0.0,>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from mistralai) (2.2.1)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.30.0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.43.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (6.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.12/dist-packages (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.9.23)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.72.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.39.1 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.39.1)\n",
            "Requirement already satisfied: opentelemetry-proto==1.39.1 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.39.1)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.60b1 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.60b1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.7.1)\n",
            "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.22.1)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.12/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb) (3.3.1)\n",
            "Downloading langchain_huggingface-1.2.0-py3-none-any.whl (30 kB)\n",
            "Installing collected packages: langchain_huggingface\n",
            "Successfully installed langchain_huggingface-1.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install langchain_huggingface sentence-transformers langchain chromadb pypdf faiss-cpu  langchain_community scikit-learn matplotlib seaborn numpy mistralai langchain-mistralai langchain_classic"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import PyPDFLoader, PyPDFDirectoryLoader\n",
        "# from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS,Chroma\n",
        "from langchain_classic.schema import Document\n",
        "import os\n",
        "\n",
        "\n",
        "loader = PyPDFDirectoryLoader(\"./dataset/\",glob=\"*.pdf\")\n",
        "docs = loader.load()\n",
        "\n",
        "\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
        "chunks = splitter.split_documents(docs)\n",
        "print(f\"Loaded {len(docs)} docs, split into {len(chunks)} chunks\")\n",
        "# inspect one\n",
        "print(chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8R-NChZ75UG",
        "outputId": "204fa46b-9419-4462-8be3-100c84b9d173"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 109 docs, split into 163 chunks\n",
            "[Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-09T20:37:37+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-09T20:37:37+05:30', 'source': 'dataset/Day-8-chunking.pdf', 'total_pages': 20, 'page': 0, 'page_label': '1'}, page_content='preencoded.png\\nDay 8\\nIngestion & Chunking'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-09T20:37:37+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-09T20:37:37+05:30', 'source': 'dataset/Day-8-chunking.pdf', 'total_pages': 20, 'page': 1, 'page_label': '2'}, page_content='preencoded.png\\nThe Art of Chunking: \\nOptimizing RAG \\nArchitecture\\nUnderstanding how to break down information is crucial for \\nefficient Retrieval Augmented Generation (RAG) systems. This \\npresentation explores the vital role of \"chunking\" in enhancing LLM \\nperformance and overall RAG architecture.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-09T20:37:37+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-09T20:37:37+05:30', 'source': 'dataset/Day-8-chunking.pdf', 'total_pages': 20, 'page': 2, 'page_label': '3'}, page_content='preencoded.png\\nWhy is Chunking Essential for \\nLLMs?\\nLLMs\\' Processing Limits\\nLarge Language Models cannot \\nprocess entire documents at \\nonce. They require content to be \\nbroken into manageable, smaller \\npieces.\\nMeaningful Segmentation\\nDocuments must be split into \\n\"meaningful chunks\" that retain \\ncoherence and context, not just \\narbitrary divisions.\\nEnhanced Retrieval\\nEffective chunking directly leads to better information retrieval, which is \\nthe cornerstone of a superior RAG system.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-09T20:37:37+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-09T20:37:37+05:30', 'source': 'dataset/Day-8-chunking.pdf', 'total_pages': 20, 'page': 3, 'page_label': '4'}, page_content='preencoded.png\\nNavigating the Context Window Limit\\nEvery Large Language Model operates within a defined \"context \\nwindow\" – a fixed number of tokens it can process \\nsimultaneously.\\n• Models can only \"remember\" and reason with information \\nwithin this window.\\n• To provide more context to the LLM, large documents must \\nbe efficiently chunked and relevant pieces retrieved.\\n• Proper chunking ensures that the most pertinent \\ninformation fits within the context window, preventing'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-09T20:37:37+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-09T20:37:37+05:30', 'source': 'dataset/Day-8-chunking.pdf', 'total_pages': 20, 'page': 3, 'page_label': '4'}, page_content='information fits within the context window, preventing \\ncritical details from being overlooked.\\nWhen a query requires information beyond this limit, chunking \\nand retrieval become indispensable.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-09T20:37:37+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-09T20:37:37+05:30', 'source': 'dataset/Day-8-chunking.pdf', 'total_pages': 20, 'page': 4, 'page_label': '5'}, page_content='preencoded.png'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-09T20:37:37+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-09T20:37:37+05:30', 'source': 'dataset/Day-8-chunking.pdf', 'total_pages': 20, 'page': 5, 'page_label': '6'}, page_content='preencoded.png\\nDefining a \"Chunk\"\\nA Small Text \\nSegment\\nA chunk is not just any arbitrary \\nsplit. It\\'s a carefully defined \\nsection of text.\\nContaining One \\nClear Idea\\nThe fundamental principle: \\neach chunk should \\nencapsulate a single, coherent \\nthought or concept.\\nBeyond Random \\nSplitting\\nAvoid merely cutting text at \\nfixed intervals; this often \\ndisrupts meaning and reduces \\nthe utility of the chunk.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-09T20:37:37+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-09T20:37:37+05:30', 'source': 'dataset/Day-8-chunking.pdf', 'total_pages': 20, 'page': 6, 'page_label': '7'}, page_content='preencoded.png\\nKey Chunking Strategies\\n01\\nFixed Size Chunking\\nSimple and straightforward, \\noften used as a baseline.\\n02\\nOverlap Chunking\\nIntroduces redundancy to \\npreserve context across \\nboundaries.\\n03\\nRecursive Text Splitter\\nHierarchical splitting that respects document structure.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-09T20:37:37+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-09T20:37:37+05:30', 'source': 'dataset/Day-8-chunking.pdf', 'total_pages': 20, 'page': 7, 'page_label': '8'}, page_content='preencoded.png'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-09T20:37:37+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-09T20:37:37+05:30', 'source': 'dataset/Day-8-chunking.pdf', 'total_pages': 20, 'page': 8, 'page_label': '9'}, page_content='preencoded.png'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-09T20:37:37+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-09T20:37:37+05:30', 'source': 'dataset/Day-8-chunking.pdf', 'total_pages': 20, 'page': 9, 'page_label': '10'}, page_content='preencoded.png'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-09T20:37:37+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-09T20:37:37+05:30', 'source': 'dataset/Day-8-chunking.pdf', 'total_pages': 20, 'page': 10, 'page_label': '11'}, page_content='preencoded.png'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-09T20:37:37+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-09T20:37:37+05:30', 'source': 'dataset/Day-8-chunking.pdf', 'total_pages': 20, 'page': 11, 'page_label': '12'}, page_content='preencoded.png'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-09T20:37:37+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-09T20:37:37+05:30', 'source': 'dataset/Day-8-chunking.pdf', 'total_pages': 20, 'page': 12, 'page_label': '13'}, page_content='preencoded.png'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-09T20:37:37+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-09T20:37:37+05:30', 'source': 'dataset/Day-8-chunking.pdf', 'total_pages': 20, 'page': 13, 'page_label': '14'}, page_content='preencoded.png'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-09T20:37:37+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-09T20:37:37+05:30', 'source': 'dataset/Day-8-chunking.pdf', 'total_pages': 20, 'page': 14, 'page_label': '15'}, page_content=\"preencoded.png\\nFixed Size Chunking: Pros \\nand Cons\\nPros:\\n• Ease of Implementation: It's \\nthe simplest chunking \\nmethod to set up and \\nexecute.\\n• Predictable Output: \\nGenerates chunks of a \\nconsistent length, which \\ncan be useful for certain \\nmodels.\\nCons:\\n• Loss of Meaning: Can \\nfrequently cut sentences or \\nideas mid-flow, leading to \\nincoherent chunks.\\n• Contextual Gaps: Important \\nconnections between cut \\ntext segments can be lost, \\nhampering retrieval \\naccuracy.\"), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-09T20:37:37+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-09T20:37:37+05:30', 'source': 'dataset/Day-8-chunking.pdf', 'total_pages': 20, 'page': 15, 'page_label': '16'}, page_content='preencoded.png\\nThe Advantage of Overlapping Chunks\\nOverlapping chunks address a critical flaw in fixed-size \\nmethods by maintaining contextual continuity.\\n• Preserves Sentence Integrity: By allowing a small portion \\nof text to repeat in subsequent chunks, it ensures that \\nsentences and short ideas are not cut off abruptly.\\n• Reduces Contextual Gaps: The overlap acts as a bridge, \\nlinking related information and improving the chances of \\nretrieving a complete thought.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-09T20:37:37+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-09T20:37:37+05:30', 'source': 'dataset/Day-8-chunking.pdf', 'total_pages': 20, 'page': 15, 'page_label': '16'}, page_content='linking related information and improving the chances of \\nretrieving a complete thought.\\n• Minor Redundancy for Major Gain: While it introduces a \\nsmall amount of redundant information, the benefit of \\nimproved coherence far outweighs this drawback.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-09T20:37:37+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-09T20:37:37+05:30', 'source': 'dataset/Day-8-chunking.pdf', 'total_pages': 20, 'page': 16, 'page_label': '17'}, page_content='preencoded.png\\nRecursive Text Splitter: Structure-\\nAware Chunking\\nPrioritizes Document Structure\\nThis advanced method first attempts to split text based on hierarchical structures like \\nheadings.\\nBreaks Down to Paragraphs\\nIf the text is still too large, it then splits into individual paragraphs.\\nFinal Split by Sentences\\nAs a last resort, it breaks down paragraphs into sentences, ensuring the \\nsmallest meaningful units.\\nMost Accurate for RAG'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-09T20:37:37+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-09T20:37:37+05:30', 'source': 'dataset/Day-8-chunking.pdf', 'total_pages': 20, 'page': 16, 'page_label': '17'}, page_content='smallest meaningful units.\\nMost Accurate for RAG\\nBy respecting the inherent organization of the document, it provides the most \\ncontextually relevant chunks for RAG systems.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-09T20:37:37+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-09T20:37:37+05:30', 'source': 'dataset/Day-8-chunking.pdf', 'total_pages': 20, 'page': 17, 'page_label': '18'}, page_content=\"preencoded.png\\nOptimal Chunk Configuration for Q&A RAG\\nFor most Question-Answering (Q&A) based RAG applications, a carefully tuned chunk size and overlap can significantly improve \\nperformance.\\n300\\nChunk Size (Tokens)\\nThis size generally allows for sufficient context without overwhelming the LLM's context window. It captures enough detail fo r \\nmost queries.\\n50\\nOverlap (Tokens)\"), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-09T20:37:37+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-09T20:37:37+05:30', 'source': 'dataset/Day-8-chunking.pdf', 'total_pages': 20, 'page': 17, 'page_label': '18'}, page_content='most queries.\\n50\\nOverlap (Tokens)\\nA 50-token overlap effectively bridges potential gaps, ensuring that key information at chunk boundaries remains connected \\nand retrievable.\\nThis configuration balances detail, context preservation, and processing efficiency, making it ideal for robust Q&A interactions.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-09T20:37:37+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-09T20:37:37+05:30', 'source': 'dataset/Day-8-chunking.pdf', 'total_pages': 20, 'page': 18, 'page_label': '19'}, page_content='preencoded.png\\nGood vs. Bad Chunks: A Visual Comparison\\nGood Chunk\\nA \"good\" chunk provides clear context, focusing on a single, \\ncomplete topic. It answers a potential question without \\nambiguity and retains all necessary surrounding \\ninformation.\\n• Clear context: All relevant information for one idea.\\n• Single topic: Focused and coherent content.\\n• Well-bounded: Starts and ends logically.\\nBad Chunk\\nA \"bad\" chunk might be cut mid-sentence, contain'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-09T20:37:37+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-09T20:37:37+05:30', 'source': 'dataset/Day-8-chunking.pdf', 'total_pages': 20, 'page': 18, 'page_label': '19'}, page_content='Bad Chunk\\nA \"bad\" chunk might be cut mid-sentence, contain \\nfragmented ideas, or blend unrelated lines. This leads to \\nconfusion and hinders effective retrieval, making it difficult \\nfor the LLM to understand or answer queries accurately.\\n• Mid-sentence cut: Incomplete thoughts.\\n• Unrelated lines: Jumbled, incoherent information.\\n• Ambiguous context: Hard for LLM to interpret.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-09T20:37:37+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-09T20:37:37+05:30', 'source': 'dataset/Day-8-chunking.pdf', 'total_pages': 20, 'page': 19, 'page_label': '20'}, page_content='preencoded.png\\nHands on tasks !'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 2', 'source': 'dataset/Day 2.pdf', 'total_pages': 18, 'page': 0, 'page_label': '1'}, page_content='Foundations of Large \\nLanguage Models (LLMs)'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 2', 'source': 'dataset/Day 2.pdf', 'total_pages': 18, 'page': 1, 'page_label': '2'}, page_content='What Are Large Language \\nModels (LLMs)?\\nDeﬁnition\\nLLMs are advanced AI programs \\nthat understand and generate \\nhuman-like text, learning from \\nvast amounts of data.\\nExamples\\nLeading LLMs include GPT\\ue0884o, \\nGemini, Claude, and Mistral, \\neach with unique capabilities.\\nImportance Today\\nThey are revolutionizing how we \\ninteract with technology, \\nautomating tasks, and powering \\nnew applications across \\nindustries.'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 2', 'source': 'dataset/Day 2.pdf', 'total_pages': 18, 'page': 2, 'page_label': '3'}, page_content=\"Today's Learning Journey: Exploring LLM Fundamentals\\nWhat LLMs Are\\nGaining a clear understanding of their core concept and purpose.\\nHow They Work\\nUnpacking the underlying mechanisms that enable their capabilities.\\nTokens, Embeddings, Attention\\nDelving into key components that define their operational logic.\\nML Basics Behind LLMs\\nConnecting LLMs to foundational Machine Learning principles.\"), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 2', 'source': 'dataset/Day 2.pdf', 'total_pages': 18, 'page': 3, 'page_label': '4'}, page_content=\"Machine Learning Basics: Predicting from Patterns\\nAt its core, Machine Learning is about making predictions based on past patterns found in data.\\n• ML models learn relationships between input data \\ue081X) and output \\ue081Y\\ue082.\\n• The process involves collecting data, analyzing patterns, choosing algorithms, training a model, and finally, making predictions.\\n• Think of it as your brain's ability to predict outcomes – ML models do the same, just with vast datasets.\\nThe ML Workﬂow\\nCollect Data\"), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 2', 'source': 'dataset/Day 2.pdf', 'total_pages': 18, 'page': 3, 'page_label': '4'}, page_content='The ML Workﬂow\\nCollect Data\\nAnalyze Patterns\\nChoose Algorithms\\nTrain Model\\nMake Predictions'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 2', 'source': 'dataset/Day 2.pdf', 'total_pages': 18, 'page': 4, 'page_label': '5'}, page_content='Language Models: Machine \\nLearning for Text\\nLanguage Models are specialized ML models trained on enormous text \\ndatasets, known as corpora, to understand and generate human \\nlanguage.\\nCore Function:\\nUnlike general ML that predicts \\nany Y from X, Language Models \\nexcel at predicting the next \\ntoken in a sequence, not an \\nentire sentence at once.\\nVersatile Applications:\\n• Answering complex questions \\n\\ue081Q&A\\ue082\\n• Enhancing search capabilities\\n• Summarizing lengthy \\ndocuments'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 2', 'source': 'dataset/Day 2.pdf', 'total_pages': 18, 'page': 4, 'page_label': '5'}, page_content='\\ue081Q&A\\ue082\\n• Enhancing search capabilities\\n• Summarizing lengthy \\ndocuments\\n• Accurate speech transcription'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 2', 'source': 'dataset/Day 2.pdf', 'total_pages': 18, 'page': 5, 'page_label': '6'}, page_content='Early Language Models: Probabilistic n-grams\\nThe earliest language models relied on simple statistical probabilities. They counted how often words appeared together.\\nCounting Patterns\\nThese models predicted the next \\nword based on the frequency of \\nword sequences in their training \\ndata.\\nn-grams\\nAn \"n-gram\" is a contiguous \\nsequence of \\'n\\' items from a given \\nsample of text or speech.\\nLimited Context\\nWhile simple and effective for their \\ntime, n-gram models struggled with'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 2', 'source': 'dataset/Day 2.pdf', 'total_pages': 18, 'page': 5, 'page_label': '6'}, page_content='Limited Context\\nWhile simple and effective for their \\ntime, n-gram models struggled with \\nlong-range dependencies in \\nlanguage.\\nN-gram Example\\nContext Predicted Next Word (based on frequency)\\n\"I love to eat...\" \"pizza\" (high frequency after \"to eat\")\\n\"The cat sat on the...\" \"mat\" (more common than \"moon\")'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 2', 'source': 'dataset/Day 2.pdf', 'total_pages': 18, 'page': 6, 'page_label': '7'}, page_content='A New Era: Neural Networks for Language\\nThe advent of neural networks marked a significant shift, moving beyond simple word counts to capture deeper \\nsemantic relationships.\\nDeep Learning Advantage\\nNeural networks can learn intricate patterns \\nand hierarchical structures within language.\\nEmbeddings: Meaning as Numbers\\nText is converted into numerical vectors \\n(embeddings), allowing the model to \\nunderstand semantic similarity.\\nSemantic & Context Capture\\nThey can grasp the meaning of words in'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 2', 'source': 'dataset/Day 2.pdf', 'total_pages': 18, 'page': 6, 'page_label': '7'}, page_content='understand semantic similarity.\\nSemantic & Context Capture\\nThey can grasp the meaning of words in \\ncontext and handle longer linguistic \\ndependencies.\\nText to Meaning'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 2', 'source': 'dataset/Day 2.pdf', 'total_pages': 18, 'page': 7, 'page_label': '8'}, page_content='The Evolution of Language Models: A Timeline\\nFrom basic statistical methods to powerful transformer architectures, language models have undergone rapid advancements.\\n1Word2Vec (2013)\\nIntroduced efficient word embeddings, capturing semantic \\nrelationships.\\n2 Recurrent Neural Networks \\n(RNNs)Handled sequential data, but struggled with very long \\nsequences.\\n3Long Short-Term Memory \\n(LSTMs)An improvement on RNNs, better at retaining information over \\nlonger sequences.\\n4 Transformers (2017)'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 2', 'source': 'dataset/Day 2.pdf', 'total_pages': 18, 'page': 7, 'page_label': '8'}, page_content='longer sequences.\\n4 Transformers (2017)\\nRevolutionized NLP with parallel processing and self-attention, \\nbecoming the foundation for modern LLMs.\\n5Modern LLMs (GPT, Gemini, \\nClaude)Vast, highly capable models built on transformer architecture, \\ndriving current AI breakthroughs.'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 2', 'source': 'dataset/Day 2.pdf', 'total_pages': 18, 'page': 8, 'page_label': '9'}, page_content='How Transformers Work: The \\nPower of Attention\\nTransformers are the backbone of modern LLMs, designed to process text \\nefficiently and understand complex relationships.\\nParallel Processing\\nUnlike earlier models, \\ntransformers can process entire \\ntext sequences simultaneously, \\ngreatly speeding up training.\\nSelf-Attention Mechanism\\nThis allows the model to weigh \\nthe importance of different words \\nin a sentence relative to each \\nother, even if they are far apart.\\nLong-Range Dependencies'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 2', 'source': 'dataset/Day 2.pdf', 'total_pages': 18, 'page': 8, 'page_label': '9'}, page_content='in a sentence relative to each \\nother, even if they are far apart.\\nLong-Range Dependencies\\nEffectively captures relationships between words that are not adjacent, \\ncrucial for understanding complex language.'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 2', 'source': 'dataset/Day 2.pdf', 'total_pages': 18, 'page': 9, 'page_label': '10'}, page_content='Tokens: The Building Blocks of \\nLLMsLLMs don\\'t process words directly; they break text into smaller units called tokens.\\nWhat Are Tokens?\\n• Tokens can be whole words, parts of words, or punctuation marks.\\n• The way text is tokenized impacts how an LLM processes information.\\nExamples:\\n\"Apple\" often translates to a single token.\\n\"Internationalization\" might be broken into multiple tokens like \"Inter\", \"national\", \\n\"ization\".'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 2', 'source': 'dataset/Day 2.pdf', 'total_pages': 18, 'page': 9, 'page_label': '10'}, page_content='\"Internationalization\" might be broken into multiple tokens like \"Inter\", \"national\", \\n\"ization\".\\nUnderstanding tokens is vital as they directly influence the cost, speed, and context window limitations of LLM interactions.'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 2', 'source': 'dataset/Day 2.pdf', 'total_pages': 18, 'page': 10, 'page_label': '11'}, page_content=\"Day 1: What Are We Covering?\\n01 \\nIntroduction to LLMs\\nUnderstanding the core concepts and their impact.\\n0 \\n 2 \\nHow LLMs Work\\nA high-level overview of their architecture and text generation.\\n0 \\n 3 \\nCapabilities & \\nLimitationsExploring why LLMs are so powerful and what they can't do.\\n0 \\n 4 \\nReal-World Applications & \\nHands-OnPractical uses and an interactive activity to get started.\"), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 2', 'source': 'dataset/Day 2.pdf', 'total_pages': 18, 'page': 11, 'page_label': '12'}, page_content='Embeddings: Converting Text \\nto Vectors\\nAt their core, Large Language Models convert human language into a \\nnumerical format they can understand and process. This transformation is \\ndone through \"embeddings.\"\\nText to Vectors\\nTransforming words and phrases into numerical arrays.\\nCapture Meaning\\nMathematically representing semantic relationships and context.\\nSimilar Concepts\\nConcepts with related meanings are grouped closer in vector space.'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 2', 'source': 'dataset/Day 2.pdf', 'total_pages': 18, 'page': 11, 'page_label': '12'}, page_content='Similar Concepts\\nConcepts with related meanings are grouped closer in vector space.\\nImagine an equation: \"King\" – \"Man\" + \"Woman\" ≈ \"Queen.\" Embeddings \\nallow LLMs to understand these nuanced relationships.'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 2', 'source': 'dataset/Day 2.pdf', 'total_pages': 18, 'page': 12, 'page_label': '13'}, page_content=\"LLM Architecture: A \\nHigh-Level Flow\\nUnderstanding the fundamental steps an LLM takes to process your \\ninput and generate a response.\\nTransformer Layers\\nEmbeddings\\nTokenizer\\nText Input\\nThis simplified diagram illustrates the journey of your query through the \\nLLM's internal mechanisms, from raw text to a coherent output.\"), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 2', 'source': 'dataset/Day 2.pdf', 'total_pages': 18, 'page': 13, 'page_label': '14'}, page_content='How LLMs Generate Text: Next-Token Prediction\\nLLMs don\\'t \"think\" like humans; they excel at a sophisticated \"word-guessing game\" based on patterns learned from vast amounts of data.\\n1 You Provide a Prompt\\nStarting the conversation with your input text.\\n2 Model Predicts Next Token\\nBased on context, it anticipates the most probable next word or \\nsub-word.\\n3 Prediction Becomes Input\\nThe newly predicted token is added to the sequence, extending \\nthe context.\\n4 Repeats Until Complete'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 2', 'source': 'dataset/Day 2.pdf', 'total_pages': 18, 'page': 13, 'page_label': '14'}, page_content='the context.\\n4 Repeats Until Complete\\nThis iterative process continues until a full sentence or desired \\noutput is generated.\\nThis \"word-guessing game,\" performed billions of times per second, creates the illusion of intelligence.'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 2', 'source': 'dataset/Day 2.pdf', 'total_pages': 18, 'page': 14, 'page_label': '15'}, page_content='Why LLMs Are So Good\\nThe impressive capabilities of LLMs stem from a combination of massive data and advanced architectural \\ndesign.\\nTrained on Huge Datasets: Exposure to petabytes of text and code from the internet.\\nFollow Normal Patterns: Learns the statistical regularities and nuances of human language.\\nRarely Unnatural: Generates remarkably coherent and contextually appropriate responses.'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 2', 'source': 'dataset/Day 2.pdf', 'total_pages': 18, 'page': 14, 'page_label': '15'}, page_content='Rarely Unnatural: Generates remarkably coherent and contextually appropriate responses.\\n\"Garbage in, garbage out\" still applies. The quality of the input greatly influences the quality of the output.'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 2', 'source': 'dataset/Day 2.pdf', 'total_pages': 18, 'page': 15, 'page_label': '16'}, page_content='Do LLMs Truly Understand?\\nThis is a profound philosophical and technical debate. While LLMs exhibit \\nimpressive linguistic feats, their \"understanding\" differs from human cognition.\\nPattern Prediction\\nThey learn and predict based on \\nstatistical patterns in data.\\nSimulated \\nUnderstanding\\nThey can mimic comprehension \\nwithout actual consciousness or \\nbelief.\\nNo Consciousness\\nLLMs lack genuine subjective experience, feelings, or self-awareness.'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 2', 'source': 'dataset/Day 2.pdf', 'total_pages': 18, 'page': 16, 'page_label': '17'}, page_content='Real-World Applications of LLMs\\nLLMs are rapidly transforming various industries and everyday tasks, making them more efficient and accessible.\\nChatbots & Assistants\\nCustomer service, virtual helpers, interactive tools.\\nCoding Assistants\\nGenerating code, debugging, explaining complex logic.\\nSummarization\\nCondensing long articles, reports, or meetings.\\nPDF Extraction\\nExtracting specific information from unstructured documents.\\nAgents & Workﬂows\\nAutomating multi-step tasks and processes.'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 2', 'source': 'dataset/Day 2.pdf', 'total_pages': 18, 'page': 16, 'page_label': '17'}, page_content='Agents & Workﬂows\\nAutomating multi-step tasks and processes.\\nPersonalized Learning\\nTailoring educational content and tutoring.'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 2', 'source': 'dataset/Day 2.pdf', 'total_pages': 18, 'page': 17, 'page_label': '18'}, page_content='Hands-On Activity'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:28+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:37:04+05:30', 'source': 'dataset/Day-5.pdf', 'total_pages': 14, 'page': 0, 'page_label': '1'}, page_content='preencoded.png\\nDay 4 \\nPrompt Design Patterns (ReAct, Self-Reflect)'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:28+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:37:04+05:30', 'source': 'dataset/Day-5.pdf', 'total_pages': 14, 'page': 1, 'page_label': '2'}, page_content='preencoded.png\\nWhy Prompt Patterns Matter\\nLarge Language Models (LLMs) interpret instructions with extreme literalness. This means that poorly constructed prompts \\ninevitably lead to suboptimal or inaccurate results. Conversely, well-designed prompts are the cornerstone of effective LLM \\ninteraction.\\nEnhanced Accuracy\\nReduces \"hallucinations\" and improves factual \\ncorrectness.\\nConsistent Outputs\\nEnsures predictable structure and formatting every \\ntime.\\nAutomation-Ready'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:28+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:37:04+05:30', 'source': 'dataset/Day-5.pdf', 'total_pages': 14, 'page': 1, 'page_label': '2'}, page_content=\"Consistent Outputs\\nEnsures predictable structure and formatting every \\ntime.\\nAutomation-Ready\\nGenerates outputs that can be seamlessly integrated \\ninto automated workflows.\\nSuperior Reasoning\\nFacilitates better logical thinking and effective tool \\nutilization.\\nThe prompt we design directly influences the model's behavior and utility.\\n“Prompting is programming the LLM with language.”\"), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:28+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:37:04+05:30', 'source': 'dataset/Day-5.pdf', 'total_pages': 14, 'page': 2, 'page_label': '3'}, page_content='preencoded.png\\nPersona / Role Prompting\\nPersona or Role Prompting involves instructing the LLM to adopt a \\nspecific identity and behavioral style. This technique is invaluable \\nfor eliciting responses with an expert tone, targeting a particular \\naudience, or ensuring domain-specific accuracy.\\nTemplate\\nAct as a . Your audience is . Use'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:28+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:37:04+05:30', 'source': 'dataset/Day-5.pdf', 'total_pages': 14, 'page': 3, 'page_label': '4'}, page_content='preencoded.png\\nStructured Output Prompting\\nFor seamless integration into production systems, LLM responses often need to be machine-readable. Structured Output Prompting ensures the model \\ndelivers information in predefined formats like JSON, Tables, XML, or Markdown Lists.\\nTemplate\\nReturn ONLY valid JSON: {\"skill\": \"\", \"rating\": \"\", \"years_of_experience\": \"\"}\\nExample\\nInput text: “Kiran has 3 years experience in Python and intermediate SQL skills.”\\nOutput:'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:28+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:37:04+05:30', 'source': 'dataset/Day-5.pdf', 'total_pages': 14, 'page': 3, 'page_label': '4'}, page_content='Example\\nInput text: “Kiran has 3 years experience in Python and intermediate SQL skills.”\\nOutput:\\n{\"skill\": \"Python\", \"rating\": \"Intermediate\", \"years_of_experience\": 3}\\n Best Practice:\\n• Clearly state the required format.\\n• Specify validation requirements.\\n• Use ALL CAPS for non-negotiable rules (e.g., ONLY, NO explanation).'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:28+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:37:04+05:30', 'source': 'dataset/Day-5.pdf', 'total_pages': 14, 'page': 4, 'page_label': '5'}, page_content='preencoded.png\\nReAct Prompting (Reason + Act)\\nReAct (Reason + Act) Prompting is particularly effective for tasks requiring tool utilization, mathematical calculations, sea rch operations, or multi-step reasoning. It \\nguides the LLM through a structured problem-solving process.\\nFormat\\nThought:Action:Observation:Final Answer:\\nExample\\nQuestion: What is 234 * 77?\\nAction: calculator(\"234 * 77\")Observation: 18018Thought: Calculation doneFinal Answer: 18,018'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:28+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:37:04+05:30', 'source': 'dataset/Day-5.pdf', 'total_pages': 14, 'page': 4, 'page_label': '5'}, page_content='Action: calculator(\"234 * 77\")Observation: 18018Thought: Calculation doneFinal Answer: 18,018\\n Used in: LangChain Agents, search-connected bots, and Retrieval Augmented Generation (RAG) tools to avoid superficial guesses and enhance \\nreliability.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:28+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:37:04+05:30', 'source': 'dataset/Day-5.pdf', 'total_pages': 14, 'page': 5, 'page_label': '6'}, page_content='preencoded.png\\nSelf-Critique / Self-Refine\\nSelf-Critique and Self-Refine prompting empowers the LLM to act as its own editor, significantly improving output quality and \\nreducing factual inaccuracies or \"hallucinations.\" This involves a two-phase prompting approach:\\n01\\nPhase 1: Generate\\nThe model first creates the initial response or content based \\non the given instructions.\\n02\\nPhase 2: Critique & Improve\\nThe model then critically reviews its own generated output,'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:28+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:37:04+05:30', 'source': 'dataset/Day-5.pdf', 'total_pages': 14, 'page': 5, 'page_label': '6'}, page_content='02\\nPhase 2: Critique & Improve\\nThe model then critically reviews its own generated output, \\nidentifying areas for enhancement and making revisions.\\nExample\\nWrite a 40-word summary of AI. Then review clarity & improve structure. Return improved version only.\\n Tip: Instruct the model to only return the improved version, avoiding the inclusion of the critique text itself, for a \\ncleaner and more concise output.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:28+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:37:04+05:30', 'source': 'dataset/Day-5.pdf', 'total_pages': 14, 'page': 6, 'page_label': '7'}, page_content='preencoded.png\\nEvidence-Based Prompting (Grounded)\\nEvidence-Based Prompting is crucial in applications like Retrieval Augmented Generation (RAG), where the model is strictly forbidden from \\ninferring or generating information not present in the provided context. It ensures that every claim is directly supported by the given data.\\nTemplate\\nUse ONLY the context below. If answer not found, say “I don’t know.” Provide supporting sentence.\\nExample\\nContext: “Gold is a good conductor of electricity.”'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:28+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:37:04+05:30', 'source': 'dataset/Day-5.pdf', 'total_pages': 14, 'page': 6, 'page_label': '7'}, page_content='Example\\nContext: “Gold is a good conductor of electricity.”\\nQuestion: Is gold a better conductor than copper?\\nAnswer: I don’t know. (No information found in the provided context)\\n Improves Reliability\\nEnsures responses are factually accurate and sourced.\\n Prevents Hallucination\\nEliminates the generation of fabricated or unverified information.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:28+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:37:04+05:30', 'source': 'dataset/Day-5.pdf', 'total_pages': 14, 'page': 7, 'page_label': '8'}, page_content=\"preencoded.png\\nDecomposition Prompting\\nDecomposition Prompting is a powerful technique for tackling complex problems by breaking them down into manageable, \\nsequential steps. This approach significantly improves the LLM's reasoning accuracy, especially for lengthy and intricate tasks.\\nTemplate\\nBreak the task into clear steps. Solve each step. Then combine into a final result.\\nExample\\nExplain how a transformer model works:\\n• Step 1: Input → tokens\\n• Step 2: Attention mechanism…\"), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:28+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:37:04+05:30', 'source': 'dataset/Day-5.pdf', 'total_pages': 14, 'page': 7, 'page_label': '8'}, page_content='Explain how a transformer model works:\\n• Step 1: Input → tokens\\n• Step 2: Attention mechanism…\\nFinal Answer: Summary of above steps.\\n Great for: Coding tasks, detailed analysis, and complex mathematical problems that require a methodical approach.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:28+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:37:04+05:30', 'source': 'dataset/Day-5.pdf', 'total_pages': 14, 'page': 8, 'page_label': '9'}, page_content='preencoded.png\\nCompare & Evaluate Prompting\\nThis technique involves instructing the model to generate multiple potential outputs and then critically compare and \\nevaluate them to select the best option. This leads to a significant boost in the accuracy and quality of the final answer, \\nparticularly in subjective or creative tasks.\\nExample\\nGenerate 3 taglines for a fitness brand. Then select the best one based on clarity & emotion. Return only the best.\\nTagline 1:\\n\"Sweat. Achieve. Repeat.\"'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:28+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:37:04+05:30', 'source': 'dataset/Day-5.pdf', 'total_pages': 14, 'page': 8, 'page_label': '9'}, page_content='Tagline 1:\\n\"Sweat. Achieve. Repeat.\"\\nTagline 2:\\n\"Unleash Your Inner Athlete.\"\\nTagline 3 (Selected):\\n\"Transform Your Body, Elevate \\nYour Mind.\"\\n Useful for: Creative endeavors, ambiguous problems, and situations where multiple valid solutions exist.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:28+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:37:04+05:30', 'source': 'dataset/Day-5.pdf', 'total_pages': 14, 'page': 9, 'page_label': '10'}, page_content='preencoded.png\\nPlanning + Persona + Format Prompt\\nCombining multiple prompt patterns is the key to achieving the best real-world performance from LLMs, especially for sophisticated applications like \\nAgents and RAG systems. This \"pattern stacking\" allows for highly nuanced and effective instructions.\\nExample for writing a report:\\nAct as a cybersecurity expert. Plan first: list the key sections for a ransomware report. Ask for approval. After approval, write a detailed report in table \\nformat.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:28+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:37:04+05:30', 'source': 'dataset/Day-5.pdf', 'total_pages': 14, 'page': 9, 'page_label': '10'}, page_content='format.\\n1 Planning\\n2 Persona\\n3 Structured Format\\n4 Review/Approval\\n Pattern Stacking: This synergistic approach is optimal for developing sophisticated AI agents and advanced RAG applications, yielding \\nmore comprehensive and accurate results.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:28+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:37:04+05:30', 'source': 'dataset/Day-5.pdf', 'total_pages': 14, 'page': 10, 'page_label': '11'}, page_content='preencoded.png\\nGood vs Bad Prompt Summary\\n“Explain blockchain.” “Explain blockchain in 5 bullets for a 12-year-old with a \\nreal-life example.”\\nNo specific format JSON, bullets, table, XML\\nNo defined role Role defined = domain accuracy\\nGuessing allowed Ground answer strictly in provided context\\n Good prompts are characterized by:\\nClear Role Definition\\n Structured Format Requirements\\nExplicit Constraints\\n Verification Mechanisms'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:28+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:37:04+05:30', 'source': 'dataset/Day-5.pdf', 'total_pages': 14, 'page': 11, 'page_label': '12'}, page_content='preencoded.png\\nChoosing the best approach to write prompts\\nZero-Shot: Simple tasks; no examples needed.Wrong use → \\nvague/inaccurate results.\\nFew-Shot: Specific formats or styles; examples guide output.Wrong \\nuse → formatting drift.\\nChain-of-Thought (CoT): Multi-step reasoning.Wrong use → \\nshallow or wrong logic.\\nReAct: Tasks needing tools/search + reasoning.Wrong use → \\nmissing or incorrect tool actions.\\nCritique / Self-Refinement: High-quality, polished outputs.Wrong'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:28+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:37:04+05:30', 'source': 'dataset/Day-5.pdf', 'total_pages': 14, 'page': 11, 'page_label': '12'}, page_content='Critique / Self-Refinement: High-quality, polished outputs.Wrong \\nuse → unreviewed errors, lower quality.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:28+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:37:04+05:30', 'source': 'dataset/Day-5.pdf', 'total_pages': 14, 'page': 12, 'page_label': '13'}, page_content='preencoded.png\\nWhat happens if you choose the wrong method\\n• Lower accuracy\\n• Missing steps or faulty reasoning\\n• Poor formatting or inconsistency\\n• Tool calls not triggered when needed\\n• Overall weaker performance'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:28+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:37:04+05:30', 'source': 'dataset/Day-5.pdf', 'total_pages': 14, 'page': 13, 'page_label': '14'}, page_content='preencoded.png\\nSummary\\nPattern What It Improves Real Benefit\\nPersona / Role Prompting \\n Tone + Expertise Domain-accurate and audience-\\nspecific responses\\nStructured Output \\n Format + Consistency Directly usable in apps (JSON, \\ntables)\\nReAct Prompting \\n Step-by-step reasoning + tool use Better correctness for math, \\nsearch, agents\\nSelf-Refine / Critique \\n Clarity + Coherence Higher quality with fewer \\nhallucinations\\nEvidence-Based Prompting \\n Source grounding Trustworthy responses (critical for'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:28+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:37:04+05:30', 'source': 'dataset/Day-5.pdf', 'total_pages': 14, 'page': 13, 'page_label': '14'}, page_content='hallucinations\\nEvidence-Based Prompting \\n Source grounding Trustworthy responses (critical for \\nRAG)'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': 'dataset/Day-7-RAG.pdf', 'total_pages': 17, 'page': 0, 'page_label': '1'}, page_content='preencoded.png\\nDay 7 \\nRetrieval-Augmented Generation (RAG)'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': 'dataset/Day-7-RAG.pdf', 'total_pages': 17, 'page': 1, 'page_label': '2'}, page_content='preencoded.png\\nWhy LLMs Go Wrong: \\nUnderstanding Hallucinations\\nLarge Language Models (LLMs) operate by predicting the next token based \\non vast patterns learned during their training. However, they lack direct \\naccess to the latest information or private knowledge bases . This \\nfundamental limitation often leads them to confidently guess when faced \\nwith queries outside their training data, resulting in what we call \\nhallucinations .'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': 'dataset/Day-7-RAG.pdf', 'total_pages': 17, 'page': 1, 'page_label': '2'}, page_content='with queries outside their training data, resulting in what we call \\nhallucinations .\\nExample: If you ask an LLM, \"Who won IPL 2025?\", it might invent a \\nwinner and match details, despite the event not having occurred yet.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': 'dataset/Day-7-RAG.pdf', 'total_pages': 17, 'page': 2, 'page_label': '3'}, page_content=\"preencoded.png\\nWhat Exactly is an LLM Hallucination?\\nSounds Confident\\nThe LLM delivers information with conviction, as if it were factual.\\nFactually Incorrect\\nThe generated content is false, misleading, or unsupported by real-world data.\\nCommon Causes:\\n• Missing Knowledge: The LLM's training data doesn't cover the specific information requested.\\n• Ambiguous Prompts: Vague or unclear user queries can lead the model to make assumptions.\"), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': 'dataset/Day-7-RAG.pdf', 'total_pages': 17, 'page': 2, 'page_label': '3'}, page_content='• Ambiguous Prompts: Vague or unclear user queries can lead the model to make assumptions.\\n• Over-Generalization: The model applies patterns too broadly, leading to incorrect inferences.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': 'dataset/Day-7-RAG.pdf', 'total_pages': 17, 'page': 3, 'page_label': '4'}, page_content=\"preencoded.png\\nWhat Exactly is an LLM Hallucination?\\nSounds Confident\\nThe LLM delivers information with conviction, as if it were factual.\\nFactually Incorrect\\nThe generated content is false, misleading, or unsupported by real-world data.\\nCommon Causes:\\n• Missing Knowledge: The LLM's training data doesn't cover the specific information requested.\\n• Ambiguous Prompts: Vague or unclear user queries can lead the model to make assumptions.\"), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': 'dataset/Day-7-RAG.pdf', 'total_pages': 17, 'page': 3, 'page_label': '4'}, page_content='• Ambiguous Prompts: Vague or unclear user queries can lead the model to make assumptions.\\n• Over-Generalization: The model applies patterns too broadly, leading to incorrect inferences.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': 'dataset/Day-7-RAG.pdf', 'total_pages': 17, 'page': 4, 'page_label': '5'}, page_content=\"preencoded.png\\nWhat Exactly is an LLM Hallucination?\\nSounds Confident\\nThe LLM delivers information with conviction, as if it were factual.\\nFactually Incorrect\\nThe generated content is false, misleading, or unsupported by real-world data.\\nCommon Causes:\\n• Missing Knowledge: The LLM's training data doesn't cover the specific information requested.\\n• Ambiguous Prompts: Vague or unclear user queries can lead the model to make assumptions.\"), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': 'dataset/Day-7-RAG.pdf', 'total_pages': 17, 'page': 4, 'page_label': '5'}, page_content='• Ambiguous Prompts: Vague or unclear user queries can lead the model to make assumptions.\\n• Over-Generalization: The model applies patterns too broadly, leading to incorrect inferences.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': 'dataset/Day-7-RAG.pdf', 'total_pages': 17, 'page': 5, 'page_label': '6'}, page_content=\"preencoded.png\\nWhat Exactly is an LLM Hallucination?\\nSounds Confident\\nThe LLM delivers information with conviction, as if it were factual.\\nFactually Incorrect\\nThe generated content is false, misleading, or unsupported by real-world data.\\nCommon Causes:\\n• Missing Knowledge: The LLM's training data doesn't cover the specific information requested.\\n• Ambiguous Prompts: Vague or unclear user queries can lead the model to make assumptions.\"), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': 'dataset/Day-7-RAG.pdf', 'total_pages': 17, 'page': 5, 'page_label': '6'}, page_content='• Ambiguous Prompts: Vague or unclear user queries can lead the model to make assumptions.\\n• Over-Generalization: The model applies patterns too broadly, leading to incorrect inferences.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': 'dataset/Day-7-RAG.pdf', 'total_pages': 17, 'page': 6, 'page_label': '7'}, page_content=\"preencoded.png\\nWhat Exactly is an LLM Hallucination?\\nSounds Confident\\nThe LLM delivers information with conviction, as if it were factual.\\nFactually Incorrect\\nThe generated content is false, misleading, or unsupported by real-world data.\\nCommon Causes:\\n• Missing Knowledge: The LLM's training data doesn't cover the specific information requested.\\n• Ambiguous Prompts: Vague or unclear user queries can lead the model to make assumptions.\"), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': 'dataset/Day-7-RAG.pdf', 'total_pages': 17, 'page': 6, 'page_label': '7'}, page_content='• Ambiguous Prompts: Vague or unclear user queries can lead the model to make assumptions.\\n• Over-Generalization: The model applies patterns too broadly, leading to incorrect inferences.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': 'dataset/Day-7-RAG.pdf', 'total_pages': 17, 'page': 7, 'page_label': '8'}, page_content='preencoded.png\\nRAG Architecture: A High-Level Overview\\nRetrieval Augmented Generation combines the strengths of information retrieval with the generative power of LLMs. Here’s how the \\npipeline works:\\n01\\nUser Query\\nThe user submits a question or prompt to the RAG system.\\n02\\nRetrieval from Knowledge Base\\nThe system searches a vast knowledge base (documents, databases) \\nto find relevant context.\\n03\\nContext + Query to LLM\\nThe retrieved context is combined with the original query and sent to'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': 'dataset/Day-7-RAG.pdf', 'total_pages': 17, 'page': 7, 'page_label': '8'}, page_content='03\\nContext + Query to LLM\\nThe retrieved context is combined with the original query and sent to \\nthe LLM.\\n04\\nResponse with Citations\\nThe LLM generates a response, referencing the sources from which \\nthe information was retrieved.\\n Retrieval + Generation — This synergistic approach offers the best of both worlds: factual accuracy and fluent, coherent text generation.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': 'dataset/Day-7-RAG.pdf', 'total_pages': 17, 'page': 8, 'page_label': '9'}, page_content=\"preencoded.png\\nWhat Exactly is an LLM Hallucination?\\nSounds Confident\\nThe LLM delivers information with conviction, as if it were factual.\\nFactually Incorrect\\nThe generated content is false, misleading, or unsupported by real-world data.\\nCommon Causes:\\n• Missing Knowledge: The LLM's training data doesn't cover the specific information requested.\\n• Ambiguous Prompts: Vague or unclear user queries can lead the model to make assumptions.\"), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': 'dataset/Day-7-RAG.pdf', 'total_pages': 17, 'page': 8, 'page_label': '9'}, page_content='• Ambiguous Prompts: Vague or unclear user queries can lead the model to make assumptions.\\n• Over-Generalization: The model applies patterns too broadly, leading to incorrect inferences.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': 'dataset/Day-7-RAG.pdf', 'total_pages': 17, 'page': 9, 'page_label': '10'}, page_content='preencoded.png'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': 'dataset/Day-7-RAG.pdf', 'total_pages': 17, 'page': 10, 'page_label': '11'}, page_content='preencoded.png\\nWhy We Need Retrieval Augmented Generation (RAG)\\nThe core challenge with traditional LLMs is that their internal parameters are frozen once training is complete. They cannot inherently access \\nnew information in real-time.\\nThe RAG Solution:\\n• Integrates real, up-to-date documents into the generation process.\\n• Provides domain-specific knowledge crucial for specialized applications.\\n• Enables source citations, allowing users to verify information.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': 'dataset/Day-7-RAG.pdf', 'total_pages': 17, 'page': 10, 'page_label': '11'}, page_content='• Enables source citations, allowing users to verify information.\\nThe result: The LLM becomes more truthful and grounded in verifiable data, drastically reducing hallucinations.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': 'dataset/Day-7-RAG.pdf', 'total_pages': 17, 'page': 11, 'page_label': '12'}, page_content='preencoded.png\\nRAG vs. Fine-Tuning: Choosing the Right Approach\\nWhen enhancing LLM performance, RAG and fine-tuning are two primary strategies. Understanding their differences is key to selecting the \\noptimal solution.\\nFeature RAG Fine-Tuning\\nSpeed Fast deployment & updates Slow (requires retraining)\\nData Size Few documents needed Thousands of examples required\\nCost Low computational cost High computational cost\\nDynamic Updates Very easy to refresh data Requires re-training the model'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': 'dataset/Day-7-RAG.pdf', 'total_pages': 17, 'page': 11, 'page_label': '12'}, page_content='Dynamic Updates Very easy to refresh data Requires re-training the model\\nBest Use Private or latest factual data Adapting to new behaviors or styles\\nConclusion: Always consider RAG as your initial strategy before opting for the more resource-intensive fine-tuning process.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': 'dataset/Day-7-RAG.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13'}, page_content=\"preencoded.png\\nRAG in the Real World: Practical Applications\\nRAG's ability to provide accurate, up-to-date, and verifiable information makes it indispensable across various industries.\\nEnterprise Chatbots\\nEnhances customer service in \\nbanking and healthcare with \\nprecise information.\\nLegal & Policy Assistants\\nProvides rapid access to legal \\nprecedents and policy \\ndocuments for quick analysis.\\nCode Documentation \\nBots\\nHelps developers navigate \\ncomplex codebases and generate\"), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': 'dataset/Day-7-RAG.pdf', 'total_pages': 17, 'page': 12, 'page_label': '13'}, page_content='Code Documentation \\nBots\\nHelps developers navigate \\ncomplex codebases and generate \\naccurate documentation.\\nResearch Assistants\\nExpedites literature reviews and \\ndata synthesis across scientific \\ndomains.\\nKey Takeaway: If an LLM leverages company-specific or proprietary data for its responses, it is almost certainly employing a RAG \\narchitecture.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': 'dataset/Day-7-RAG.pdf', 'total_pages': 17, 'page': 13, 'page_label': '14'}, page_content=\"preencoded.png\\nDiverse Retrieval Sources for RAG Systems\\nThe power of RAG lies in its flexibility to integrate knowledge from almost any digital source, transforming raw data into searchable intelligence.\\nPDFs\\nWebsites\\nSQL Databases\\nAPIs\\nSharePoint / Drive\\nEssentially, any form of text-based information can be processed and indexed to become part of the LLM's dynamic knowledge base, enabling robust and relevant responses.\"), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': 'dataset/Day-7-RAG.pdf', 'total_pages': 17, 'page': 14, 'page_label': '15'}, page_content=\"preencoded.png\\nWhat Makes a Good RAG System?\\nAn effective RAG system is built on several critical components that ensure accuracy, relevance, and reliability in LLM-generated responses.\\nCorrect & Relevant Retrieval\\nEnsuring the system pulls the most accurate and pertinent information.\\nStructured Chunking\\nBreaking down documents into optimally sized segments for efficient retrieval.\\nTop-k Contextual Grounding\\nSelecting the most relevant 'k' chunks to provide sufficient context to the LLM.\"), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': 'dataset/Day-7-RAG.pdf', 'total_pages': 17, 'page': 14, 'page_label': '15'}, page_content=\"Selecting the most relevant 'k' chunks to provide sufficient context to the LLM.\\nCitations + Verifiable Sources\\nProviding clear references to allow users to cross-reference and build trust.\\nHallucination Fallback Strategies\\nImplementing mechanisms to detect and mitigate potential hallucinations.\"), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': 'dataset/Day-7-RAG.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16'}, page_content='preencoded.png\\nFixing Hallucinations with \\nRetrieval\\nLet\\'s illustrate the direct impact of retrieval on mitigating LLM hallucinations using a \\nsimple example:\\nLLM-only \\nWhen asked a question beyond its \\ntraining data (e.g., \"What were the latest \\nQ3 earnings for Company X?\"), an LLM \\nwithout retrieval might:\\n• Invent financial figures.\\n• State outdated information.\\n• Generate a plausible but completely \\nfalse report.\\nResult: Hallucinates and provides \\nincorrect information.\\nRetrieval-enabled'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': 'dataset/Day-7-RAG.pdf', 'total_pages': 17, 'page': 15, 'page_label': '16'}, page_content='false report.\\nResult: Hallucinates and provides \\nincorrect information.\\nRetrieval-enabled \\nWith retrieval, the same question triggers \\na search across real-time financial reports \\nor company databases. The LLM then:\\n• Accesses the latest Q3 report.\\n• Extracts accurate earnings data.\\n• Cites the source of the information.\\nResult: Provides a correct and verifiable \\nresponse.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': 'dataset/Day-7-RAG.pdf', 'total_pages': 17, 'page': 16, 'page_label': '17'}, page_content='preencoded.png\\nWhen RAG Systems Fall Short\\nWhile powerful, RAG systems are not foolproof. Their effectiveness hinges on the quality of their components \\nand implementation.\\nPoor Chunking\\nDocuments are split too broadly or too narrowly, hindering retrieval accuracy.\\nWrong Search Algorithm\\nIneffective algorithms fail to match queries with relevant document sections.\\nMissing Documents\\nCritical information is not included in the knowledge base, leading to gaps.\\nLow-Quality Embeddings'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T08:58:44+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T08:58:44+05:30', 'source': 'dataset/Day-7-RAG.pdf', 'total_pages': 17, 'page': 16, 'page_label': '17'}, page_content='Critical information is not included in the knowledge base, leading to gaps.\\nLow-Quality Embeddings\\nPoor semantic representation of text leads to inaccurate retrieval matches.\\nUnderstanding these common pitfalls is the first step. We will explore strategies to improve and optimize these \\naspects in our upcoming sessions.'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 3', 'source': 'dataset/Day 3.pdf', 'total_pages': 14, 'page': 0, 'page_label': '1'}, page_content='Day 2\\nPrompt Engineering'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 3', 'source': 'dataset/Day 3.pdf', 'total_pages': 14, 'page': 1, 'page_label': '2'}, page_content='● Focus on essential prompt engineering \\ntechniques\\n● Understand the function of the context \\nwindow size\\n● Develop effective prompts for better model \\nresponses\\n● Explore advanced prompting strategies \\nduring Day 2'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 3', 'source': 'dataset/Day 3.pdf', 'total_pages': 14, 'page': 2, 'page_label': '3'}, page_content='What is Prompt Engineering?\\n● Crafting and reﬁning inputs for large \\nlanguage models\\n● Involves structuring prompts to guide \\nmodel behavior\\n● Focuses on achieving desired, high-quality \\nmodel outputs\\n● Essential skill for maximizing the utility of \\nLLMs'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 3', 'source': 'dataset/Day 3.pdf', 'total_pages': 14, 'page': 3, 'page_label': '4'}, page_content='What is Prompt Engineering?\\n● Crafting and reﬁning inputs for large \\nlanguage models\\n● Involves structuring prompts to guide \\nmodel behavior\\n● Focuses on achieving desired, high-quality \\nmodel outputs\\n● Essential skill for maximizing the utility of \\nLLMs'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 3', 'source': 'dataset/Day 3.pdf', 'total_pages': 14, 'page': 4, 'page_label': '5'}, page_content=\"Zero-Shot Prompting Explained\\n● Zero-shot prompting provides \\nan instruction only\\n● The LLM uses its training to \\nanswer the request\\n● No speciﬁc examples are given \\nwithin the prompt\\n● It relies solely on the model's \\nexisting knowledge\"), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 3', 'source': 'dataset/Day 3.pdf', 'total_pages': 14, 'page': 5, 'page_label': '6'}, page_content='Zero-Shot Prompting Explained'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 3', 'source': 'dataset/Day 3.pdf', 'total_pages': 14, 'page': 6, 'page_label': '7'}, page_content=\"Few-Shot Prompting \\nExplained\\n● Providing examples guides the \\nmodel's response\\n● Few-shot prompting includes \\nseveral input-output pairs\\n● Improves accuracy and helps \\nmodel learn speciﬁc tasks\\n● Examples are shown directly \\nwithin the prompt's context\"), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 3', 'source': 'dataset/Day 3.pdf', 'total_pages': 14, 'page': 7, 'page_label': '8'}, page_content='Few-Shot Prompting Explained'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 3', 'source': 'dataset/Day 3.pdf', 'total_pages': 14, 'page': 9, 'page_label': '10'}, page_content='Building a Prompt Framework\\nT o perform Few-shot prompting effectively, you need a structure. \\nJust throwing text at the model can confuse it. Use the Standard \\nPrompt Structure:\\n1. Role (Optional): Who is the AI?\\n2. Instruction: What is the task?\\n3. Examples (The \"Shots\"): The pattern to follow.\\n4. Context/Constraint: Any guardrails?\\n5. Input Data: The actual thing to process.\\n6. Output Indicator: A cue for the AI to start.'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 3', 'source': 'dataset/Day 3.pdf', 'total_pages': 14, 'page': 10, 'page_label': '11'}, page_content='Building a Prompt Framework\\nT o perform Few-shot prompting effectively, you need a structure. \\nJust throwing text at the model can confuse it. Use the Standard \\nPrompt Structure:\\n1. Role (Optional): Who is the AI?\\n2. Instruction: What is the task?\\n3. Examples (The \"Shots\"): The pattern to follow.\\n4. Context/Constraint: Any guardrails?\\n5. Input Data: The actual thing to process.\\n6. Output Indicator: A cue for the AI to start.'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 3', 'source': 'dataset/Day 3.pdf', 'total_pages': 14, 'page': 11, 'page_label': '12'}, page_content=\"Context Window \\nDeep Dive\\n● The context window is the \\nmodel's short-term memory\\n● It deﬁnes the amount of text \\nthe model can process\\n● Window size limits the input \\nand output length\\n● Exceeding the window causes \\nthe model to forget \\ninformation\"), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 3', 'source': 'dataset/Day 3.pdf', 'total_pages': 14, 'page': 12, 'page_label': '13'}, page_content='What happens if the context window is \\nexceeded ?'), Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Day 3', 'source': 'dataset/Day 3.pdf', 'total_pages': 14, 'page': 13, 'page_label': '14'}, page_content='Hands on …..'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:59+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:33:59+05:30', 'source': 'dataset/Day-6.pdf', 'total_pages': 13, 'page': 0, 'page_label': '1'}, page_content='preencoded.png\\nDay 6\\nPrompt Evaluation & Quality Measurement\\nEnsuring accuracy, reliability & trust in LLM outputs'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:59+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:33:59+05:30', 'source': 'dataset/Day-6.pdf', 'total_pages': 13, 'page': 1, 'page_label': '2'}, page_content='preencoded.png\\nThe Art and Science of LLM \\nPrompt Evaluation\\nIn the rapidly evolving landscape of Large Language Models (LLMs), \\neffective prompt evaluation is paramount. This presentation \\nexplores various methods to ensure LLM outputs are high-quality, \\nreliable, and aligned with user expectations.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:59+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:33:59+05:30', 'source': 'dataset/Day-6.pdf', 'total_pages': 13, 'page': 2, 'page_label': '3'}, page_content='preencoded.png\\nWhy Prompt Evaluation Matters\\nIncorrect Facts\\nLLMs can generate factually inaccurate information, \\nleading to misinformation.\\nMissing Information\\nOutputs may lack crucial details, resulting in incomplete \\nor unhelpful responses.\\nWrong Formats\\nLLMs might deviate from specified output formats, \\ncausing integration issues.\\nHallucinations\\nThe model can produce confident but entirely fabricated \\ncontent, a significant risk.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:59+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:33:59+05:30', 'source': 'dataset/Day-6.pdf', 'total_pages': 13, 'page': 2, 'page_label': '3'}, page_content='The model can produce confident but entirely fabricated \\ncontent, a significant risk.\\nWithout robust evaluation metrics, deploying LLMs can lead to unreliable systems. We need to measure quality before \\ndeployment.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:59+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:33:59+05:30', 'source': 'dataset/Day-6.pdf', 'total_pages': 13, 'page': 3, 'page_label': '4'}, page_content='preencoded.png\\nEvaluation Categories\\nHuman Evaluation\\nLeveraging human judgment for nuanced quality \\nassessment.\\nAutomated Metrics\\nQuantifiable scores for specific linguistic tasks.\\nBehavioral Checks\\nRule-based tests to enforce structural and content \\nconstraints.\\nLLM-as-a-Judge\\nUsing advanced LLMs to evaluate simpler model outputs.\\nThe most effective evaluation strategies combine multiple methods for comprehensive quality assurance.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:59+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:33:59+05:30', 'source': 'dataset/Day-6.pdf', 'total_pages': 13, 'page': 4, 'page_label': '5'}, page_content='preencoded.png\\nHuman Evaluation\\nHuman evaluation involves domain experts assessing LLM outputs based on a predefined set of criteria. This \\nmethod is invaluable for capturing the subjective and nuanced aspects of language quality.\\n• Factual Accuracy: Verifying the correctness of information.\\n• Completeness: Ensuring all required information is present.\\n• Grammar & Fluency: Assessing linguistic quality and readability.\\n• Tone and Safety: Judging appropriate tone and absence of harmful content.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:59+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:33:59+05:30', 'source': 'dataset/Day-6.pdf', 'total_pages': 13, 'page': 4, 'page_label': '5'}, page_content='• Tone and Safety: Judging appropriate tone and absence of harmful content.\\nWhile human evaluation offers unparalleled quality and incorporates specialized domain knowledge, it is both \\nresource-intensive and time-consuming.\\n1\\nPros: High Quality\\nProvides deep insights and accurate assessments.\\n2\\nPros: Domain Expertise\\nLeverages specialized knowledge for nuanced feedback.\\n3\\nCons: Expensive\\nRequires significant financial investment.\\n4\\nCons: Slow\\nCan delay development cycles due to manual effort.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:59+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:33:59+05:30', 'source': 'dataset/Day-6.pdf', 'total_pages': 13, 'page': 5, 'page_label': '6'}, page_content='preencoded.png\\nAutomated Evaluation\\nAutomated metrics provide objective and quantifiable assessments of LLM \\nperformance, making them suitable for large-scale and iterative evaluations. They \\nare particularly useful for specific NLP tasks where clear reference answers exist.\\nCommonly used in:\\n• Summarization: Measuring how well a model condenses text.\\n• Translation: Assessing the accuracy of language conversion.\\n• Classification: Evaluating the correctness of categorical assignments.\\nPros: Fast'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:59+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:33:59+05:30', 'source': 'dataset/Day-6.pdf', 'total_pages': 13, 'page': 5, 'page_label': '6'}, page_content='• Classification: Evaluating the correctness of categorical assignments.\\nPros: Fast\\nQuick execution for rapid feedback.\\nPros: Scalable\\nEfficiently evaluates large datasets.\\nCons: Limited Meaning Capture\\nStruggles with semantic nuances and \\ncontext.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:59+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:33:59+05:30', 'source': 'dataset/Day-6.pdf', 'total_pages': 13, 'page': 6, 'page_label': '7'}, page_content='preencoded.png\\nBLEU Score: Bilingual Evaluation Understudy\\nThe BLEU score is a widely used automated metric primarily for evaluating \\nmachine translation. It measures the similarity between a machine-\\ngenerated translation (candidate) and one or more human-generated \\nreference translations.\\nHow it works:\\n• N-gram Overlap: Compares sequences of words (n-grams) between \\nthe candidate and reference texts.\\n• Score Range: A score from 0 to 1 (often expressed as a percentage)'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:59+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:33:59+05:30', 'source': 'dataset/Day-6.pdf', 'total_pages': 13, 'page': 6, 'page_label': '7'}, page_content='• Score Range: A score from 0 to 1 (often expressed as a percentage) \\nindicates higher similarity.\\nExample:Reference: “Cats are great pets.”Model: “Cats make good \\npets.”Shared n-grams contribute to a higher BLEU score.\\nLimit: BLEU scores can penalize outputs that use synonyms or alternative \\nphrasings, as they prioritize exact wording matches, potentially \\noverlooking semantic equivalence.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:59+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:33:59+05:30', 'source': 'dataset/Day-6.pdf', 'total_pages': 13, 'page': 7, 'page_label': '8'}, page_content='preencoded.png\\nROUGE Score: Recall-Oriented Understudy for Gisting \\nEvaluation\\nROUGE is a set of metrics specifically designed to evaluate automatic \\nsummarization and machine translation by comparing an automatically \\nproduced summary or translation with a set of reference summaries or \\ntranslations.\\nTypes of ROUGE:\\n• ROUGE-1: Measures the overlap of unigrams (individual words).\\n• ROUGE-2: Measures the overlap of bigrams (sequences of two words).'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:59+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:33:59+05:30', 'source': 'dataset/Day-6.pdf', 'total_pages': 13, 'page': 7, 'page_label': '8'}, page_content='• ROUGE-2: Measures the overlap of bigrams (sequences of two words).\\n• ROUGE-L: Focuses on the longest common subsequence, capturing \\nsentence-level structural similarity without requiring consecutive matches.\\nStrength: ROUGE metrics excel at measuring recall, indicating how much \\nimportant information from the reference is preserved in the generated text.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:59+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:33:59+05:30', 'source': 'dataset/Day-6.pdf', 'total_pages': 13, 'page': 8, 'page_label': '9'}, page_content=\"preencoded.png\\nClassification Metrics\\nFor tasks that categorize inputs, specific metrics are used to assess the model's accuracy and reliability.\\n85%\\nAccuracy\\nThe proportion of total correct predictions (Correct predictions / \\nTotal predictions).\\n92%\\nPrecision\\nThe proportion of true positive predictions among all positive \\npredictions.\\n88%\\nRecall\\nThe proportion of true positive predictions among all actual \\npositive instances.\\n90%\\nF1-Score\"), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:59+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:33:59+05:30', 'source': 'dataset/Day-6.pdf', 'total_pages': 13, 'page': 8, 'page_label': '9'}, page_content='The proportion of true positive predictions among all actual \\npositive instances.\\n90%\\nF1-Score\\nThe harmonic mean of Precision and Recall, useful for imbalanced \\ndatasets.\\nExample Use Cases:\\n• Sentiment Classification: Determining if text expresses positive, negative, or neutral sentiment.\\n• Email Spam Detection: Identifying whether an email is spam or legitimate.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:59+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:33:59+05:30', 'source': 'dataset/Day-6.pdf', 'total_pages': 13, 'page': 9, 'page_label': '10'}, page_content='preencoded.png\\nBehavioral Evaluation (Rule-based Checks)\\nBehavioral evaluation, often implemented through rule-based checks, ensures that LLM outputs adhere to specific structural, formatting, or content constraints defined in the \\nprompt.\\n• Format Validation: Ensuring outputs conform to specified structures, e.g., valid \\nJSON, XML.\\n• Content Inclusion: Verifying the presence of required elements like citations or \\nreasoning steps.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:59+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:33:59+05:30', 'source': 'dataset/Day-6.pdf', 'total_pages': 13, 'page': 9, 'page_label': '10'}, page_content='reasoning steps.\\n• Structural Adherence: Checking for ordered lists, specific paragraph structures, or \\nother formatting rules.\\n• Hallucination Prevention: Implementing rules to detect and flag fabricated \\ninformation.\\nAutomated tests based on these rules contribute to stable and predictable model performance. For example, a rule might dictate: \"Output must contain a field: \"answer\": \\n\"<value>\".\"'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:59+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:33:59+05:30', 'source': 'dataset/Day-6.pdf', 'total_pages': 13, 'page': 10, 'page_label': '11'}, page_content='preencoded.png\\nLLM-as-a-Judge\\nThis innovative evaluation method leverages a more powerful or specially tuned LLM to assess the outputs of \\nanother, often less capable, LLM. The \"judge\" LLM provides human-like feedback and scoring, automating a \\nprocess traditionally requiring human intervention.\\n• Rank Responses: Ordering multiple LLM outputs by quality or relevance.\\n• Score Reasoning & Correctness: Evaluating the logical coherence and factual accuracy of answers.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:59+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:33:59+05:30', 'source': 'dataset/Day-6.pdf', 'total_pages': 13, 'page': 10, 'page_label': '11'}, page_content='• Score Reasoning & Correctness: Evaluating the logical coherence and factual accuracy of answers.\\n• Detect Hallucinations: Identifying instances where the LLM generates false information.\\nPrompt Example: \"Rate this answer 1-10 based on factual accuracy.\"\\nUsed in:\\n• Leaderboards: Benchmarking and comparing LLM performance.\\n• Auto-Feedback Systems: Providing instant, scalable feedback for model improvement.\\nCost & Token Efficiency Evaluation'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:59+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:33:59+05:30', 'source': 'dataset/Day-6.pdf', 'total_pages': 13, 'page': 10, 'page_label': '11'}, page_content='Cost & Token Efficiency Evaluation\\nBeyond quality, the practical considerations of cost and performance are critical for deploying LLMs efficiently.\\nTokens Input/Output\\nMonitoring token usage directly impacts operational costs.\\nExecution Latency\\nMinimizing response time is crucial for a positive user experience.\\nThe ultimate goal is to achieve high-quality responses with optimal efficiency and reduced computational expense.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:59+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:33:59+05:30', 'source': 'dataset/Day-6.pdf', 'total_pages': 13, 'page': 11, 'page_label': '12'}, page_content='preencoded.png\\nHow a good prompt will change everything !\\nA good prompt ensures:\\n Correctness\\n  Completeness\\n  Structured & formatted output\\n  Reasoning included\\n  Low hallucination\\n  Efficient \\ntoken usage\\n  Consistent performance'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:33:59+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:33:59+05:30', 'source': 'dataset/Day-6.pdf', 'total_pages': 13, 'page': 12, 'page_label': '13'}, page_content='preencoded.png\\nHow a good prompt will \\nchange everything !\\nA good prompt ensures:\\n Correctness\\n Completeness\\n Structured & formatted output\\n Reasoning included\\n Low hallucination\\n Efficient token usage\\n Consistent performance'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:32:52+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:36:15+05:30', 'source': 'dataset/Day-4.pdf', 'total_pages': 13, 'page': 0, 'page_label': '1'}, page_content='preencoded.png\\nDay - 3 \\nChain of thoughts and Self-Consistency'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:32:52+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:36:15+05:30', 'source': 'dataset/Day-4.pdf', 'total_pages': 13, 'page': 1, 'page_label': '2'}, page_content='preencoded.png\\nWhy LLMs Need Reasoning\\nLarge Language Models (LLMs) excel at pattern recognition, but they don\\'t \"think\" in \\nthe human sense. Their core function is to predict the next token based on vast \\namounts of data.\\nWhen tasks demand logical deduction or multiple sequential steps, simple prediction \\nfalls short. This is where the concept of reasoning becomes critical for LLMs.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:32:52+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:36:15+05:30', 'source': 'dataset/Day-4.pdf', 'total_pages': 13, 'page': 2, 'page_label': '3'}, page_content='preencoded.png\\nThe Gap: Prediction vs. Reasoning\\nPattern Completion\\nLLMs operate on sophisticated pattern \\nmatching, completing sequences rather \\nthan understanding underlying logic.\\nNeed for Structured \\nThought\\nComplex, multi-step tasks require a \\nstructured, methodical approach that \\nprediction alone cannot provide.\\nBridging the Gap\\nWithout guided reasoning, LLMs can \\nstruggle with coherence, consistency, \\nand factual accuracy.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:32:52+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:36:15+05:30', 'source': 'dataset/Day-4.pdf', 'total_pages': 13, 'page': 2, 'page_label': '3'}, page_content='Without guided reasoning, LLMs can \\nstruggle with coherence, consistency, \\nand factual accuracy.\\nThis fundamental difference leads to common LLM pitfalls that reasoning techniques aim to address.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:32:52+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:36:15+05:30', 'source': 'dataset/Day-4.pdf', 'total_pages': 13, 'page': 3, 'page_label': '4'}, page_content=\"preencoded.png\\nThe Challenges of Unguided LLMs\\nLogical Jumps\\nModels may skip necessary intermediate \\nsteps, leading to incomplete or flawed \\nconclusions.\\nHallucinations\\nWithout a clear reasoning path, LLMs can \\nconfidently generate factually incorrect \\ninformation.\\nSkipped Steps\\nCrucial parts of a problem-solving \\nsequence might be omitted, undermining \\nthe final answer's validity.\\nThese issues highlight the critical need for explicit reasoning mechanisms to guide LLM behavior.\"), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:32:52+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:36:15+05:30', 'source': 'dataset/Day-4.pdf', 'total_pages': 13, 'page': 4, 'page_label': '5'}, page_content=\"preencoded.png\\nIntroducing Chain-of-\\nThought (CoT)\\nCoT is a prompting technique \\nthat makes the model “show its \\nwork.”\\nChain-of-Thought (CoT) transforms how LLMs approach complex problems by \\ninstructing them to vocalize their reasoning process. This makes the invisible steps \\nvisible, leading to more robust and verifiable outputs.\\nIt's akin to a student showing all their calculations in a math problem—the final \\nanswer is important, but the process reveals understanding.\"), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:32:52+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:36:15+05:30', 'source': 'dataset/Day-4.pdf', 'total_pages': 13, 'page': 5, 'page_label': '6'}, page_content=\"preencoded.png\\nHow CoT Works: Key Principles\\nForces Step-by-Step\\nCoT explicitly guides the LLM to break down problems into \\nsequential, manageable steps.\\nExposes Logic\\nThe intermediate reasoning becomes transparent, allowing users \\nto understand the model's path to a solution.\\nMimics Human Problem Solving\\nInspired by how humans tackle complex tasks, CoT encourages a \\nmore deliberate and structured approach.\\nEnhances Specific Tasks\"), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:32:52+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:36:15+05:30', 'source': 'dataset/Day-4.pdf', 'total_pages': 13, 'page': 5, 'page_label': '6'}, page_content='more deliberate and structured approach.\\nEnhances Specific Tasks\\nIt is particularly effective for reasoning, mathematics, planning, and \\nmulti-step decision-making.\\nCoT shifts the LLM from simply \"guessing an answer\" to \"walking through the solution\" systematically.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:32:52+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:36:15+05:30', 'source': 'dataset/Day-4.pdf', 'total_pages': 13, 'page': 6, 'page_label': '7'}, page_content='preencoded.png\\nWhen to Leverage Chain-\\nof-Thought\\nBest Use Cases:\\n• Math & arithmetic problems\\n• Logical deduction & puzzles\\n• Multi-step decision making\\n• Multi-hop questions (requiring multiple \\ninformation retrievals)\\n• Complex planning tasks\\n• Classification with detailed \\nexplanation\\nAvoid CoT for:\\n• Simple Q&A (e.g., \"What is the capital \\nof France?\")\\n• Short creative tasks (e.g., \"Write a \\nhaiku\")\\n• Direct fact retrieval'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:32:52+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:36:15+05:30', 'source': 'dataset/Day-4.pdf', 'total_pages': 13, 'page': 6, 'page_label': '7'}, page_content='of France?\")\\n• Short creative tasks (e.g., \"Write a \\nhaiku\")\\n• Direct fact retrieval\\nA good rule of thumb: If a question requires more than a single step or direct recall, CoT can \\nsignificantly improve the LLM\\'s performance.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:32:52+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:36:15+05:30', 'source': 'dataset/Day-4.pdf', 'total_pages': 13, 'page': 7, 'page_label': '8'}, page_content='preencoded.png\\nWhy CoT Enhances Performance\\nBreaks Down Problems\\nCoT deconstructs complex challenges into a series of manageable, logical steps.\\nReduces Hallucinations\\nBy articulating each step, the model is less likely to invent facts or make \\nunsupported claims.\\nFosters Self-Correction\\nThe visible reasoning path allows the LLM to evaluate its own logic and potentially \\ncorrect errors.\\nMimics Human Cognition\\nThis structured approach mirrors effective human problem-solving, leading to'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:32:52+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:36:15+05:30', 'source': 'dataset/Day-4.pdf', 'total_pages': 13, 'page': 7, 'page_label': '8'}, page_content='This structured approach mirrors effective human problem-solving, leading to \\nmore reliable outcomes.\\nUltimately, CoT prompts encourage \"slow thinking,\" resulting in more accurate, consistent, and explainable answers from LLMs.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:32:52+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:36:15+05:30', 'source': 'dataset/Day-4.pdf', 'total_pages': 13, 'page': 8, 'page_label': '9'}, page_content='preencoded.png\\nMastering CoT Prompt Patterns\\nGeneral Reasoning\\n\"Let’s think step by step.\"\\n\"Explain your reasoning before answering.\"\\nMathematical Tasks\\n\"Solve it step-by-step and show the calculations.\"\\nLogical Deduction\\n\"Think through each condition one-by-one.\"\\nPlanning & Execution\\n\"List the steps needed to reach the final solution.\"\\nEmploying these specific phrases can significantly guide the LLM toward generating clear, step-by-step reasoning sequences.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:32:52+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:36:15+05:30', 'source': 'dataset/Day-4.pdf', 'total_pages': 13, 'page': 9, 'page_label': '10'}, page_content='preencoded.png\\nIntroducing Self-Consistency\\nSelf-consistency: Ask the model to \\nsolve the same problem multiple \\ntimes → pick the most common \\nanswer.\\nWhile CoT makes the reasoning path visible, self-consistency takes it a step further by \\nleveraging the LLM\\'s capacity to explore multiple reasoning avenues.\\nBy sampling several \"thoughts\" from the model and identifying the most frequent outcome, we \\ncan drastically improve the reliability of the final answer. It\\'s essentially implementing a'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:32:52+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:36:15+05:30', 'source': 'dataset/Day-4.pdf', 'total_pages': 13, 'page': 9, 'page_label': '10'}, page_content='can drastically improve the reliability of the final answer. It\\'s essentially implementing a \\n\"majority vote\" among the LLM\\'s own internal reasoning processes.'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:32:52+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:36:15+05:30', 'source': 'dataset/Day-4.pdf', 'total_pages': 13, 'page': 10, 'page_label': '11'}, page_content=\"preencoded.png\\nWhy Self-Consistency Boosts \\nAccuracy\\nDiverse Paths\\nLLMs can generate various reasoning sequences, some correct, others flawed.\\nCorrectness Amplification\\nThe correct answers tend to appear more frequently across multiple samples.\\nNoise Reduction\\nMajority voting effectively filters out erroneous or outlier reasoning paths.\\nEnhanced Stability\\nThis technique makes the LLM's reasoning more robust, especially for challenging questions.\"), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:32:52+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:36:15+05:30', 'source': 'dataset/Day-4.pdf', 'total_pages': 13, 'page': 10, 'page_label': '11'}, page_content=\"This technique makes the LLM's reasoning more robust, especially for challenging questions.\\nBy generating and comparing multiple reasoning trajectories, self-consistency reduces hallucinations \\nand leads to a more stable and accurate final answer.\"), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:32:52+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:36:15+05:30', 'source': 'dataset/Day-4.pdf', 'total_pages': 13, 'page': 11, 'page_label': '12'}, page_content='preencoded.png\\nHands on tasks\\nTask 1 — CoT vs No-CoT\\n• Solve any math word problem\\n• Compare accuracy with and without CoT\\nTask 2 — Write a CoT Prompt\\n• Convert a normal prompt → CoT-enhanced reasoning prompt\\nTask 3 — Self-Consistency Experiment\\n• Ask the same question 5 times using CoT\\n• Count the answers\\n• Report the majority result'), Document(metadata={'producer': 'Microsoft® PowerPoint® LTSC', 'creator': 'Microsoft® PowerPoint® LTSC', 'creationdate': '2025-12-08T21:32:52+05:30', 'title': '', 'author': 'Bhuvan Chandra Mothe', 'subject': '', 'moddate': '2025-12-08T21:36:15+05:30', 'source': 'dataset/Day-4.pdf', 'total_pages': 13, 'page': 12, 'page_label': '13'}, page_content='preencoded.png\\nSummary\\n• CoT → Improves LLM reasoning by forcing step-by-step logic\\n• Self-consistency → Improves stability by sampling multiple reasoning paths\\n• Best for math, logic, multi-step reasoning, planning\\n• Avoid CoT for simple answer tasks\\n• These techniques reduce hallucination and improve accuracy\\nCoT + Self-consistency → Stronger, more reliable LLM reasoning.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Creating embeddings... this may take a moment.\")\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1Cze6vdqqOQ",
        "outputId": "0b85f42a-530f-439f-a9bf-48edb4e2000a"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating embeddings... this may take a moment.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore = FAISS.from_documents(chunks, embeddings)"
      ],
      "metadata": {
        "id": "jaNos4bJs9tM"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 1})"
      ],
      "metadata": {
        "id": "_QMJSb6Ys_O_"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_mistralai import ChatMistralAI\n",
        "\n",
        "llm = ChatMistralAI(model=\"mistral-medium\")"
      ],
      "metadata": {
        "id": "3rki7w3BtDPq"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_classic.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_classic.chains import create_retrieval_chain\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "Answer the following question based only on the provided context:\n",
        "\n",
        "<context>\n",
        "{context}\n",
        "</context>\n",
        "\n",
        "Question: {input}\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "wRSGqrMJtDMO"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_chain = create_stuff_documents_chain(llm, prompt)"
      ],
      "metadata": {
        "id": "vb69jIW6tDJL"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rag_chain = create_retrieval_chain(retriever, document_chain)"
      ],
      "metadata": {
        "id": "Z0VoC_j-tDGO"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "if not os.getenv(\"MISTRAL_API_KEY\"):\n",
        "    os.environ[\"MISTRAL_API_KEY\"] = getpass(\"Enter your Mistral API Key: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6N-2CjBDxTBg",
        "outputId": "ba0e87a8-60eb-4f9d-e255-bf6b6c490931"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Mistral API Key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_query = \"What is llm ?\"\n",
        "response = rag_chain.invoke({\"input\": user_query})\n",
        "\n",
        "print(\"\\n--- RESPONSE ---\")\n",
        "print(response[\"answer\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKup9dbztDDS",
        "outputId": "c6e3cbad-16d0-4692-b4e7-8e611e6eab13"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- RESPONSE ---\n",
            "Based on the provided context, **LLM** stands for **Large Language Model**, a type of AI system that is being used to transform industries and tasks by enabling applications like:\n",
            "\n",
            "- **Chatbots & Assistants** (customer service, virtual helpers)\n",
            "- **Coding Assistants** (code generation, debugging)\n",
            "- **Summarization** (condensing long texts)\n",
            "- **PDF Extraction** (pulling data from unstructured documents)\n",
            "- **Agents & Workflows** (automating multi-step processes).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vQ460kg-tC8Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}